"""
è°ƒè¯•å·¥å…·è°ƒç”¨é—®é¢˜
"""
import asyncio
import os
from loom import LoomBuilder
from loom.llm import OpenAIProvider
from loom.kernel.core import UniversalEventBus, Dispatcher
from loom.protocol.cloudevents import CloudEvent
from loom.node.tool import ToolNode
from loom.protocol.mcp import MCPToolDefinition

# è®¾ç½®OpenAIå‡­è¯
os.environ["OPENAI_API_KEY"] = "sk-Fy6Y5WV5eugN61DhxH1AjI8th71OWfopqA2OCj5t93UIZ6aF"
os.environ["OPENAI_MODEL"] = "gpt-4o-mini"
os.environ["OPENAI_BASE_URL"] = "https://xiaoai.plus/v1"

async def test_tool_debug():
    """è°ƒè¯•å·¥å…·è°ƒç”¨"""
    # åˆ›å»ºåŸºç¡€è®¾æ–½
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºOpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=False
    )

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„å·¥å…·
    def add_numbers(a: float, b: float) -> float:
        """Add two numbers together"""
        print(f"ğŸ”§ Toolè¢«è°ƒç”¨: add_numbers({a}, {b})")
        result = a + b
        print(f"ğŸ”§ Toolè¿”å›: {result}")
        return result

    tool_def = MCPToolDefinition(
        name="add_numbers",
        description="Add two numbers together and return the sum",
        inputSchema={
            "type": "object",
            "properties": {
                "a": {"type": "number", "description": "First number"},
                "b": {"type": "number", "description": "Second number"}
            },
            "required": ["a", "b"]
        }
    )

    tool_node = ToolNode(
        node_id="add-tool",
        dispatcher=dispatcher,
        tool_def=tool_def,
        func=add_numbers
    )

    print(f"âœ… Toolåˆ›å»ºæˆåŠŸ: {tool_node.node_id}")
    print(f"   Toolå®šä¹‰: {tool_def.model_dump()}")

    # åˆ›å»ºAgent
    agent = (LoomBuilder()
        .with_id('debug-agent')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_tools([tool_node])
        .with_agent(
            role='Math Assistant',
            system_prompt='You are a math assistant. When asked to add numbers, you MUST use the add_numbers tool.'
        )
        .build())

    print(f"\nâœ… Agentåˆ›å»ºæˆåŠŸ: {agent.node_id}")
    print(f"   å·²æ³¨å†Œå·¥å…·: {list(agent.known_tools.keys())}")

    # æ£€æŸ¥å·¥å…·å®šä¹‰
    print(f"\nğŸ“‹ æ£€æŸ¥Agentçš„å·¥å…·æ³¨å†Œ:")
    print(f"   - known_tools: {agent.known_tools}")
    print(f"   - tool_registry definitions: {[d.name for d in agent.tool_registry.definitions]}")

    # æµ‹è¯•å·¥å…·è°ƒç”¨
    print("\nğŸ“¨ å‘é€é—®é¢˜: What is 5 + 3? Use the add_numbers tool.")
    event = CloudEvent(
        type="node.request",
        source="user",
        data={"content": "What is 5 + 3? You MUST use the add_numbers tool to calculate this."}
    )

    print("\nğŸ”„ å¼€å§‹å¤„ç†...")

    # ç›´æ¥æµ‹è¯•LLMæ˜¯å¦ç”Ÿæˆtool_calls
    print("\nğŸ” ç›´æ¥æµ‹è¯•LLMå“åº”:")
    messages = [
        {"role": "system", "content": agent.system_prompt},
        {"role": "user", "content": "What is 5 + 3? You MUST use the add_numbers tool."}
    ]
    tools = [tool_def.model_dump()]

    llm_response = await provider.chat(messages, tools=tools)
    print(f"   LLMè¿”å›ç±»å‹: {type(llm_response)}")
    print(f"   LLM content: {llm_response.content if hasattr(llm_response, 'content') else llm_response.get('content')}")
    print(f"   LLM tool_calls: {llm_response.tool_calls if hasattr(llm_response, 'tool_calls') else llm_response.get('tool_calls')}")

    print("\nğŸ”„ é€šè¿‡Agentå¤„ç†...")
    result = await agent.process(event)
    print(f"\nğŸ¤– æœ€ç»ˆå“åº”:\n{result}")

# è¿è¡Œæµ‹è¯•
asyncio.run(test_tool_debug())
