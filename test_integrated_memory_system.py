"""
é›†æˆæµ‹è¯•ï¼šå®Œæ•´çš„è®°å¿†ç³»ç»Ÿæµ‹è¯•
æµ‹è¯•é˜¶æ®µä¸€ï¼ˆæŠ•å½±ä¼˜åŒ–ï¼‰å’Œé˜¶æ®µäºŒï¼ˆL4å‹ç¼©ï¼‰çš„é›†æˆ

åœºæ™¯ï¼šAIçŸ¥è¯†åº“åŠ©æ‰‹
- åŠ©æ‰‹å­¦ä¹ å„ç§æŠ€æœ¯çŸ¥è¯†ï¼ˆç§¯ç´¯L4 factsï¼‰
- ç”¨æˆ·æå‡ºä¸åŒç±»å‹çš„é—®é¢˜ï¼ˆè§¦å‘ä¸åŒæŠ•å½±æ¨¡å¼ï¼‰
- è‡ªåŠ¨è§¦å‘L4å‹ç¼©ï¼ˆå½“factsè¶…è¿‡é˜ˆå€¼ï¼‰
- éªŒè¯å‹ç¼©åä»èƒ½æ­£ç¡®å›ç­”é—®é¢˜
"""
import asyncio
import os

# ç¦ç”¨tokenizerså¹¶è¡ŒåŒ–è­¦å‘Š
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from loom import LoomBuilder
from loom.llm import OpenAIProvider
from loom.kernel.core import UniversalEventBus, Dispatcher
from loom.protocol.cloudevents import CloudEvent
from loom.node.tool import ToolNode
from loom.protocol.mcp import MCPToolDefinition
from loom.memory.core import LoomMemory
from loom.memory.types import MemoryUnit, MemoryTier, MemoryType
from loom.projection.profiles import ProjectionMode

# è®¾ç½®OpenAIå‡­è¯
os.environ["OPENAI_API_KEY"] = "sk-Fy6Y5WV5eugN61DhxH1AjI8th71OWfopqA2OCj5t93UIZ6aF"
os.environ["OPENAI_MODEL"] = "gpt-4o-mini"
os.environ["OPENAI_BASE_URL"] = "https://xiaoai.plus/v1"


class TestMonitor:
    """æµ‹è¯•ç›‘æ§å™¨ - è®°å½•å’ŒéªŒè¯æµ‹è¯•è¿‡ç¨‹"""

    def __init__(self):
        self.events = []
        self.l4_size_history = []
        self.projection_history = []
        self.compression_triggered = False

    def log_event(self, event_type: str, data: dict):
        """è®°å½•äº‹ä»¶"""
        self.events.append({
            "type": event_type,
            "data": data
        })

    def log_l4_size(self, size: int):
        """è®°å½•L4å¤§å°"""
        self.l4_size_history.append(size)

    def log_projection(self, mode: str, facts_count: int):
        """è®°å½•æŠ•å½±ä¿¡æ¯"""
        self.projection_history.append({
            "mode": mode,
            "facts_count": facts_count
        })

    def mark_compression(self):
        """æ ‡è®°å‹ç¼©å·²è§¦å‘"""
        self.compression_triggered = True

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "=" * 80)
        print("ğŸ“Š æµ‹è¯•æ‘˜è¦")
        print("=" * 80)
        print(f"æ€»äº‹ä»¶æ•°: {len(self.events)}")
        print(f"L4å¤§å°å˜åŒ–: {self.l4_size_history}")
        print(f"æŠ•å½±æ¬¡æ•°: {len(self.projection_history)}")
        print(f"å‹ç¼©è§¦å‘: {'âœ… æ˜¯' if self.compression_triggered else 'âŒ å¦'}")
        print("\næŠ•å½±å†å²:")
        for i, proj in enumerate(self.projection_history):
            print(f"  {i+1}. æ¨¡å¼: {proj['mode']}, Factsæ•°é‡: {proj['facts_count']}")


# çŸ¥è¯†åº“æ•°æ® - åˆ†ä¸ºå¤šä¸ªä¸»é¢˜
KNOWLEDGE_BASE = {
    "python": [
        "Python is a high-level, interpreted programming language",
        "Python was created by Guido van Rossum in 1991",
        "Python supports multiple programming paradigms",
        "Python has a simple and readable syntax",
        "Python is widely used for web development",
        "Python is popular in data science and machine learning",
        "Python has a large standard library",
        "Python uses dynamic typing",
    ],
    "machine_learning": [
        "Machine learning is a subset of artificial intelligence",
        "Machine learning algorithms learn from data",
        "Supervised learning uses labeled training data",
        "Unsupervised learning finds patterns in unlabeled data",
        "Reinforcement learning learns through trial and error",
        "Deep learning uses neural networks with multiple layers",
        "Neural networks are inspired by biological neurons",
        "Gradient descent is used to optimize neural networks",
    ],
    "web_development": [
        "HTML is the standard markup language for web pages",
        "CSS is used for styling web pages",
        "JavaScript is the programming language of the web",
        "React is a popular JavaScript library for building UIs",
        "Node.js allows JavaScript to run on the server",
        "REST APIs use HTTP methods for communication",
        "GraphQL is an alternative to REST APIs",
        "WebSockets enable real-time bidirectional communication",
    ],
    "databases": [
        "SQL is a language for managing relational databases",
        "NoSQL databases are designed for specific data models",
        "MongoDB is a popular document-oriented database",
        "Redis is an in-memory key-value store",
        "PostgreSQL is an advanced open-source relational database",
        "Database indexing improves query performance",
        "ACID properties ensure database transaction reliability",
        "Database normalization reduces data redundancy",
    ]
}


async def setup_infrastructure():
    """è®¾ç½®åŸºç¡€è®¾æ–½ï¼šäº‹ä»¶æ€»çº¿ã€è°ƒåº¦å™¨ã€LLMæä¾›è€…"""
    print("\n" + "=" * 80)
    print("ğŸ”§ é˜¶æ®µ0ï¼šè®¾ç½®åŸºç¡€è®¾æ–½")
    print("=" * 80)

    # åˆ›å»ºäº‹ä»¶æ€»çº¿å’Œè°ƒåº¦å™¨
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)
    print("âœ… äº‹ä»¶æ€»çº¿å’Œè°ƒåº¦å™¨å·²åˆ›å»º")

    # åˆ›å»ºOpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=False
    )
    print(f"âœ… LLM Providerå·²åˆ›å»º: {provider.config.generation.model}")

    # åˆ›å»ºæµ‹è¯•ç›‘æ§å™¨
    monitor = TestMonitor()
    print("âœ… æµ‹è¯•ç›‘æ§å™¨å·²åˆ›å»º")

    return bus, dispatcher, provider, monitor


async def create_knowledge_tool():
    """åˆ›å»ºçŸ¥è¯†æŸ¥è¯¢å·¥å…·"""
    def search_knowledge(topic: str, query: str) -> str:
        """æœç´¢çŸ¥è¯†åº“"""
        if topic in KNOWLEDGE_BASE:
            results = [fact for fact in KNOWLEDGE_BASE[topic] if query.lower() in fact.lower()]
            if results:
                return f"Found {len(results)} results: " + "; ".join(results[:3])
            return f"No results found for '{query}' in {topic}"
        return f"Topic '{topic}' not found"

    tool_def = MCPToolDefinition(
        name="search_knowledge",
        description="Search the knowledge base for information on a specific topic",
        inputSchema={
            "type": "object",
            "properties": {
                "topic": {
                    "type": "string",
                    "enum": ["python", "machine_learning", "web_development", "databases"],
                    "description": "The topic to search in"
                },
                "query": {
                    "type": "string",
                    "description": "The search query"
                }
            },
            "required": ["topic", "query"]
        }
    )

    return tool_def, search_knowledge


async def stage1_populate_l4(memory: LoomMemory, monitor: TestMonitor):
    """é˜¶æ®µ1ï¼šå¡«å……L4çŸ¥è¯†åº“"""
    print("\n" + "=" * 80)
    print("ğŸ“š é˜¶æ®µ1ï¼šå¡«å……L4çŸ¥è¯†åº“")
    print("=" * 80)

    total_facts = 0
    for topic, facts in KNOWLEDGE_BASE.items():
        print(f"\næ·»åŠ  {topic} çŸ¥è¯†...")
        for i, fact in enumerate(facts):
            await memory.add(MemoryUnit(
                content=fact,
                tier=MemoryTier.L4_GLOBAL,
                type=MemoryType.FACT,
                importance=0.7 + (i * 0.03),
                metadata={"topic": topic}
            ))
            total_facts += 1

        current_size = len(memory._l4_global)
        monitor.log_l4_size(current_size)
        print(f"   âœ… å·²æ·»åŠ  {len(facts)} ä¸ªfactsï¼Œå½“å‰L4æ€»æ•°: {current_size}")

    print(f"\nâœ… é˜¶æ®µ1å®Œæˆï¼šå…±æ·»åŠ  {total_facts} ä¸ªfactsåˆ°L4")
    return total_facts


async def stage2_test_projection_modes(memory: LoomMemory, monitor: TestMonitor):
    """é˜¶æ®µ2ï¼šæµ‹è¯•æŠ•å½±ä¼˜åŒ–ï¼ˆä¸åŒæ¨¡å¼ï¼‰"""
    print("\n" + "=" * 80)
    print("ğŸ” é˜¶æ®µ2ï¼šæµ‹è¯•æŠ•å½±ä¼˜åŒ–")
    print("=" * 80)

    # æµ‹è¯•ç”¨ä¾‹ï¼šä¸åŒç±»å‹çš„æŒ‡ä»¤
    test_cases = [
        ("æŸ¥è¯¢", "minimal", "ç®€çŸ­æŸ¥è¯¢"),
        ("Analyze neural networks in detail", "analytical", "åˆ†ææ€§ä»»åŠ¡"),
        ("Fix the error in the code", "debug", "è°ƒè¯•ä»»åŠ¡"),
        ("ç»§ç»­ä¹‹å‰çš„è®¨è®º", "contextual", "ä¸Šä¸‹æ–‡ç›¸å…³"),
        ("Process user data and generate report", "standard", "æ ‡å‡†ä»»åŠ¡"),
    ]

    for instruction, expected_mode, description in test_cases:
        print(f"\nğŸ“ æµ‹è¯•: {description}")
        print(f"   æŒ‡ä»¤: '{instruction}'")
        print(f"   é¢„æœŸæ¨¡å¼: {expected_mode}")

        # æ£€æµ‹æ¨¡å¼
        detected_mode = memory._detect_mode(instruction)
        print(f"   âœ… æ£€æµ‹åˆ°æ¨¡å¼: {detected_mode.value}")

        # åˆ›å»ºæŠ•å½±
        projection = await memory.create_projection(
            instruction=instruction,
            total_budget=2000
        )

        facts_count = len(projection.relevant_facts) if projection.relevant_facts else 0
        print(f"   ğŸ“Š é€‰æ‹©çš„factsæ•°é‡: {facts_count}")

        # è®°å½•åˆ°ç›‘æ§å™¨
        monitor.log_projection(detected_mode.value, facts_count)

        # éªŒè¯æ¨¡å¼æ˜¯å¦æ­£ç¡®
        if detected_mode.value == expected_mode:
            print(f"   âœ… æ¨¡å¼æ£€æµ‹æ­£ç¡®")
        else:
            print(f"   âš ï¸  æ¨¡å¼æ£€æµ‹ä¸åŒ¹é…ï¼ˆé¢„æœŸ: {expected_mode}, å®é™…: {detected_mode.value}ï¼‰")

    print(f"\nâœ… é˜¶æ®µ2å®Œæˆï¼šæµ‹è¯•äº† {len(test_cases)} ä¸ªæŠ•å½±æ¨¡å¼")


async def stage3_trigger_l4_compression(memory: LoomMemory, provider, monitor: TestMonitor):
    """é˜¶æ®µ3ï¼šè§¦å‘L4å‹ç¼©"""
    print("\n" + "=" * 80)
    print("ğŸ—œï¸  é˜¶æ®µ3ï¼šè§¦å‘L4å‹ç¼©")
    print("=" * 80)

    # æ£€æŸ¥å½“å‰L4å¤§å°
    current_size = len(memory._l4_global)
    print(f"\nå½“å‰L4å¤§å°: {current_size} facts")

    # å¯ç”¨L4å‹ç¼©ï¼ˆè®¾ç½®ä½é˜ˆå€¼ä»¥ä¾¿æµ‹è¯•ï¼‰
    print("\nğŸ”§ å¯ç”¨L4å‹ç¼©...")
    memory.enable_l4_compression(
        llm_provider=provider,
        threshold=20,  # ä½é˜ˆå€¼ï¼Œæ–¹ä¾¿è§¦å‘
        similarity_threshold=0.75,
        min_cluster_size=3
    )
    print(f"âœ… L4å‹ç¼©å·²å¯ç”¨")
    print(f"   - é˜ˆå€¼: {memory.l4_compressor.threshold}")
    print(f"   - ç›¸ä¼¼åº¦é˜ˆå€¼: {memory.l4_compressor.similarity_threshold}")
    print(f"   - æœ€å°èšç±»å¤§å°: {memory.l4_compressor.min_cluster_size}")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
    should_compress = await memory.l4_compressor.should_compress(memory._l4_global)
    print(f"\néœ€è¦å‹ç¼©: {should_compress}")

    if should_compress:
        print(f"\nğŸ—œï¸  å¼€å§‹L4å‹ç¼©...")
        print(f"   å‹ç¼©å‰: {len(memory._l4_global)} ä¸ªfacts")

        # æ‰§è¡Œå‹ç¼©
        await memory._compress_l4()
        monitor.mark_compression()

        print(f"   å‹ç¼©å: {len(memory._l4_global)} ä¸ªfacts")
        compression_rate = (1 - len(memory._l4_global) / current_size) * 100
        print(f"   å‹ç¼©ç‡: {compression_rate:.1f}%")

        monitor.log_l4_size(len(memory._l4_global))
    else:
        print("âš ï¸  L4å¤§å°æœªè¶…è¿‡é˜ˆå€¼ï¼Œæœªè§¦å‘å‹ç¼©")

    print(f"\nâœ… é˜¶æ®µ3å®Œæˆ")


async def stage4_test_agent_with_memory(bus, dispatcher, provider, memory, monitor):
    """é˜¶æ®µ4ï¼šæµ‹è¯•Agentä½¿ç”¨å‹ç¼©åçš„è®°å¿†"""
    print("\n" + "=" * 80)
    print("ğŸ¤– é˜¶æ®µ4ï¼šæµ‹è¯•Agentä½¿ç”¨å‹ç¼©åçš„è®°å¿†")
    print("=" * 80)

    # åˆ›å»ºå·¥å…·
    tool_def, search_func = await create_knowledge_tool()
    tool_node = ToolNode(
        node_id="knowledge-tool",
        dispatcher=dispatcher,
        tool_def=tool_def,
        func=search_func
    )
    print("âœ… çŸ¥è¯†æŸ¥è¯¢å·¥å…·å·²åˆ›å»º")

    # åˆ›å»ºAgent
    agent = (LoomBuilder()
        .with_id('knowledge-assistant')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_tools([tool_node])
        .with_memory(memory)
        .with_agent(
            role='Knowledge Assistant',
            system_prompt='You are a helpful knowledge assistant. Use the search_knowledge tool to find information.'
        )
        .build())
    print(f"âœ… Agentå·²åˆ›å»º: {agent.node_id}")

    # æµ‹è¯•é—®é¢˜
    questions = [
        "What is Python used for?",
        "Explain machine learning",
        "Tell me about databases"
    ]

    for i, question in enumerate(questions):
        print(f"\nğŸ“¨ é—®é¢˜ {i+1}: {question}")

        event = CloudEvent(
            type="node.request",
            source="user",
            data={"content": question}
        )

        result = await agent.process(event)
        print(f"ğŸ¤– å›ç­”: {result[:200]}...")

    print(f"\nâœ… é˜¶æ®µ4å®Œæˆï¼šæµ‹è¯•äº† {len(questions)} ä¸ªé—®é¢˜")


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "=" * 80)
    print("ğŸš€ é›†æˆæµ‹è¯•ï¼šå®Œæ•´çš„è®°å¿†ç³»ç»Ÿ")
    print("=" * 80)
    print("æµ‹è¯•ç›®æ ‡ï¼š")
    print("  1. é˜¶æ®µä¸€ï¼šæŠ•å½±ä¼˜åŒ–ï¼ˆæ¨¡å¼æ£€æµ‹ã€é¢„ç®—æ§åˆ¶ã€è¯­ä¹‰ç›¸å…³æ€§ï¼‰")
    print("  2. é˜¶æ®µäºŒï¼šL4å‹ç¼©ï¼ˆèšç±» + LLMæ€»ç»“ï¼‰")
    print("=" * 80)

    try:
        # é˜¶æ®µ0ï¼šè®¾ç½®åŸºç¡€è®¾æ–½
        bus, dispatcher, provider, monitor = await setup_infrastructure()

        # åˆ›å»ºLoomMemory
        print("\nğŸ”§ åˆ›å»ºLoomMemory...")
        memory = LoomMemory("knowledge-assistant")
        print("âœ… LoomMemoryå·²åˆ›å»º")

        # é˜¶æ®µ1ï¼šå¡«å……L4çŸ¥è¯†åº“
        total_facts = await stage1_populate_l4(memory, monitor)

        # é˜¶æ®µ2ï¼šæµ‹è¯•æŠ•å½±ä¼˜åŒ–
        await stage2_test_projection_modes(memory, monitor)

        # é˜¶æ®µ3ï¼šè§¦å‘L4å‹ç¼©
        await stage3_trigger_l4_compression(memory, provider, monitor)

        # é˜¶æ®µ4ï¼šæµ‹è¯•Agentä½¿ç”¨å‹ç¼©åçš„è®°å¿†
        await stage4_test_agent_with_memory(bus, dispatcher, provider, memory, monitor)

        # æ‰“å°æµ‹è¯•æ‘˜è¦
        monitor.print_summary()

        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
