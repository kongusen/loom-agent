# HierarchicalMemory + RAG é›†æˆæŒ‡å—

> **ç‰ˆæœ¬**: v0.1.9 
> **åŠŸèƒ½**: åˆ†å±‚è®°å¿†ç³»ç»Ÿ + æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰

## æ¦‚è¿°

HierarchicalMemory æ˜¯ Loom Agent çš„é«˜çº§è®°å¿†ç³»ç»Ÿï¼Œå®ç°äº†ç±»ä¼¼äººç±»è®°å¿†çš„åˆ†å±‚æ¶æ„ï¼Œå¹¶æ”¯æŒåŸºäºå‘é‡æ•°æ®åº“çš„è¯­ä¹‰æ£€ç´¢ï¼ˆRAGï¼‰ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **4 å±‚è®°å¿†æ¶æ„**: Ephemeral â†’ Working â†’ Session â†’ Long-term
- **è¯­ä¹‰æ£€ç´¢ï¼ˆRAGï¼‰**: åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ™ºèƒ½æ£€ç´¢
- **è‡ªåŠ¨æ™‹å‡æœºåˆ¶**: Working Memory â†’ Long-term Memory æ™ºèƒ½æµè½¬
- **å·¥å…·è®°å¿†ç®¡ç†**: ä¸´æ—¶å­˜å‚¨å·¥å…·è°ƒç”¨ä¸­é—´çŠ¶æ€ï¼Œç”¨å®Œå³ä¸¢
- **æ— ç¼é›†æˆ**: ä¸ ContextAssembler æ·±åº¦é›†æˆ
- **é›¶é…ç½®å¯åŠ¨**: æ— éœ€å‘é‡æ•°æ®åº“ä¹Ÿèƒ½ä½¿ç”¨ï¼ˆå…³é”®è¯æ£€ç´¢é™çº§ï¼‰

---

## è®°å¿†å±‚çº§è¯¦è§£

### 1. Ephemeral Memoryï¼ˆä¸´æ—¶è®°å¿†ï¼‰

**ç”¨é€”**: å·¥å…·è°ƒç”¨çš„ä¸­é—´çŠ¶æ€ï¼Œæ‰§è¡Œå®Œæˆåè‡ªåŠ¨æ¸…é™¤

**ç”Ÿå‘½å‘¨æœŸ**:
```
å·¥å…·è°ƒç”¨å¼€å§‹ â†’ è®°å½•ä¸­é—´çŠ¶æ€ â†’ å·¥å…·æ‰§è¡Œ â†’ ä¿å­˜æœ€ç»ˆç»“æœåˆ° Session â†’ æ¸…é™¤ä¸´æ—¶è®°å¿†
```

**ç‰¹ç‚¹**:
- åŸºäº Key-Value å­˜å‚¨ï¼ˆDictï¼‰
- ä¸æŒä¹…åŒ–
- ä¸å‚ä¸è‡ªåŠ¨æ™‹å‡
- ç”¨äºé¿å…æ±¡æŸ“å¯¹è¯å†å²

**ç¤ºä¾‹**:
```python
# å·¥å…·è°ƒç”¨å¼€å§‹
await memory.add_ephemeral(
    key="tool_call_123",
    content="Calling search_api with query='Python tutorials'",
    metadata={"status": "in_progress"}
)

# å·¥å…·æ‰§è¡Œå®Œæˆï¼Œæ¸…ç†ä¸´æ—¶è®°å¿†
await memory.clear_ephemeral(key="tool_call_123")
```

---

### 2. Working Memoryï¼ˆå·¥ä½œè®°å¿†ï¼‰

**ç”¨é€”**: Agent å½“å‰å…³æ³¨çš„çŸ­æœŸé‡è¦ä¿¡æ¯

**å®¹é‡**: å¯é…ç½®ï¼ˆé»˜è®¤ 10 æ¡ï¼‰ï¼Œè¶…å‡ºåè‡ªåŠ¨æ™‹å‡åˆ° Long-term

**ç‰¹ç‚¹**:
- ä» Session Memory è‡ªåŠ¨æå–å…³é”®ä¿¡æ¯
- æ”¯æŒè‡ªåŠ¨æ™‹å‡åˆ° Long-term Memory
- é€‚åˆå­˜å‚¨"æœ€è¿‘å…³æ³¨çš„é‡è¦äº‹å®"

**ç¤ºä¾‹**:
```python
memory = HierarchicalMemory(
    working_memory_size=10,  # æœ€å¤šä¿ç•™ 10 æ¡
    auto_promote=True,       # å¯ç”¨è‡ªåŠ¨æ™‹å‡
)

# Working Memory ä¼šè‡ªåŠ¨ä»å¯¹è¯ä¸­æå–
# å½“å®¹é‡è¶…é™æ—¶ï¼Œæœ€æ—§çš„è®°å¿†ä¼šæ™‹å‡åˆ° Long-term
```

---

### 3. Session Memoryï¼ˆä¼šè¯è®°å¿†ï¼‰

**ç”¨é€”**: å½“å‰å¯¹è¯çš„å®Œæ•´å†å²

**å®¹é‡**: å¯é…ç½®ï¼ˆé»˜è®¤ 100 æ¡ï¼‰ï¼Œè¶…å‡ºåè§¦å‘å‹ç¼©

**ç‰¹ç‚¹**:
- å­˜å‚¨ `List[Message]`ï¼ˆå…¼å®¹ç°æœ‰ BaseMemory æ¥å£ï¼‰
- å®Œæ•´ä¿ç•™å¯¹è¯ä¸Šä¸‹æ–‡
- å‚ä¸ ContextAssembler çš„ä¸Šä¸‹æ–‡ç»„è£…

**ç¤ºä¾‹**:
```python
# æ·»åŠ æ¶ˆæ¯åˆ° Session Memory
async for event in memory.add_message_stream(message):
    print(event)

# è·å–æœ€è¿‘ N æ¡
session_msgs = await memory.get_by_tier("session", limit=20)
```

---

### 4. Long-term Memoryï¼ˆé•¿æœŸè®°å¿†ï¼‰

**ç”¨é€”**: è·¨ä¼šè¯çš„æŒä¹…åŒ–çŸ¥è¯†ï¼ˆç”¨æˆ·ç”»åƒã€é¢†åŸŸçŸ¥è¯†ç­‰ï¼‰

**å®¹é‡**: æ— é™åˆ¶ï¼ˆå—å­˜å‚¨ç©ºé—´é™åˆ¶ï¼‰

**ç‰¹ç‚¹**:
- æ”¯æŒå‘é‡åŒ–å­˜å‚¨ï¼ˆEmbeddingï¼‰
- æ”¯æŒè¯­ä¹‰æ£€ç´¢ï¼ˆRAGï¼‰
- å¯æŒä¹…åŒ–åˆ°ç£ç›˜
- è‡ªåŠ¨ä» Working Memory æ™‹å‡

**ç¤ºä¾‹**:
```python
# æ‰‹åŠ¨æ·»åŠ åˆ°é•¿æœŸè®°å¿†
await memory.add_to_longterm(
    content="ç”¨æˆ·å¼ ä¸‰æ˜¯ä¸€å Python æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿ pandas å’Œ numpyã€‚",
    metadata={"category": "user_profile", "importance": "high"}
)

# è¯­ä¹‰æ£€ç´¢
result = await memory.retrieve(
    query="ç”¨æˆ·çš„æŠ€æœ¯èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ",
    top_k=5,
    tier="longterm"
)
```

---

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install loom-agent

# å¯é€‰ï¼šå‘é‡åŒ–èƒ½åŠ›
pip install openai  # OpenAI Embedding
pip install faiss-cpu  # FAISS åŠ é€Ÿï¼ˆå¯é€‰ï¼‰
```

### åŸºç¡€ç”¨æ³•ï¼ˆé›¶é…ç½®ï¼‰

```python
from loom.builtin.memory import HierarchicalMemory
from loom.core.message import Message

# åˆ›å»ºè®°å¿†ç³»ç»Ÿï¼ˆæ— éœ€å‘é‡åŒ–ï¼Œä½¿ç”¨å…³é”®è¯æ£€ç´¢ï¼‰
memory = HierarchicalMemory(
    enable_persistence=False,
    auto_promote=True,
)

# æ·»åŠ å¯¹è¯
msg = Message(role="user", content="æˆ‘å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åå·¥ç¨‹å¸ˆ")
async for event in memory.add_message_stream(msg):
    print(event)

# æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
result = await memory.retrieve(query="å¼ ä¸‰æ˜¯è°ï¼Ÿ", top_k=3)
print(result)
```

---

## RAG é›†æˆï¼ˆè¯­ä¹‰æ£€ç´¢ï¼‰

### é…ç½®å‘é‡åŒ–èƒ½åŠ›

```python
from loom.builtin.memory import HierarchicalMemory
from loom.builtin.embeddings import OpenAIEmbedding
from loom.builtin.vector_store import InMemoryVectorStore

# 1. åˆ›å»º Embedding æ¨¡å‹
embedding = OpenAIEmbedding(
    model="text-embedding-3-small",  # æˆ– "text-embedding-3-large"
    api_key="your_openai_api_key",  # æˆ–é€šè¿‡ OPENAI_API_KEY ç¯å¢ƒå˜é‡
)

# 2. åˆ›å»ºå‘é‡å­˜å‚¨
vector_store = InMemoryVectorStore(
    dimension=1536,  # text-embedding-3-small çš„ç»´åº¦
    use_faiss=True,  # ä½¿ç”¨ FAISS åŠ é€Ÿï¼ˆå¯é€‰ï¼‰
)
await vector_store.initialize()

# 3. åˆ›å»º HierarchicalMemory
memory = HierarchicalMemory(
    embedding=embedding,
    vector_store=vector_store,
    auto_promote=True,
)
```

### è¯­ä¹‰æ£€ç´¢ç¤ºä¾‹

```python
# æ·»åŠ å¯¹è¯ï¼ˆè‡ªåŠ¨å‘é‡åŒ–ï¼‰
conversations = [
    ("user", "æˆ‘æœ€è¿‘åœ¨å­¦ä¹  Rust ç¼–ç¨‹è¯­è¨€"),
    ("assistant", "Rust æ˜¯ä¸€é—¨æ³¨é‡å®‰å…¨å’Œæ€§èƒ½çš„ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ã€‚"),
    ("user", "æˆ‘å¯¹ WebAssembly ä¹Ÿå¾ˆæ„Ÿå…´è¶£"),
    ("assistant", "Rust å¯¹ WASM æ”¯æŒéå¸¸å¥½ï¼"),
]

for role, content in conversations:
    msg = Message(role=role, content=content)
    async for _ in memory.add_message_stream(msg):
        pass

# æ‰‹åŠ¨æ·»åŠ ç”¨æˆ·ç”»åƒåˆ°é•¿æœŸè®°å¿†
await memory.add_to_longterm(
    content="ç”¨æˆ·æ­£åœ¨å­¦ä¹  Rust å’Œ WebAssemblyï¼Œå¯¹ç³»ç»Ÿç¼–ç¨‹æ„Ÿå…´è¶£ã€‚",
    metadata={"category": "user_profile"}
)

# è¯­ä¹‰æ£€ç´¢ï¼ˆåŸºäºå‘é‡ç›¸ä¼¼åº¦ï¼‰
result = await memory.retrieve(
    query="ç”¨æˆ·åœ¨å­¦ä»€ä¹ˆæŠ€æœ¯ï¼Ÿ",  # è¯­ä¹‰åŒ¹é…ï¼Œä¸éœ€è¦ç²¾ç¡®å…³é”®è¯
    top_k=3,
    tier="longterm",
)

print(result)
# è¾“å‡º XML æ ¼å¼çš„æ£€ç´¢ç»“æœï¼š
# <retrieved_memory>
#   <memory tier="longterm" relevance="0.89">
#   ç”¨æˆ·æ­£åœ¨å­¦ä¹  Rust å’Œ WebAssemblyï¼Œå¯¹ç³»ç»Ÿç¼–ç¨‹æ„Ÿå…´è¶£ã€‚
#   </memory>
# </retrieved_memory>
```

---

## å·¥å…·è®°å¿†ï¼ˆEphemeral Memoryï¼‰

### AgentExecutor è‡ªåŠ¨é›†æˆ

ä» v0.1.8 å¼€å§‹ï¼ŒAgentExecutor è‡ªåŠ¨ç®¡ç†å·¥å…·è°ƒç”¨çš„ä¸´æ—¶è®°å¿†ï¼š

```python
from loom.core.agent_executor import AgentExecutor
from loom.builtin.memory import HierarchicalMemory

memory = HierarchicalMemory()

executor = AgentExecutor(
    agent=your_agent,
    context_manager=create_enhanced_context_manager(memory=memory),
)

# å·¥å…·è°ƒç”¨æµç¨‹ï¼ˆè‡ªåŠ¨ç®¡ç†ï¼‰ï¼š
# 1. å·¥å…·è°ƒç”¨å¼€å§‹ â†’ add_ephemeral(key="tool_{id}", ...)
# 2. æ‰§è¡Œå·¥å…·
# 3. ä¿å­˜ç»“æœåˆ° Session Memory
# 4. clear_ephemeral(key="tool_{id}")
```

### æ‰‹åŠ¨ç®¡ç†å·¥å…·è®°å¿†

```python
tool_id = "call_abc123"
tool_name = "search_database"

try:
    # 1. è®°å½•å·¥å…·è°ƒç”¨å¼€å§‹
    await memory.add_ephemeral(
        key=f"tool_{tool_id}",
        content=f"Calling {tool_name}(query='user profile')",
        metadata={"tool_name": tool_name, "status": "in_progress"}
    )

    # 2. æ‰§è¡Œå·¥å…·
    result = await execute_tool(tool_name, args)

    # 3. ä¿å­˜æœ€ç»ˆç»“æœåˆ° Session Memory
    result_msg = Message(role="tool", content=str(result), name=tool_name)
    async for _ in memory.add_message_stream(result_msg):
        pass

finally:
    # 4. æ¸…ç†ä¸´æ—¶è®°å¿†ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ¸…ç†ï¼‰
    await memory.clear_ephemeral(key=f"tool_{tool_id}")
```

---

## è‡ªåŠ¨æ™‹å‡æœºåˆ¶

### å·¥ä½œåŸç†

```
Session Message (å¯¹è¯æ¶ˆæ¯)
        â†“
è‡ªåŠ¨æå–å…³é”®ä¿¡æ¯
        â†“
Working Memory (å®¹é‡: N æ¡)
        â†“
å®¹é‡è¶…é™ + auto_promote=True
        â†“
Long-term Memory
        â”œâ”€ å‘é‡åŒ– (Embedding)
        â””â”€ å­˜å…¥å‘é‡åº“ (VectorStore)
        â†“
æŒä¹…åŒ–åˆ°ç£ç›˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
```

### é…ç½®ç¤ºä¾‹

```python
memory = HierarchicalMemory(
    working_memory_size=5,   # Working Memory å®¹é‡
    auto_promote=True,       # å¯ç”¨è‡ªåŠ¨æ™‹å‡
    embedding=embedding,     # æ™‹å‡æ—¶è‡ªåŠ¨å‘é‡åŒ–
    vector_store=vector_store,
)

# æ·»åŠ å¤šæ¡æ¶ˆæ¯
for i in range(10):
    msg = Message(role="user", content=f"Message {i}")
    async for _ in memory.add_message_stream(msg):
        pass

# ç»“æœï¼š
# - Working Memory: 5 æ¡ï¼ˆæœ€è¿‘çš„ï¼‰
# - Long-term Memory: 5 æ¡ï¼ˆæœ€æ—§çš„å·²æ™‹å‡ï¼‰
```

---

## ä¸ ContextAssembler é›†æˆ

### EnhancedContextManager è‡ªåŠ¨é›†æˆ

```python
from loom.core.context_assembler import create_enhanced_context_manager

# åˆ›å»ºå¸¦ Memory çš„ ContextManager
context_manager = create_enhanced_context_manager(
    memory=memory,
    max_context_tokens=8000,
    enable_smart_assembly=True,
)

# å‡†å¤‡ä¸Šä¸‹æ–‡ï¼ˆè‡ªåŠ¨æ£€ç´¢ç›¸å…³è®°å¿†ï¼‰
message = Message(role="user", content="ç”¨æˆ·çš„æŠ€æœ¯èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ")
prepared = await context_manager.prepare(message)

# ä¸Šä¸‹æ–‡ç»„è£…æµç¨‹ï¼š
# 1. è°ƒç”¨ memory.retrieve(query=message.content, top_k=5, tier="longterm")
# 2. å°†æ£€ç´¢ç»“æœä½œä¸º HIGH ä¼˜å…ˆçº§ç»„ä»¶æ·»åŠ 
# 3. æ™ºèƒ½ç»„è£…ï¼šç³»ç»Ÿæç¤º + æ£€ç´¢è®°å¿† + å†å²å¯¹è¯ + å½“å‰æ¶ˆæ¯
# 4. è‡ªåŠ¨æˆªæ–­ä»¥é€‚åº” token é¢„ç®—
```

### æ£€ç´¢ç»“æœæ ¼å¼

`memory.retrieve()` è¿”å› XML æ ¼å¼ï¼Œæ–¹ä¾¿ LLM ç†è§£ï¼š

```xml
<retrieved_memory>
  <memory tier="longterm" relevance="0.92">
  ç”¨æˆ·æ˜¯ä¸€å Python æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿ pandasã€numpy ç­‰å·¥å…·ã€‚
  </memory>
  <memory tier="longterm" relevance="0.85">
  ç”¨æˆ·å¯¹æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ éå¸¸æ„Ÿå…´è¶£ï¼Œæ­£åœ¨å­¦ä¹  PyTorchã€‚
  </memory>
</retrieved_memory>
```

---

## å‘é‡å­˜å‚¨é€‰é¡¹

### InMemoryVectorStoreï¼ˆé»˜è®¤ï¼‰

**ç‰¹ç‚¹**:
- é›¶é…ç½®ï¼Œå¼€ç®±å³ç”¨
- åŸºäº NumPy å®ç°
- å¯é€‰ FAISS åŠ é€Ÿ
- ä¸æŒä¹…åŒ–ï¼ˆé‡å¯ä¸¢å¤±ï¼‰

```python
from loom.builtin.vector_store import InMemoryVectorStore

vector_store = InMemoryVectorStore(
    dimension=1536,
    use_faiss=True,  # å°è¯•ä½¿ç”¨ FAISSï¼Œå¤±è´¥åˆ™é™çº§åˆ° NumPy
)
await vector_store.initialize()
```

### ChromaDBï¼ˆå¤–éƒ¨å­˜å‚¨ï¼‰

**ç‰¹ç‚¹**:
- æŒä¹…åŒ–å­˜å‚¨
- æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²
- é«˜æ€§èƒ½

```python
# TODO: v0.1.9 å°†æ”¯æŒ ChromaDB é€‚é…å™¨
# from loom.builtin.vector_store import ChromaDBAdapter
```

---

## API å‚è€ƒ

### HierarchicalMemory

#### æ„é€ å‡½æ•°

```python
HierarchicalMemory(
    embedding: Optional[BaseEmbedding] = None,
    vector_store: Optional[BaseVectorStore] = None,
    enable_persistence: bool = False,
    auto_promote: bool = True,
    working_memory_size: int = 10,
    session_memory_size: int = 100,
)
```

**å‚æ•°**:
- `embedding`: Embedding æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
- `vector_store`: å‘é‡å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
- `enable_persistence`: æ˜¯å¦æŒä¹…åŒ–åˆ°ç£ç›˜
- `auto_promote`: æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ™‹å‡
- `working_memory_size`: Working Memory å®¹é‡
- `session_memory_size`: Session Memory å®¹é‡

#### æ ¸å¿ƒæ–¹æ³•

##### `add_message_stream(message: Message) -> AsyncGenerator[AgentEvent]`

æ·»åŠ æ¶ˆæ¯åˆ° Session Memoryï¼Œè‡ªåŠ¨æå–åˆ° Working Memoryã€‚

```python
async for event in memory.add_message_stream(message):
    if event.type == AgentEventType.MEMORY_ADD_END:
        print("æ¶ˆæ¯å·²æ·»åŠ ")
```

##### `retrieve(query: str, top_k: int = 5, tier: Optional[str] = None) -> str`

è¯­ä¹‰æ£€ç´¢ç›¸å…³è®°å¿†ï¼Œè¿”å› XML æ ¼å¼ç»“æœã€‚

```python
result = await memory.retrieve(
    query="ç”¨æˆ·çš„æŠ€æœ¯èƒŒæ™¯",
    top_k=5,
    tier="longterm",  # å¯é€‰ï¼š"ephemeral", "working", "session", "longterm"
)
```

##### `add_to_longterm(content: str, metadata: Optional[Dict] = None) -> None`

æ‰‹åŠ¨æ·»åŠ åˆ°é•¿æœŸè®°å¿†å¹¶å‘é‡åŒ–ã€‚

```python
await memory.add_to_longterm(
    content="ç”¨æˆ·æ˜¯ Python å¼€å‘è€…",
    metadata={"category": "profile", "importance": "high"}
)
```

##### `get_by_tier(tier: str, limit: Optional[int] = None) -> List[Message]`

æŒ‰å±‚çº§è·å–è®°å¿†ã€‚

```python
# è·å–æœ€è¿‘ 10 æ¡ä¼šè¯è®°å¿†
session_msgs = await memory.get_by_tier("session", limit=10)

# è·å–æ‰€æœ‰é•¿æœŸè®°å¿†
longterm_msgs = await memory.get_by_tier("longterm")
```

#### Ephemeral Memory æ–¹æ³•

##### `add_ephemeral(key: str, content: str, metadata: Optional[Dict] = None)`

æ·»åŠ ä¸´æ—¶è®°å¿†ï¼ˆå·¥å…·è°ƒç”¨ä¸­é—´çŠ¶æ€ï¼‰ã€‚

```python
await memory.add_ephemeral(
    key="tool_call_123",
    content="Calling API...",
    metadata={"status": "in_progress"}
)
```

##### `get_ephemeral(key: str) -> Optional[str]`

è·å–ä¸´æ—¶è®°å¿†ã€‚

```python
content = await memory.get_ephemeral(key="tool_call_123")
```

##### `clear_ephemeral(key: Optional[str] = None)`

æ¸…é™¤ä¸´æ—¶è®°å¿†ï¼ˆå•ä¸ªæˆ–å…¨éƒ¨ï¼‰ã€‚

```python
# æ¸…é™¤å•ä¸ª
await memory.clear_ephemeral(key="tool_call_123")

# æ¸…é™¤å…¨éƒ¨
await memory.clear_ephemeral()
```

---

## äº‹ä»¶ç³»ç»Ÿ

v0.1.8 æ–°å¢ RAG ç›¸å…³äº‹ä»¶ï¼š

```python
class AgentEventType(str, Enum):
    # RAG äº‹ä»¶
    MEMORY_RETRIEVE_START = "memory_retrieve_start"
    MEMORY_RETRIEVE_COMPLETE = "memory_retrieve_complete"
    MEMORY_VECTORIZE_START = "memory_vectorize_start"
    MEMORY_VECTORIZE_COMPLETE = "memory_vectorize_complete"

    # Ephemeral Memory äº‹ä»¶
    EPHEMERAL_ADD = "ephemeral_add"
    EPHEMERAL_CLEAR = "ephemeral_clear"
```

**ç›‘å¬äº‹ä»¶ç¤ºä¾‹**:

```python
async for event in memory.add_message_stream(message):
    if event.type == AgentEventType.MEMORY_VECTORIZE_START:
        print("å¼€å§‹å‘é‡åŒ–...")
    elif event.type == AgentEventType.MEMORY_VECTORIZE_COMPLETE:
        print("å‘é‡åŒ–å®Œæˆ")
```

---

## æœ€ä½³å®è·µ

### 1. å‘é‡åŒ–å¼€é”€ä¼˜åŒ–

```python
# âœ… å¥½ï¼šæ‰¹é‡å‘é‡åŒ–
contents = [msg.content for msg in messages]
embeddings = await embedding.embed_documents(contents)

# âŒ å·®ï¼šé€æ¡å‘é‡åŒ–
for msg in messages:
    emb = await embedding.embed_query(msg.content)
```

### 2. é•¿æœŸè®°å¿†ç®¡ç†

```python
# å®šæœŸæ¸…ç†ä½ä»·å€¼è®°å¿†
longterm = await memory.get_by_tier("longterm")

# åˆ é™¤ä½ç›¸å…³æ€§æˆ–è¿‡æœŸçš„è®°å¿†
# TODO: v0.1.9 å°†æ”¯æŒåˆ é™¤å’Œæ›´æ–°æ“ä½œ
```

### 3. Token é¢„ç®—æ§åˆ¶

```python
# ä½¿ç”¨ ContextAssembler è‡ªåŠ¨ç®¡ç† token é¢„ç®—
context_manager = create_enhanced_context_manager(
    memory=memory,
    max_context_tokens=8000,  # æ ¹æ®æ¨¡å‹é™åˆ¶è°ƒæ•´
    enable_smart_assembly=True,
)

# æ£€ç´¢æ—¶é™åˆ¶æ•°é‡
result = await memory.retrieve(query=query, top_k=3)  # ä¸è¦å¤ªå¤š
```

### 4. åˆ†å±‚è®°å¿†ç­–ç•¥

| è®°å¿†å±‚çº§ | é€‚ç”¨åœºæ™¯ | å®¹é‡å»ºè®® | æŒä¹…åŒ– |
|---------|---------|----------|--------|
| Ephemeral | å·¥å…·è°ƒç”¨ä¸­é—´çŠ¶æ€ | æ— é™åˆ¶ï¼ˆä¸´æ—¶ï¼‰ | âŒ |
| Working | å½“å‰ä»»åŠ¡å…³é”®ä¿¡æ¯ | 5-10 æ¡ | âŒ |
| Session | å®Œæ•´å¯¹è¯å†å² | 50-100 æ¡ | âŒ |
| Long-term | ç”¨æˆ·ç”»åƒã€é¢†åŸŸçŸ¥è¯† | æ— é™åˆ¶ | âœ… |

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ä½¿ç”¨ OpenAI Embedding å¯ä»¥å—ï¼Ÿ

**A**: å¯ä»¥ï¼HierarchicalMemory æ”¯æŒé›¶é…ç½®å¯åŠ¨ï¼Œä¼šè‡ªåŠ¨é™çº§åˆ°å…³é”®è¯æ£€ç´¢ã€‚

```python
# æ— éœ€ embedding å’Œ vector_store
memory = HierarchicalMemory()

# ä»ç„¶å¯ä»¥æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
result = await memory.retrieve(query="å¼ ä¸‰")
```

### Q2: å¦‚ä½•ä½¿ç”¨å…¶ä»– Embedding æ¨¡å‹ï¼Ÿ

**A**: å®ç° `BaseEmbedding` æ¥å£å³å¯ï¼š

```python
from loom.interfaces.embedding import BaseEmbedding

class CustomEmbedding(BaseEmbedding):
    async def embed_query(self, text: str) -> List[float]:
        # ä½ çš„å®ç°
        pass

    async def embed_documents(self, texts: List[str]) -> List[List[float]]:
        # ä½ çš„å®ç°
        pass
```

### Q3: å‘é‡å­˜å‚¨æ”¯æŒå“ªäº›æ•°æ®åº“ï¼Ÿ

**A**: å½“å‰æ”¯æŒï¼š
- âœ… InMemoryVectorStoreï¼ˆé»˜è®¤ï¼‰
- ğŸš§ ChromaDBï¼ˆv0.1.9 è®¡åˆ’ï¼‰
- ğŸš§ Pineconeï¼ˆv0.2.0 è®¡åˆ’ï¼‰

å¯é€šè¿‡å®ç° `BaseVectorStore` æ¥å£è‡ªå®šä¹‰ã€‚

### Q4: å¦‚ä½•æŒä¹…åŒ– Long-term Memoryï¼Ÿ

**A**:

```python
memory = HierarchicalMemory(
    enable_persistence=True,
    # é»˜è®¤ä¿å­˜åˆ° ~/.loom/memory.json
)

# æ‰‹åŠ¨ä¿å­˜
await memory.save()

# æ‰‹åŠ¨åŠ è½½
await memory.load()
```

### Q5: è‡ªåŠ¨æ™‹å‡çš„è§„åˆ™æ˜¯ä»€ä¹ˆï¼Ÿ

**A**:
1. Working Memory å®¹é‡è¶…é™æ—¶è§¦å‘
2. æŒ‰ FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰åŸåˆ™æ™‹å‡æœ€æ—§çš„è®°å¿†
3. åªæ™‹å‡ `len(content) > 100` çš„è®°å¿†ï¼ˆé¿å…æ™‹å‡æ— æ„ä¹‰çŸ­å¥ï¼‰
4. æ™‹å‡æ—¶è‡ªåŠ¨å‘é‡åŒ–ï¼ˆå¦‚æœé…ç½®äº† embeddingï¼‰

---

## ç¤ºä¾‹ä»£ç 

å®Œæ•´ç¤ºä¾‹è¯·å‚è€ƒï¼š
- `examples/hierarchical_memory_rag_example.py`

---

## ç‰ˆæœ¬å†å²

### v0.1.8 (2024-12-15)

- âœ… å®ç° 4 å±‚è®°å¿†æ¶æ„
- âœ… æ”¯æŒè¯­ä¹‰æ£€ç´¢ï¼ˆRAGï¼‰
- âœ… é›†æˆ OpenAI Embedding
- âœ… å®ç° InMemoryVectorStore
- âœ… è‡ªåŠ¨æ™‹å‡æœºåˆ¶
- âœ… å·¥å…·è®°å¿†ï¼ˆEphemeral Memoryï¼‰
- âœ… ä¸ ContextAssembler é›†æˆ
- âœ… æ–°å¢ 6 ä¸ª RAG äº‹ä»¶ç±»å‹

### Roadmap

- ğŸš§ v0.1.9: ChromaDB é€‚é…å™¨
- ğŸš§ v0.2.0: è®°å¿†åˆ é™¤å’Œæ›´æ–° API
- ğŸš§ v0.2.0: Pinecone æ”¯æŒ
- ğŸš§ v0.2.1: æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å…³é”®è¯ï¼‰

---

## å‚è€ƒèµ„æ–™

- [BaseMemory Protocol](../../interfaces/memory.py)
- [ContextAssembler é›†æˆ](./context_assembler.md)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [FAISS GitHub](https://github.com/facebookresearch/faiss)
