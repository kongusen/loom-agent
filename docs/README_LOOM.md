# Loom Agent Framework

> ä¸€ä¸ªå¼ºå¤§ã€çµæ´»ã€å¯æ‰©å±•çš„ AI Agent å¼€å‘æ¡†æ¶ï¼Œå¯¹æ ‡ LangChainï¼Œå…·å¤‡ Claude Code çº§å·¥ç¨‹èƒ½åŠ›

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### æ¶æ„ä¼˜åŠ¿
- **ç»„åˆä¼˜å…ˆ**: æä¾›å¯æ‹¼è£…çš„æ„å»ºå—,è€Œéå®Œæ•´åº”ç”¨
- **åˆ†å±‚æ¸…æ™°**: Interface â†’ Core â†’ Components â†’ Patterns å››å±‚æ¶æ„
- **å¼ºç±»å‹**: åŸºäº Pydantic çš„å¼ºç±»å‹ç³»ç»Ÿ,å‡å°‘è¿è¡Œæ—¶é”™è¯¯
- **å¼‚æ­¥ä¼˜å…ˆ**: å…¨é“¾è·¯ async/await,åŸç”Ÿæ”¯æŒæµå¼è¾“å‡º

### Claude Code çº§å·¥ç¨‹å®è·µ
- **6 é˜¶æ®µå·¥å…·æµæ°´çº¿**: Discover â†’ Validate â†’ Authorize â†’ CheckCancel â†’ Execute â†’ Format
- **æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©**: 92% é˜ˆå€¼è§¦å‘,8 æ®µå¼ç»“æ„åŒ–å‹ç¼©ç®—æ³•
- **å¹¶å‘è°ƒåº¦å™¨**: æœ€å¤§ 10 å¹¶å‘,æ™ºèƒ½åŒºåˆ†å¹¶å‘å®‰å…¨/éå®‰å…¨å·¥å…·
- **åŠ¨æ€ç³»ç»Ÿæç¤º**: è‡ªåŠ¨ç”Ÿæˆå·¥å…·ç›®å½•ã€é£æ ¼æŒ‡å¼•ä¸è¾¹ç•Œæé†’
- **Multi-Agent æ”¯æŒ**: SubAgent éš”ç¦»æ‰§è¡Œ,æ”¯æŒä»»åŠ¡åˆ†è§£ä¸ç»“æœæ±‡æ€»

### ç”Ÿæ€é›†æˆ
- **MCP åè®®æ”¯æŒ**: åŸç”Ÿæ¥å…¥ Model Context Protocol å·¥å…·ç”Ÿæ€
- **æ’ä»¶åŒ–æ‰©å±•**: é€šè¿‡æ³¨å†Œä¸­å¿ƒæ‰©å±• LLM/Tool/Memory,æ— éœ€ä¿®æ”¹æ ¸å¿ƒ
- **å¤š LLM æ”¯æŒ**: OpenAI, Anthropic, æœ¬åœ°æ¨¡å‹ç­‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# åŸºç¡€å®‰è£…
pip install -e .

# å¯é€‰ä¾èµ–
pip install openai          # OpenAI LLM
pip install anthropic       # Anthropic Claude
pip install httpx           # HTTP è¯·æ±‚å·¥å…·
pip install duckduckgo-search  # Web æœç´¢å·¥å…·
```

### æœ€ç®€å•çš„ç¤ºä¾‹ï¼ˆæ¨èï¼Œä¸€è¡Œæ„å»ºï¼‰

```python
import asyncio
import loom
from loom.builtin.llms import MockLLM

# ä½¿ç”¨ä¾¿æ·æ„å»ºå‡½æ•°ï¼Œä¸€è¡Œåˆ›å»º Agent
agent = loom.agent(llm=MockLLM(responses=["The answer is 42"]))
print(asyncio.run(agent.ainvoke("What is the meaning of life?")))
```

### å¸¦å·¥å…·çš„ Agent

```python
import asyncio, os, loom
from loom.builtin.tools import Calculator, ReadFileTool, WriteFileTool

async def main():
    # å»ºè®®ä»ç¯å¢ƒå˜é‡è¯»å– OPENAI_API_KEY
    agent = loom.agent(
        provider="openai", model="gpt-4o",
        tools=[Calculator(), ReadFileTool(), WriteFileTool()],
        max_iterations=10
    )

    result = await agent.ainvoke(
        "Calculate 123 * 456, write the result to result.txt, then read it back"
    )
    print(result)

asyncio.run(main())
```

### è‡ªå®šä¹‰å·¥å…·ï¼ˆ@loom.tool è£…é¥°å™¨ï¼‰

```python
import loom
from typing import List

@loom.tool(description="Sum a list of numbers")
def sum_list(nums: List[float]) -> float:
    return sum(nums)

SumTool = sum_list
agent = loom.agent(provider="openai", model="gpt-4o", tools=[SumTool()])
```

### Multi-Agent ç³»ç»Ÿ

```python
from loom import Agent
from loom.builtin.llms import OpenAILLM
from loom.patterns import MultiAgentSystem

# å®šä¹‰ä¸“ä¸š Agent
researcher = Agent(llm=OpenAILLM(api_key="...", model="gpt-4"), tools=[...])
analyst = Agent(llm=OpenAILLM(api_key="...", model="gpt-4"), tools=[...])
writer = Agent(llm=OpenAILLM(api_key="...", model="gpt-4"), tools=[...])

# åˆ›å»ºåä½œç³»ç»Ÿ
system = MultiAgentSystem(
    agents={"researcher": researcher, "analyst": analyst, "writer": writer},
    coordinator=OpenAILLM(api_key="...", model="gpt-4")
)

result = await system.run("Research Python trends, analyze data, write report")
```

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### 1. åˆ†å±‚æ¶æ„

```
Developer Apps (ChatBot, CodeGen, RAG, Multi-Agent)
           â”‚
  High-Level: Agent Â· Chain Â· Router Â· Workflow
           â”‚
  Core: AgentExecutor Â· ToolPipeline Â· Scheduler Â· MemoryManager
           â”‚
  Interfaces: BaseLLM Â· BaseTool Â· BaseMemory Â· BaseCompressor
           â”‚
  Ecosystem: PluginRegistry Â· MCP Adapter
```

### 2. Agent ä¸»å¾ªç¯

```python
# Agent ä¸»å¾ªç¯æ‰§è¡Œæµç¨‹
1. æ¶ˆæ¯é¢„å¤„ç† & å‹ç¼©æ£€æŸ¥ (92% é˜ˆå€¼)
2. åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤º (å·¥å…·ç›®å½• + é£æ ¼æŒ‡å¼•)
3. LLM ç”Ÿæˆ (æ”¯æŒå·¥å…·è°ƒç”¨)
4. å·¥å…·æ‰§è¡Œ (6 é˜¶æ®µæµæ°´çº¿)
5. ç»“æœèšåˆ & çŠ¶æ€æ›´æ–°
6. å¾ªç¯åˆ¤æ–­ (æœ€å¤§è¿­ä»£æ¬¡æ•°)
```

### 3. å·¥å…·æ‰§è¡Œæµæ°´çº¿

```python
# 6 é˜¶æ®µæµæ°´çº¿
tool_call â†’ Discover â†’ Validate â†’ Authorize â†’ CheckCancel â†’ Execute â†’ Format â†’ Result

# æ¯ä¸ªé˜¶æ®µéƒ½æœ‰:
- æ¸…æ™°çš„èŒè´£è¾¹ç•Œ
- é”™è¯¯å¤„ç†ä¸è‡ªæ„ˆ
- æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- é˜¶æ®µè€—æ—¶ç»Ÿè®¡
```

### 4. å¹¶å‘è°ƒåº¦

```python
# å¹¶å‘å®‰å…¨å·¥å…· (æœ€å¤§ 10 å¹¶å‘)
Read, Glob, Grep, WebSearch, Task ...

# éå¹¶å‘å®‰å…¨å·¥å…· (ä¸²è¡Œæ‰§è¡Œ)
Write, Edit, Bash, TodoWrite ...

# è°ƒåº¦å™¨è‡ªåŠ¨å¤„ç†
scheduler.schedule_batch(tools)  # è‡ªåŠ¨å¹¶å‘/ä¸²è¡Œå†³ç­–
```

## ğŸ§© å†…ç½®ç»„ä»¶

### LLM æä¾›è€…

| æä¾›è€… | ç±»å | æ”¯æŒå·¥å…·è°ƒç”¨ | æµå¼è¾“å‡º |
|--------|------|-------------|---------|
| OpenAI | `OpenAILLM` | âœ… | âœ… |
| Mock (æµ‹è¯•) | `MockLLM` | âŒ | âŒ |
| Rule (è§„åˆ™) | `RuleLLM` | âœ… | âŒ |

### å†…ç½®å·¥å…·

| å·¥å…· | ç±»å | å¹¶å‘å®‰å…¨ | ä¾èµ– |
|------|------|---------|------|
| è®¡ç®—å™¨ | `Calculator` | âœ… | - |
| æ–‡ä»¶è¯»å– | `ReadFileTool` | âœ… | - |
| æ–‡ä»¶å†™å…¥ | `WriteFileTool` | âŒ | - |
| æ–‡ä»¶æœç´¢ | `GlobTool` | âœ… | - |
| å†…å®¹æœç´¢ | `GrepTool` | âœ… | - |
| Web æœç´¢ | `WebSearchTool` | âœ… | duckduckgo-search |
| Python REPL | `PythonREPLTool` | âŒ | - |
| HTTP è¯·æ±‚ | `HTTPRequestTool` | âœ… | httpx |
| SubAgent | `TaskTool` | âœ… | - |

### å†…å­˜åç«¯

- `InMemoryMemory`: å†…å­˜å­˜å‚¨ (å¼€å‘/æµ‹è¯•)
- `RedisMemory`: Redis æŒä¹…åŒ– (ç”Ÿäº§ç¯å¢ƒ) - å¾…å®ç°
- `PostgreSQLMemory`: PostgreSQL å­˜å‚¨ - å¾…å®ç°

### å‹ç¼©ç­–ç•¥

- `StructuredCompressor`: 8 æ®µå¼ç»“æ„åŒ–å‹ç¼© (å¯¹é½ Claude Code AU2 ç®—æ³•)
- `SlidingWindowCompressor`: æ»‘åŠ¨çª—å£å‹ç¼© - å¾…å®ç°

## ğŸ”Œ MCP é›†æˆ

Loom åŸç”Ÿæ”¯æŒ Model Context Protocol,å¯ç›´æ¥ä½¿ç”¨æ•´ä¸ª MCP å·¥å…·ç”Ÿæ€!

```python
from loom import Agent
from loom.builtin.llms import OpenAILLM
from loom.mcp import MCPToolRegistry

# è‡ªåŠ¨å‘ç°æœ¬åœ° MCP servers
registry = MCPToolRegistry()
await registry.discover_local_servers()

# åŠ è½½ MCP å·¥å…·
tools = await registry.load_servers(["filesystem", "github", "postgres"])

# åœ¨ Agent ä¸­ä½¿ç”¨
agent = Agent(llm=OpenAILLM(api_key="..."), tools=tools)
result = await agent.run("Read config.json and create a GitHub issue")

await registry.close()
```

**å¯ç”¨çš„ MCP Servers**:
- `@modelcontextprotocol/server-filesystem` - æ–‡ä»¶ç³»ç»Ÿ
- `@modelcontextprotocol/server-github` - GitHub é›†æˆ
- `@modelcontextprotocol/server-postgres` - PostgreSQL æ•°æ®åº“
- `@modelcontextprotocol/server-puppeteer` - Web è‡ªåŠ¨åŒ–
- ä»¥åŠæ•°ç™¾ä¸ªç¤¾åŒº servers...

è¯¦è§: [LOOM_MCP_INTEGRATION.md](./LOOM_MCP_INTEGRATION.md)

## ğŸ¨ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰å·¥å…·

```python
from pydantic import BaseModel, Field
from loom.interfaces.tool import BaseTool

class WeatherInput(BaseModel):
    city: str = Field(description="City name")

class WeatherTool(BaseTool):
    name = "get_weather"
    description = "Get current weather"
    args_schema = WeatherInput
    is_concurrency_safe = True

    async def run(self, city: str, **kwargs):
        return f"Weather in {city}: Sunny, 25Â°C"

# ä½¿ç”¨
agent = Agent(llm=llm, tools=[WeatherTool()])
```

### è‡ªå®šä¹‰ LLM

```python
from loom.interfaces.llm import BaseLLM

class MyLLM(BaseLLM):
    @property
    def model_name(self) -> str:
        return "my-model"

    @property
    def supports_tools(self) -> bool:
        return True

    async def generate(self, messages):
        # å®ç°ç”Ÿæˆé€»è¾‘
        return "response"

    async def stream(self, messages):
        # å®ç°æµå¼è¾“å‡º
        yield "chunk"

    async def generate_with_tools(self, messages, tools):
        # å®ç°å·¥å…·è°ƒç”¨
        return {"content": "...", "tool_calls": [...]}
```

### é“¾å¼ç»„åˆ

```python
from loom.components import Chain

# æ„å»ºå¤„ç†é“¾
chain = (
    Chain([preprocess])
    | agent
    | Chain([postprocess])
)

result = await chain.run(input)
```

### æƒé™æ§åˆ¶

```python
from loom import Agent

agent = Agent(
    llm=llm,
    tools=tools,
    permission_policy={
        "write_file": "ask",      # éœ€è¦ç”¨æˆ·ç¡®è®¤
        "http_request": "deny",   # ç›´æ¥æ‹’ç»
        "default": "allow"        # é»˜è®¤å…è®¸
    }
)
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

```python
# è·å–è¿è¡ŒæŒ‡æ ‡
metrics = agent.get_metrics()

print(metrics)
# {
#   'total_iterations': 5,
#   'llm_calls': 6,
#   'tool_calls': 8,
#   'total_errors': 0,
#   'compression_count': 1
# }
```

## ğŸ§ª æµ‹è¯•

```python
# ä½¿ç”¨ MockLLM è¿›è¡Œæµ‹è¯•
from loom.builtin.llms import MockLLM

mock_llm = MockLLM(responses=[
    "I will use the calculator",
    "The answer is 4"
])

agent = Agent(llm=mock_llm, tools=[Calculator()])
result = await agent.run("What is 2+2?")
assert "4" in result
```

## ğŸ“– æ–‡æ¡£

- [å®Œæ•´è®¾è®¡æ–‡æ¡£](../department/LOOM_UNIFIED_DEVELOPER_GUIDE.md)
- [MCP é›†æˆæŒ‡å—](./LOOM_MCP_INTEGRATION.md)
- [æ¶æ„è®¾è®¡ v2.0](../department/LOOM_FRAMEWORK_DESIGN_V2.md)
- [Claude Code æŠ€æœ¯è§£æ](../department/Claude_Code_Agentç³»ç»Ÿå®Œæ•´æŠ€æœ¯è§£æ.md)

## ğŸ—ºï¸ è·¯çº¿å›¾

- [x] **Phase 1**: æ ¸å¿ƒæ¥å£ä¸åŸºç¡€ç»„ä»¶
- [x] **Phase 2**: ä¸Šä¸‹æ–‡å‹ç¼©ä¸ç¨³å®šæ€§
- [x] **Phase 3**: å·¥å…·ç”Ÿæ€ä¸ Multi-Agent
- [x] **Phase 4**: MCP åè®®é›†æˆ
- [ ] **Phase 5**: ç”Ÿäº§åŒ– (Prometheus, ç†”æ–­, CI/CD)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®! è¯·æŸ¥çœ‹ [è´¡çŒ®æŒ‡å—](./CONTRIBUTING.md)

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](./LICENSE)

## ğŸ™ è‡´è°¢

- è®¾è®¡çµæ„Ÿæ¥è‡ª Claude Code, LangChain, AutoGPT
- MCP åè®®ç”± Anthropic æä¾›

---

**Loom: Build Intelligent Agents with Building Blocks** ğŸ§©
