# Loom Agent v0.1 è¿ç§»æŒ‡å—

**ä» v0.0.x å‡çº§åˆ° v0.1.0**

æœ¬æŒ‡å—å¸®åŠ©æ‚¨å°†ç°æœ‰ä»£ç è¿ç§»åˆ° Loom Agent v0.1.0ã€‚è¿™æ˜¯ä¸€æ¬¡**é‡å¤§æ¶æ„å‡çº§**ï¼Œå®Œå…¨é‡æ„äº†LLMæ¥å£å’ŒAgent APIã€‚

---

## ğŸ¯ æ ¸å¿ƒå˜æ›´

### 1. **ç»Ÿä¸€LLMæ¥å£** - ä»4ä¸ªæ–¹æ³•ç®€åŒ–åˆ°1ä¸ª

**ä¹‹å‰ (v0.0.x)**:
```python
class BaseLLM(ABC):
    async def generate(...) -> str
    async def stream(...) -> AsyncGenerator[str, None]
    async def generate_with_tools(...) -> Dict
    async def stream_with_tools(...) -> AsyncGenerator[str, None]
```

**ç°åœ¨ (v0.1.0)**:
```python
@runtime_checkable
class BaseLLM(Protocol):
    @property
    def model_name(self) -> str: ...

    async def stream(
        self,
        messages: List[Dict],
        tools: Optional[List[Dict]] = None,
        response_format: Optional[Dict] = None,
        **kwargs
    ) -> AsyncGenerator[LLMEvent, None]: ...
```

### 2. **Agent APIç®€åŒ–** - 2ä¸ªæ¸…æ™°çš„å…¥å£

**ä¹‹å‰ (v0.0.x)**:
```python
# æ··ä¹±çš„å¤šä¸ªæ–¹æ³•
agent.run()      # éæµå¼
agent.stream()   # æ—§æµå¼ â†’ StreamEvent
agent.astream()  # åˆ«å
agent.execute()  # æ–°æµå¼ â†’ AgentEvent
```

**ç°åœ¨ (v0.1.0)**:
```python
# åªæœ‰2ä¸ªæ¸…æ™°çš„æ–¹æ³•
agent.run()      # éæµå¼ â†’ str
agent.execute()  # æµå¼ â†’ AsyncGenerator[AgentEvent]
agent.ainvoke()  # run()çš„LangChainé£æ ¼åˆ«å
```

### 3. **ç»Ÿä¸€äº‹ä»¶æ ¼å¼** - LLMEvent

**ä¹‹å‰ (v0.0.x)**:
```python
# stream() è¿”å›å­—ç¬¦ä¸²
async for chunk in llm.stream(messages):
    print(chunk)  # str

# StreamEvent (å·²åºŸå¼ƒ)
async for event in agent.stream(input):
    if event.type == "text":
        print(event.content)
```

**ç°åœ¨ (v0.1.0)**:
```python
# ç»Ÿä¸€çš„ LLMEvent å­—å…¸
async for event in llm.stream(messages):
    if event["type"] == "content_delta":
        print(event["content"])
    elif event["type"] == "tool_calls":
        handle_tools(event["tool_calls"])
    elif event["type"] == "finish":
        print(f"Done: {event['finish_reason']}")
```

---

## ğŸ“‹ è¿ç§»æ¸…å•

### âœ… Agentä½¿ç”¨è€…

#### 1. **æ›´æ–°æµå¼è¾“å‡ºä»£ç **

**ä¹‹å‰**:
```python
async for chunk in agent.stream("è¯·æ±‚"):
    print(chunk, end="")
```

**ä¹‹å**:
```python
from loom.core.events import AgentEventType

async for event in agent.execute("è¯·æ±‚"):
    if event.type == AgentEventType.LLM_DELTA:
        print(event.content, end="")
    elif event.type == AgentEventType.AGENT_FINISH:
        break
```

#### 2. **åˆ é™¤ StreamEvent å¯¼å…¥**

**ä¹‹å‰**:
```python
from loom.core.types import StreamEvent  # âŒ å·²åˆ é™¤
```

**ä¹‹å**:
```python
from loom.core.events import AgentEvent, AgentEventType  # âœ… ä½¿ç”¨è¿™ä¸ª
```

#### 3. **æ›´æ–°äº‹ä»¶å¤„ç†**

**ä¹‹å‰**:
```python
if event.type == "text":
    print(event.content)
elif event.type == "tool_call":
    print(event.tool_name)
```

**ä¹‹å**:
```python
if event.type == AgentEventType.LLM_DELTA:
    print(event.content)
elif event.type == AgentEventType.TOOL_EXECUTION_START:
    print(event.metadata.get('tool_name'))
elif event.type == AgentEventType.TOOL_RESULT:
    print(event.tool_result.content)
```

### âœ… LLMå®ç°è€…

#### 1. **ä»ABCæ”¹ä¸ºProtocol**

**ä¹‹å‰**:
```python
from loom.interfaces.llm import BaseLLM

class MyLLM(BaseLLM):  # éœ€è¦ç»§æ‰¿
    async def generate(...): ...
    async def stream(...): ...
    async def generate_with_tools(...): ...
    async def stream_with_tools(...): ...
```

**ä¹‹å**:
```python
# ä¸éœ€è¦ç»§æ‰¿ï¼åªéœ€å®ç°Protocol
class MyLLM:
    @property
    def model_name(self) -> str:
        return "my-model"

    async def stream(
        self,
        messages: List[Dict],
        tools: Optional[List[Dict]] = None,
        response_format: Optional[Dict] = None,
        **kwargs
    ) -> AsyncGenerator[LLMEvent, None]:
        # å¤„ç†æ‰€æœ‰æƒ…å†µï¼šæ–‡æœ¬ã€å·¥å…·ã€JSON
        async for chunk in api_stream:
            yield {"type": "content_delta", "content": chunk}

        if tool_calls:
            yield {"type": "tool_calls", "tool_calls": tool_calls}

        yield {"type": "finish", "finish_reason": "stop"}
```

#### 2. **ç»Ÿä¸€æ‰€æœ‰LLMè°ƒç”¨**

**ä¹‹å‰**:
```python
# éœ€è¦æ ¹æ®æ˜¯å¦æœ‰å·¥å…·é€‰æ‹©ä¸åŒæ–¹æ³•
if tools:
    result = await llm.generate_with_tools(messages, tools)
else:
    result = await llm.generate(messages)
```

**ä¹‹å**:
```python
# ç»Ÿä¸€ä½¿ç”¨ stream()
async for event in llm.stream(messages, tools=tools):
    if event["type"] == "content_delta":
        content += event["content"]
    elif event["type"] == "tool_calls":
        tool_calls = event["tool_calls"]
```

---

## ğŸ”§ å¸¸è§è¿ç§»åœºæ™¯

### åœºæ™¯1: ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ

**ä¹‹å‰**:
```python
result = await agent.run("ä½ å¥½")
print(result)
```

**ä¹‹å**:
```python
# å®Œå…¨ä¸å˜ï¼run() ä¾ç„¶å¯ç”¨
result = await agent.run("ä½ å¥½")
print(result)
```

### åœºæ™¯2: æµå¼è¾“å‡ºåˆ°UI

**ä¹‹å‰**:
```python
async for chunk in agent.stream("è®²ä¸ªæ•…äº‹"):
    ui.append_text(chunk)
```

**ä¹‹å**:
```python
from loom.core.events import AgentEventType

async for event in agent.execute("è®²ä¸ªæ•…äº‹"):
    if event.type == AgentEventType.LLM_DELTA:
        ui.append_text(event.content)
    elif event.type == AgentEventType.TOOL_RESULT:
        ui.show_tool(event.tool_result.tool_name)
```

### åœºæ™¯3: FastAPIæµå¼å“åº”

**ä¹‹å‰**:
```python
@app.get("/stream")
async def stream_endpoint(query: str):
    async def generator():
        async for chunk in agent.stream(query):
            yield f"data: {chunk}\n\n"

    return StreamingResponse(generator())
```

**ä¹‹å**:
```python
from loom.core.events import AgentEventType

@app.get("/stream")
async def stream_endpoint(query: str):
    async def generator():
        async for event in agent.execute(query):
            if event.type == AgentEventType.LLM_DELTA:
                yield f"data: {event.content}\n\n"
            elif event.type == AgentEventType.AGENT_FINISH:
                yield "data: [DONE]\n\n"
                break

    return StreamingResponse(generator(), media_type="text/event-stream")
```

### åœºæ™¯4: å®ç°è‡ªå®šä¹‰LLM

**ä¹‹å‰**:
```python
class MyLLM(BaseLLM):
    async def generate(self, messages):
        # å®ç°
        pass

    async def stream(self, messages):
        # å®ç°
        pass

    async def generate_with_tools(self, messages, tools):
        # å®ç°
        pass

    async def stream_with_tools(self, messages, tools):
        # å®ç°
        pass
```

**ä¹‹å**:
```python
class MyLLM:
    @property
    def model_name(self) -> str:
        return "my-model"

    async def stream(self, messages, tools=None, **kwargs):
        # ä¸€ä¸ªæ–¹æ³•å¤„ç†æ‰€æœ‰æƒ…å†µ
        async for chunk in my_api.stream(messages):
            yield {"type": "content_delta", "content": chunk}

        yield {"type": "finish", "finish_reason": "stop"}
```

---

## ğŸš€ æ–°ç‰¹æ€§

### 1. è¿è¡Œæ—¶ProtocoléªŒè¯

```python
from loom.interfaces.llm import validate_llm

llm = MyLLM()
validate_llm(llm)  # è‡ªåŠ¨æ£€æŸ¥æ˜¯å¦å®ç°äº†Protocol
```

### 2. ç»Ÿä¸€äº‹ä»¶æµ

```python
# LLMEvent æ¶µç›–æ‰€æœ‰åœºæ™¯
{
    "type": "content_delta",  # æ–‡æœ¬å¢é‡
    "content": "Hello"
}
{
    "type": "tool_calls",  # å·¥å…·è°ƒç”¨
    "tool_calls": [...]
}
{
    "type": "finish",  # å®Œæˆæ ‡è®°
    "finish_reason": "stop"
}
```

### 3. æ›´å¥½çš„ç±»å‹å®‰å…¨

```python
# TypedDict æä¾›ç±»å‹æç¤º
from loom.interfaces.llm import LLMEvent

async def process_stream(stream: AsyncGenerator[LLMEvent, None]):
    async for event in stream:
        # IDE è‡ªåŠ¨æç¤º event çš„ç»“æ„
        if event["type"] == "content_delta":
            print(event["content"])
```

---

## â“ å¸¸è§é—®é¢˜

### Q: æ—§çš„ `stream()` æ–¹æ³•è¿˜èƒ½ç”¨å—ï¼Ÿ

**A**: ä¸èƒ½ã€‚`agent.stream()` å’Œ `agent.astream()` å·²è¢«å®Œå…¨åˆ é™¤ã€‚è¯·ä½¿ç”¨ `agent.execute()`ã€‚

### Q: StreamEvent åœ¨å“ªé‡Œï¼Ÿ

**A**: `StreamEvent` å·²è¢«åˆ é™¤ã€‚è¯·ä½¿ç”¨ `AgentEvent` (ä» `loom.core.events` å¯¼å…¥)ã€‚

### Q: æˆ‘çš„è‡ªå®šä¹‰LLMè¿˜éœ€è¦ç»§æ‰¿BaseLLMå—ï¼Ÿ

**A**: ä¸éœ€è¦ï¼åªè¦å®ç° `model_name` å±æ€§å’Œ `stream()` æ–¹æ³•å³å¯ã€‚è¿™å°±æ˜¯Protocolçš„ä¼˜åŠ¿ã€‚

### Q: å¦‚ä½•åˆ¤æ–­æˆ‘çš„LLMæ˜¯å¦å…¼å®¹ï¼Ÿ

**A**: ä½¿ç”¨è¿è¡Œæ—¶éªŒè¯ï¼š
```python
from loom.interfaces.llm import is_llm

if is_llm(my_llm):
    print("å…¼å®¹!")
else:
    print("éœ€è¦æ›´æ–°")
```

### Q: ä¸ºä»€ä¹ˆè¦åšè¿™ä¸ªæ”¹å˜ï¼Ÿ

**A**: ä¸»è¦åŸå› ï¼š
1. **ç®€åŒ–**: ä»4ä¸ªæ–¹æ³•å‡å°‘åˆ°1ä¸ªæ–¹æ³•
2. **ç»Ÿä¸€**: æ‰€æœ‰LLMæ“ä½œè¿”å›ç›¸åŒæ ¼å¼
3. **çµæ´»**: Protocolæ”¯æŒé¸­å­ç±»å‹ï¼Œæ— éœ€ç»§æ‰¿
4. **ç±»å‹å®‰å…¨**: è¿è¡Œæ—¶éªŒè¯ + é™æ€ç±»å‹æ£€æŸ¥
5. **ä¸€è‡´æ€§**: æ¶ˆé™¤åˆ†æ”¯é€»è¾‘ï¼Œä»£ç æ›´æ¸…æ™°

---

## ğŸ“š æ›´å¤šèµ„æº

- **å®Œæ•´æ–‡æ¡£**: [docs/user/user-guide.md](user/user-guide.md)
- **APIå‚è€ƒ**: [docs/user/api-reference.md](user/api-reference.md)
- **ç¤ºä¾‹ä»£ç **: [examples/](../examples/)
- **GitHub**: https://github.com/kongusen/loom-agent

---

## ğŸ’¡ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœåœ¨è¿ç§»è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š

1. **æ£€æŸ¥æ–‡æ¡£**: æŸ¥çœ‹ [ç”¨æˆ·æŒ‡å—](user/user-guide.md)
2. **æŸ¥çœ‹ç¤ºä¾‹**: å‚è€ƒ [examples/](../examples/) ç›®å½•
3. **æäº¤Issue**: https://github.com/kongusen/loom-agent/issues
4. **è”ç³»æ”¯æŒ**: wanghaishan0210@gmail.com

---

**ç¥æ‚¨è¿ç§»é¡ºåˆ©ï¼** ğŸ‰
