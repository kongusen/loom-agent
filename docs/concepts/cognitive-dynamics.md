# 认知动力学

> **理解导向** - 深入理解 loom-agent 的认知理论基础

## 概述

认知动力学（Cognitive Dynamics）是 loom-agent 的理论基础，它将 Agent 的运行过程类比为生物的认知过程，强调信息的流动、转化和代谢。

## 核心概念

### 1. 双系统理论（Dual-Process Theory）

loom-agent 借鉴认知心理学的双系统理论（Daniel Kahneman《思考，快与慢》），实现了两种并行的认知处理模式：

**System 1（系统 1）- 快速思维**：
- **特点**：快速、自动、直觉、无意识
- **实现**：流式输出（StreamChunks）
- **认知过程**：模式识别、快速反应
- **输出形式**：实时文本流

**System 2（系统 2）- 慢速思维**：
- **特点**：慢速、受控、理性、有意识
- **实现**：思考节点（Thoughts）
- **认知过程**：深度推理、逻辑分析
- **输出形式**：结构化洞察

**认知状态空间（S → O）**：
```
S (State Space / 隐空间)：高维内部状态
  ├─ 活跃思考 (active_thoughts)
  ├─ 待投影洞察 (pending_insights)
  └─ 记忆向量 (memory_embeddings)
         ↓
    投影算子 π (Projection Operator)
         ↓
O (Observable / 显空间)：低维可观测输出
```

### 2. 认知熵（Cognitive Entropy）

信息的无序程度和复杂度：

- **高熵**：信息混乱、冗余、难以处理
- **低熵**：信息有序、精炼、易于理解

**目标**：通过认知代谢降低熵，保持系统的有序性。

### 2. 认知代谢（Cognitive Metabolism）

类比生物代谢，Agent 需要"消化"和"转化"信息：

```
输入信息 → 处理 → 精炼 → 输出信息
（高熵）    （代谢）  （降熵）  （低熵）
```

**关键机制**：
- **摄入**：接收外部信息
- **消化**：理解和处理信息
- **吸收**：提取关键信息
- **排泄**：丢弃冗余信息

### 3. 记忆管理

Agent 的记忆类似于人类的记忆系统：

**短期记忆（Working Memory）**：
- 当前对话上下文
- 最近的工具调用结果
- 临时状态信息

**长期记忆（Long-term Memory）**：
- 历史对话记录
- 学习到的知识
- 用户偏好设置

**记忆代谢**：
- 定期清理过期信息
- 压缩冗余内容
- 保留关键信息

### 4. 上下文窗口管理

LLM 的上下文窗口是有限的，需要智能管理：

**挑战**：
- Token 限制（如 4K, 8K, 128K）
- 长对话导致上下文溢出
- 信息冗余降低效率

**解决方案**：
- **上下文清理器（Context Sanitizer）**：自动压缩和精炼上下文
- **滑动窗口**：保留最近的 N 条消息
- **摘要生成**：将历史对话压缩为摘要

### 5. 分形代谢（Fractal Metabolism）

在 Crew 中，代谢过程是分形的：

```
Crew 层级：
Agent A → 输出 → 清理 → Agent B → 输出 → 清理 → Agent C
         (代谢)         (代谢)         (代谢)
```

**BubbleUpSanitizer**：
- 每个 Agent 的输出都会被清理
- 只保留关键信息传递给下一个 Agent
- 防止上下文污染和信息爆炸

**优势**：
- 保持信息流的清洁
- 避免长链路的上下文溢出
- 提高整体系统效率

## 实际应用

### 在 loom-agent 中的实现

**ContextSanitizer**：
```python
class ContextSanitizer:
    async def sanitize(self, context: str, target_token_limit: int) -> str:
        """压缩上下文到目标 token 限制"""
        # 使用 LLM 生成摘要
        # 保留关键信息
        # 丢弃冗余内容
```

**BubbleUpSanitizer**：
- 在 Crew 的 sequential 模式中使用
- 每个 Agent 的输出都会被清理
- 默认限制为 100 tokens

### 设计建议

1. **合理设置 token 预算**：避免过度消耗
2. **使用上下文清理器**：保持信息流清洁
3. **定期清理记忆**：防止记忆膨胀
4. **监控熵值**：及时发现信息混乱

## 总结

认知动力学为 Agent 系统提供了理论基础：

1. **认知熵**：衡量信息的有序程度
2. **认知代谢**：转化和精炼信息
3. **记忆管理**：短期和长期记忆的平衡
4. **上下文管理**：智能处理有限的上下文窗口
5. **分形代谢**：在多层级系统中保持信息清洁

## 相关文档

- [架构设计](architecture.md) - 了解系统架构
- [设计哲学](design-philosophy.md) - 深入了解设计理念
