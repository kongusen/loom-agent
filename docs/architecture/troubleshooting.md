# Loom Agent v0.1.1 æ•…éšœæ’æŸ¥æŒ‡å—

**ç³»ç»ŸåŒ–é—®é¢˜è¯Šæ–­** | **å¿«é€Ÿå®šä½æ ¹å› ** | **ä¸€æ­¥æ­¥è§£å†³æ–¹æ¡ˆ**

---

## ğŸ” å¿«é€Ÿè¯Šæ–­æµç¨‹å›¾

```
Agent å‡ºç°é—®é¢˜ï¼Ÿ
â”‚
â”œâ”€ 1. Agent ä¸å“åº”/ä¸å¯åŠ¨ï¼Ÿ
â”‚   â”œâ”€ æ£€æŸ¥ LLM é…ç½®
â”‚   â”‚   â”œâ”€ API key è®¾ç½®ï¼Ÿ â†’ export OPENAI_API_KEY=sk-...
â”‚   â”‚   â”œâ”€ Model åç§°æ­£ç¡®ï¼Ÿ â†’ "gpt-4" ä¸æ˜¯ "gpt4"
â”‚   â”‚   â””â”€ Provider æ”¯æŒï¼Ÿ â†’ openai/anthropic/azure
â”‚   â”‚
â”‚   â”œâ”€ æ£€æŸ¥å¯¼å…¥
â”‚   â”‚   â”œâ”€ from loom import agent  â† æ­£ç¡®
â”‚   â”‚   â””â”€ from loom import Agent  â† ä¹Ÿæ­£ç¡®
â”‚   â”‚
â”‚   â””â”€ æ£€æŸ¥ async/await
â”‚       â”œâ”€ await agent.run() â† æ­£ç¡®
â”‚       â””â”€ agent.run()       â† é”™è¯¯ï¼ˆè¿”å›coroutineï¼‰
â”‚
â”œâ”€ 2. Agent æ‰§è¡Œåæ— è¾“å‡ºï¼Ÿ
â”‚   â”œâ”€ æ£€æŸ¥è¿”å›å€¼
â”‚   â”‚   â””â”€ result = await agent.run() â†’ print(result)
â”‚   â”‚
â”‚   â”œâ”€ æ£€æŸ¥äº‹ä»¶æµ
â”‚   â”‚   â””â”€ async for event in agent.execute(): ...
â”‚   â”‚
â”‚   â””â”€ æ£€æŸ¥æ—¥å¿—
â”‚       â””â”€ å¯ç”¨ LoggingHook
â”‚
â”œâ”€ 3. å·¥å…·è°ƒç”¨å¤±è´¥ï¼Ÿ
â”‚   â”œâ”€ å·¥å…·å·²æ³¨å†Œï¼Ÿ
â”‚   â”‚   â””â”€ tools=[ReadFileTool(), BashTool()]
â”‚   â”‚
â”‚   â”œâ”€ å·¥å…·åç§°æ­£ç¡®ï¼Ÿ
â”‚   â”‚   â””â”€ "read_file" ä¸æ˜¯ "readfile"
â”‚   â”‚
â”‚   â””â”€ æƒé™é—®é¢˜ï¼Ÿ
â”‚       â””â”€ HITLHook é˜»æ­¢ï¼Ÿæ£€æŸ¥ ask_handler
â”‚
â”œâ”€ 4. ä¸Šä¸‹æ–‡/Token é—®é¢˜ï¼Ÿ
â”‚   â”œâ”€ è¶…è¿‡ token é™åˆ¶ï¼Ÿ
â”‚   â”‚   â”œâ”€ å¢åŠ  max_context_tokens
â”‚   â”‚   â””â”€ å¯ç”¨ CompressionManager
â”‚   â”‚
â”‚   â”œâ”€ ä¸Šä¸‹æ–‡ä¸¢å¤±ï¼Ÿ
â”‚   â”‚   â””â”€ å¯ç”¨ ContextDebugger
â”‚   â”‚
â”‚   â””â”€ Compression å¤±è´¥ï¼Ÿ
â”‚       â””â”€ æ£€æŸ¥ COMPRESSION_FALLBACK äº‹ä»¶
â”‚
â”œâ”€ 5. è¶…è¿‡æœ€å¤§è¿­ä»£ï¼Ÿ
â”‚   â”œâ”€ å¢åŠ  max_iterations
â”‚   â”œâ”€ æ£€æŸ¥æ­»å¾ªç¯
â”‚   â””â”€ ä¼˜åŒ– system_instructions
â”‚
â”œâ”€ 6. Crash Recovery å¤±è´¥ï¼Ÿ
â”‚   â”œâ”€ thread_id å”¯ä¸€ï¼Ÿ
â”‚   â”œâ”€ EventJournal é…ç½®æ­£ç¡®ï¼Ÿ
â”‚   â””â”€ æ—¥å¿—æ–‡ä»¶å­˜åœ¨ï¼Ÿ
â”‚
â””â”€ 7. æ€§èƒ½é—®é¢˜ï¼Ÿ
    â”œâ”€ Token ä½¿ç”¨è¿‡é«˜ï¼Ÿ â†’ ä¼˜åŒ– context
    â”œâ”€ å“åº”æ…¢ï¼Ÿ â†’ ä½¿ç”¨æ›´å¿«çš„ model
    â””â”€ å¹¶å‘é—®é¢˜ï¼Ÿ â†’ ä½¿ç”¨ Crew å¹¶è¡Œæ‰§è¡Œ
```

---

## ğŸš¨ å¸¸è§é”™è¯¯é€ŸæŸ¥è¡¨

### é”™è¯¯ 1: `ToolNotFoundError: Tool 'bash' not found`

**åŸå› **: å·¥å…·æœªæ³¨å†Œåˆ° Agent

**è§£å†³æ–¹æ¡ˆ**:
```python
# âŒ é”™è¯¯
agent(llm=llm, tools=[])  # æ²¡æœ‰ BashTool

# âœ… æ­£ç¡®
from loom.builtin.tools import BashTool
agent(llm=llm, tools=[BashTool()])
```

**è°ƒè¯•æ­¥éª¤**:
1. æ£€æŸ¥ `tools=[]` å‚æ•°
2. ç¡®è®¤å·¥å…·å·²å¯¼å…¥
3. éªŒè¯å·¥å…·åç§°æ‹¼å†™

---

### é”™è¯¯ 2: `MaxIterationsExceeded: Agent exceeded 50 iterations`

**åŸå› **: Agent é™·å…¥å¾ªç¯æˆ–ä»»åŠ¡å¤ªå¤æ‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ 1: å¢åŠ è¿­ä»£é™åˆ¶
agent(llm=llm, max_iterations=100)

# æ–¹æ¡ˆ 2: ä¼˜åŒ– system_instructions
agent(
    llm=llm,
    system_instructions="""
    å®Œæˆä»»åŠ¡åç«‹å³åœæ­¢ã€‚
    ä¸è¦é‡å¤å·²å®Œæˆçš„å·¥ä½œã€‚
    å¦‚æœé‡åˆ°é—®é¢˜ï¼ŒæŠ¥å‘Šè€Œä¸æ˜¯æ— é™é‡è¯•ã€‚
    """
)

# æ–¹æ¡ˆ 3: æ·»åŠ å–æ¶ˆä»¤ç‰Œ
cancel_token = asyncio.Event()
result = await agent.run("task", cancel_token=cancel_token)
```

**è°ƒè¯•æ­¥éª¤**:
1. å¯ç”¨è¯¦ç»†æ—¥å¿—æŸ¥çœ‹è¿­ä»£è¿‡ç¨‹
2. æ£€æŸ¥ ITERATION_START äº‹ä»¶
3. åˆ†ææ˜¯å¦æœ‰å·¥å…·è°ƒç”¨æ­»å¾ªç¯

---

### é”™è¯¯ 3: `TokenLimitExceeded: Context size 12000 exceeds limit 8000`

**åŸå› **: ä¸Šä¸‹æ–‡è¶…è¿‡æ¨¡å‹é™åˆ¶

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ 1: å¢åŠ é™åˆ¶ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
agent(llm=llm, max_context_tokens=16000)

# æ–¹æ¡ˆ 2: å¯ç”¨å‹ç¼©ï¼ˆv0.1.1 è‡ªåŠ¨å¯ç”¨ï¼‰
from loom.core.compression_manager import CompressionManager
compressor = CompressionManager(llm=llm, compression_threshold=0.92)
agent(llm=llm, compressor=compressor)

# æ–¹æ¡ˆ 3: ä¼˜åŒ– Context Assembly
from loom.core.context_assembly import ContextAssembler
assembler = ContextAssembler(max_tokens=8000)
# ä½¿ç”¨ assembler ç®¡ç†ä¸Šä¸‹æ–‡ç»„ä»¶ä¼˜å…ˆçº§
```

**è°ƒè¯•æ­¥éª¤**:
1. å¯ç”¨ ContextDebugger æŸ¥çœ‹ token ä½¿ç”¨
2. æ£€æŸ¥å“ªäº›ç»„ä»¶å ç”¨æœ€å¤š tokens
3. è°ƒæ•´ç»„ä»¶ä¼˜å…ˆçº§æˆ–å¯ç”¨æˆªæ–­

---

### é”™è¯¯ 4: `ThreadIdRequired: enable_persistence=True requires thread_id`

**åŸå› **: å¯ç”¨æŒä¹…åŒ–ä½†æœªæä¾› thread_id

**è§£å†³æ–¹æ¡ˆ**:
```python
# âŒ é”™è¯¯
agent(llm=llm, enable_persistence=True)

# âœ… æ­£ç¡®
import uuid
agent(
    llm=llm,
    enable_persistence=True,
    thread_id=f"user-{user_id}-{uuid.uuid4()}"
)
```

**thread_id æœ€ä½³å®è·µ**:
- æ ¼å¼: `user-{user_id}-{session_id}`
- å¿…é¡»å”¯ä¸€ï¼ˆè·¨ç”¨æˆ·å’Œä¼šè¯ï¼‰
- ç”¨äº crash recovery å’Œä¼šè¯ç®¡ç†

---

### é”™è¯¯ 5: `LLMError: OpenAI API key not found`

**åŸå› **: API key æœªè®¾ç½®æˆ–æ— æ•ˆ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ¡ˆ 1: ç¯å¢ƒå˜é‡
export OPENAI_API_KEY=sk-...

# æ–¹æ¡ˆ 2: .env æ–‡ä»¶
echo "OPENAI_API_KEY=sk-..." > .env
pip install python-dotenv
```

```python
# æ–¹æ¡ˆ 3: ä»£ç ä¸­è®¾ç½®ï¼ˆä¸æ¨èç”¨äºç”Ÿäº§ï¼‰
from loom.builtin.llms.openai import OpenAILLM
llm = OpenAILLM(model="gpt-4", api_key="sk-...")
```

**è°ƒè¯•æ­¥éª¤**:
1. è¿è¡Œ `echo $OPENAI_API_KEY` éªŒè¯ç¯å¢ƒå˜é‡
2. æ£€æŸ¥ API key æ˜¯å¦æœ‰æ•ˆï¼ˆç™»å½• OpenAI dashboardï¼‰
3. ç¡®è®¤ key æœ‰è¶³å¤Ÿçš„é…é¢

---

### é”™è¯¯ 6: `TypeError: 'coroutine' object is not iterable`

**åŸå› **: å¿˜è®°ä½¿ç”¨ `await` æˆ– `async for`

**è§£å†³æ–¹æ¡ˆ**:
```python
# âŒ é”™è¯¯
result = agent.run("task")  # è¿”å› coroutine
for event in agent.execute("task"):  # é”™è¯¯ï¼šä¸æ˜¯æ™®é€šè¿­ä»£å™¨

# âœ… æ­£ç¡®
result = await agent.run("task")  # ä½¿ç”¨ await
async for event in agent.execute("task"):  # ä½¿ç”¨ async for
    print(event)
```

---

### é”™è¯¯ 7: `PermissionDenied: Tool 'bash' blocked by HITLHook`

**åŸå› **: HITL Hook é˜»æ­¢äº†å·¥å…·æ‰§è¡Œ

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥ ask_handler è¿”å›å€¼
hitl = HITLHook(
    dangerous_tools=["bash"],
    ask_handler=lambda msg: input(f"{msg} (y/n): ") == "y"  # ç¡®ä¿è¿”å› bool
)

# æˆ–ä¸´æ—¶å…è®¸æ‰€æœ‰æ“ä½œï¼ˆå¼€å‘ç¯å¢ƒï¼‰
hitl = HITLHook(
    dangerous_tools=[],  # ç©ºåˆ—è¡¨ = ä¸æ‹¦æˆªä»»ä½•å·¥å…·
)
```

---

### é”™è¯¯ 8: `MemoryError: Failed to save to disk`

**åŸå› **: ç£ç›˜ç©ºé—´ä¸è¶³æˆ–æƒé™é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥ç£ç›˜ç©ºé—´
import shutil
free_space = shutil.disk_usage(".").free / (1024**3)
print(f"Free space: {free_space:.2f} GB")

# æ£€æŸ¥æƒé™
from pathlib import Path
persist_dir = Path(".loom")
persist_dir.mkdir(parents=True, exist_ok=True)

# æ£€æŸ¥æŒä¹…åŒ–ä¿¡æ¯
memory = PersistentMemory()
info = memory.get_persistence_info()
print(info)
```

---

## ğŸ”§ ç³»ç»ŸåŒ–è°ƒè¯•æ£€æŸ¥æ¸…å•

### Leve 1: åŸºç¡€é…ç½®æ£€æŸ¥

```
[ ] 1. Python ç‰ˆæœ¬ >= 3.9
[ ] 2. loom-agent å·²å®‰è£… (pip list | grep loom)
[ ] 3. ä¾èµ–åŒ…å·²å®‰è£… (openai, anthropic ç­‰)
[ ] 4. API key å·²è®¾ç½® (echo $OPENAI_API_KEY)
[ ] 5. ç½‘ç»œè¿æ¥æ­£å¸¸ (ping api.openai.com)
```

**éªŒè¯è„šæœ¬**:
```bash
python -c "
import sys
print(f'Python: {sys.version}')
try:
    import loom
    print(f'loom-agent: {loom.__version__}')
except ImportError:
    print('loom-agent: NOT INSTALLED')
import os
print(f'OPENAI_API_KEY: {\"SET\" if os.getenv(\"OPENAI_API_KEY\") else \"NOT SET\"}')"
```

---

### Level 2: Agent é…ç½®æ£€æŸ¥

```
[ ] 1. LLM é…ç½®æ­£ç¡®
[ ] 2. å·¥å…·å·²æ³¨å†Œ
[ ] 3. system_instructions æ¸…æ™°
[ ] 4. max_iterations åˆç†
[ ] 5. max_context_tokens è¶³å¤Ÿ
[ ] 6. Memory é…ç½®æ­£ç¡®ï¼ˆå¦‚éœ€è¦ï¼‰
[ ] 7. Hooks é…ç½®æ­£ç¡®ï¼ˆå¦‚éœ€è¦ï¼‰
```

**éªŒè¯è„šæœ¬**:
```python
# agent_config_check.py
from loom import agent
from loom.builtin.tools import ReadFileTool

my_my_agent = loom.agent(
    provider="openai",
    model="gpt-4",
    tools=[ReadFileTool()],
    max_iterations=50,
    max_context_tokens=8000
)

# æ£€æŸ¥é…ç½®
print(f"LLM: {my_agent.executor.llm}")
print(f"Tools: {list(my_agent.executor.tools.keys())}")
print(f"Max iterations: {my_agent.executor.max_iterations}")
print(f"Max context tokens: {my_agent.executor.max_context_tokens}")
```

---

### Level 3: æ‰§è¡Œæµç¨‹è°ƒè¯•

å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼š

```python
from loom import agent
from loom.core.lifecycle_hooks import LoggingHook
from loom.core.events import AgentEventType
from pathlib import Path

# æ–¹å¼ 1: LoggingHook
logging_hook = LoggingHook(
    log_level="DEBUG",
    log_file=Path("./agent_debug.log")
)

my_my_agent = loom.agent(
    llm=llm,
    tools=tools,
    hooks=[logging_hook]
)

# æ–¹å¼ 2: æ‰‹åŠ¨äº‹ä»¶ç›‘å¬
async for event in my_agent.execute("task"):
    print(f"[{event.type}] {event.metadata}")
    
    if event.type == AgentEventType.ERROR:
        print(f"ERROR: {event.error}")
        import traceback
        traceback.print_exc()
```

---

### Level 4: ä¸Šä¸‹æ–‡è°ƒè¯•

```python
from loom.core import ContextDebugger

debugger = ContextDebugger(enable_auto_export=True)

my_my_agent = loom.agent(
    llm=llm,
    tools=tools,
    context_debugger=debugger
)

await my_agent.run("task")

# ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
print(debugger.generate_summary())

# æ£€æŸ¥ç‰¹å®šè¿­ä»£
print(debugger.explain_iteration(5))

# æ£€æŸ¥ç‰¹å®šç»„ä»¶
print(debugger.explain_component("file_content"))
```

---

### Level 5: æ€§èƒ½åˆ†æ

```python
from loom.core.lifecycle_hooks import LifecycleHook
import time

class PerformanceHook(LifecycleHook):
    """æ€§èƒ½åˆ†æ Hook"""
    
    def __init__(self):
        self.metrics = {
            "llm_calls": 0,
            "llm_total_time": 0,
            "tool_calls": {},
            "iterations": 0
        }
        self._llm_start = None
    
    async def before_llm_call(self, frame, messages):
        self._llm_start = time.time()
        self.metrics["llm_calls"] += 1
        return None
    
    async def after_llm_response(self, frame, response):
        if self._llm_start:
            elapsed = time.time() - self._llm_start
            self.metrics["llm_total_time"] += elapsed
        return None
    
    async def before_tool_execution(self, frame, tool_call):
        tool_name = tool_call.get("name", "unknown")
        if tool_name not in self.metrics["tool_calls"]:
            self.metrics["tool_calls"][tool_name] = 0
        self.metrics["tool_calls"][tool_name] += 1
        return None
    
    async def after_iteration_end(self, frame, result):
        self.metrics["iterations"] += 1
        return None
    
    def report(self):
        print("\n" + "=" * 60)
        print("æ€§èƒ½æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ€»è¿­ä»£æ¬¡æ•°: {self.metrics['iterations']}")
        print(f"LLM è°ƒç”¨æ¬¡æ•°: {self.metrics['llm_calls']}")
        print(f"LLM æ€»è€—æ—¶: {self.metrics['llm_total_time']:.2f}s")
        print(f"å¹³å‡ LLM è€—æ—¶: {self.metrics['llm_total_time'] / max(self.metrics['llm_calls'], 1):.2f}s")
        print(f"\nå·¥å…·ä½¿ç”¨ç»Ÿè®¡:")
        for tool, count in self.metrics["tool_calls"].items():
            print(f"  - {tool}: {count} æ¬¡")
        print("=" * 60)

# ä½¿ç”¨
perf = PerformanceHook()
my_my_agent = loom.agent(llm=llm, tools=tools, hooks=[perf])
await my_agent.run("task")
perf.report()
```

---

## ğŸ“Š é—®é¢˜åˆ†ç±»å’Œè§£å†³æ–¹æ¡ˆ

### ç±»åˆ« 1: é…ç½®é—®é¢˜

| ç—‡çŠ¶ | æ ¹å›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| Agent ä¸å¯åŠ¨ | LLM é…ç½®é”™è¯¯ | æ£€æŸ¥ provider, model, api_key |
| å·¥å…·æ— æ³•ä½¿ç”¨ | å·¥å…·æœªæ³¨å†Œ | æ·»åŠ åˆ° tools=[] |
| æƒé™é”™è¯¯ | HITLHook æ‹¦æˆª | é…ç½® ask_handler æˆ–ç§»é™¤æ‹¦æˆª |

---

### ç±»åˆ« 2: æ‰§è¡Œé—®é¢˜

| ç—‡çŠ¶ | æ ¹å›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| è¶…è¿‡æœ€å¤§è¿­ä»£ | æ­»å¾ªç¯æˆ–ä»»åŠ¡å¤ªå¤æ‚ | å¢åŠ  max_iterations æˆ–ä¼˜åŒ–æŒ‡ä»¤ |
| æ— è¾“å‡º | å¿˜è®° await | ä½¿ç”¨ await agent.run() |
| Crash | æœªæ•è·å¼‚å¸¸ | æ·»åŠ  try-exceptï¼Œæ£€æŸ¥æ—¥å¿— |

---

### ç±»åˆ« 3: æ€§èƒ½é—®é¢˜

| ç—‡çŠ¶ | æ ¹å›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| å“åº”æ…¢ | æ¨¡å‹å¤ªå¤§ | ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚ gpt-3.5-turboï¼‰ |
| Token ä½¿ç”¨é«˜ | ä¸Šä¸‹æ–‡å¤ªå¤§ | å¯ç”¨å‹ç¼©ï¼Œä¼˜åŒ–ç»„ä»¶ä¼˜å…ˆçº§ |
| å†…å­˜å ç”¨é«˜ | å†å²æ¶ˆæ¯å¤ªå¤š | å®šæœŸæ¸…ç† memory |

---

### ç±»åˆ« 4: ä¸Šä¸‹æ–‡é—®é¢˜

| ç—‡çŠ¶ | æ ¹å›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| Token è¶…é™ | ä¸Šä¸‹æ–‡å¤ªå¤§ | å¯ç”¨ CompressionManager |
| ä¸Šä¸‹æ–‡ä¸¢å¤± | å‹ç¼©è¿‡åº¦ | è°ƒæ•´ compression_threshold |
| ç»„ä»¶è¢«æ’é™¤ | ä¼˜å…ˆçº§å¤ªä½ | æé«˜ä¼˜å…ˆçº§æˆ–å¢åŠ  budget |

---

## ğŸ’¡ è°ƒè¯•æŠ€å·§

### æŠ€å·§ 1: ä½¿ç”¨æµå¼APIæŸ¥çœ‹å®æ—¶è¿›åº¦

```python
async for event in agent.execute("task"):
    print(f"[{event.timestamp:.2f}] {event.type}: {event.metadata}")
```

### æŠ€å·§ 2: ä¿å­˜äº‹ä»¶æ—¥å¿—ç”¨äºç¦»çº¿åˆ†æ

```python
events = []
async for event in agent.execute("task"):
    events.append(event)

# ä¿å­˜åˆ°æ–‡ä»¶
import json
with open("events.json", "w") as f:
    json.dump([e.__dict__ for e in events], f, indent=2, default=str)
```

### æŠ€å·§ 3: ä½¿ç”¨ ContextDebugger å¯è§†åŒ–ä¸Šä¸‹æ–‡

```python
debugger = ContextDebugger(enable_auto_export=True)
agent(llm=llm, context_debugger=debugger)

# æ‰§è¡ŒåæŸ¥çœ‹
print(debugger.generate_summary())
```

### æŠ€å·§ 4: åˆ›å»ºæœ€å°å¤ç°æ¡ˆä¾‹

```python
# minimal_repro.py
import asyncio
from loom import agent

async def main():
    # æœ€ç®€é…ç½®
    my_my_agent = loom.agent(provider="openai", model="gpt-4")
    
    # æœ€ç®€ä»»åŠ¡
    result = await my_agent.run("Hello")
    print(result)

asyncio.run(main())
```

---

## ğŸ†˜ è·å–å¸®åŠ©

### 1. æ£€æŸ¥æ–‡æ¡£
- Quick Reference: `docs/user/quick-reference.md`
- User Guide: `docs/user/user-guide.md`
- API Reference: `docs/user/api-reference.md`

### 2. æŸ¥çœ‹ç¤ºä¾‹
- å®Œæ•´ç¤ºä¾‹: `examples/complete/`
- é›†æˆç¤ºä¾‹: `examples/integrations/`

### 3. æäº¤ Issue
GitHub: https://github.com/your-org/loom-agent/issues

**æäº¤æ—¶è¯·åŒ…å«**:
- loom-agent ç‰ˆæœ¬
- Python ç‰ˆæœ¬
- æœ€å°å¤ç°æ¡ˆä¾‹
- å®Œæ•´é”™è¯¯å †æ ˆ
- ç›¸å…³æ—¥å¿—

---

**Version**: v0.1.1  
**Last Updated**: 2024-12-12  
**License**: MIT
