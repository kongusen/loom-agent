# LLM Providers è¿ç§»å®Œæˆ âœ…

## æ¦‚è§ˆ

æˆåŠŸè¿ç§»äº† 12 ä¸ª LLM Providersï¼ŒåŸºäº OpenAI å…¼å®¹ API æ¶æ„ï¼Œå®ç°äº†ç»Ÿä¸€ã€ç®€æ´çš„é…ç½®æ–¹å¼ã€‚

---

## è¿ç§»çš„ Providers

### 1. OpenAI å…¼å®¹åŸºç±»

**loom/providers/llm/openai_compatible.py** (73 è¡Œ)

```python
class OpenAICompatibleProvider(OpenAIProvider):
    """OpenAI å…¼å®¹ Provider åŸºç±»"""
    DEFAULT_BASE_URL: str | None = None
    DEFAULT_MODEL: str | None = None
    API_KEY_ENV_VAR: str | None = None
    PROVIDER_NAME: str = "OpenAI Compatible"
```

**ç‰¹ç‚¹**ï¼š
- ç»§æ‰¿è‡ª OpenAIProvider
- å­ç±»åªéœ€å®šä¹‰ç±»å±æ€§
- è‡ªåŠ¨å¤„ç†ç¯å¢ƒå˜é‡è¯»å–
- æ”¯æŒè‡ªå®šä¹‰ base_url å’Œ model

---

### 2. å›½å†… LLM Providers (5ä¸ª)

#### DeepSeek
```python
class DeepSeekProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "https://api.deepseek.com/v1"
    DEFAULT_MODEL = "deepseek-chat"
    API_KEY_ENV_VAR = "DEEPSEEK_API_KEY"
```

#### Qwen (é€šä¹‰åƒé—®)
```python
class QwenProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    DEFAULT_MODEL = "qwen-plus"
    API_KEY_ENV_VAR = "DASHSCOPE_API_KEY"
```

#### Zhipu (æ™ºè°±AI)
```python
class ZhipuProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "https://open.bigmodel.cn/api/paas/v4"
    DEFAULT_MODEL = "glm-4-plus"
    API_KEY_ENV_VAR = "ZHIPU_API_KEY"
```

#### Kimi (æœˆä¹‹æš—é¢)
```python
class KimiProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "https://api.moonshot.cn/v1"
    DEFAULT_MODEL = "moonshot-v1-8k"
    API_KEY_ENV_VAR = "MOONSHOT_API_KEY"
```

#### Doubao (è±†åŒ…)
```python
class DoubaoProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
    DEFAULT_MODEL = "doubao-pro-32k"
    API_KEY_ENV_VAR = "DOUBAO_API_KEY"
```

---

### 3. æœ¬åœ°éƒ¨ç½² Providers (3ä¸ª)

#### Ollama
```python
class OllamaProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "http://localhost:11434/v1"
    DEFAULT_MODEL = "llama3.2"
    API_KEY_ENV_VAR = None  # ä¸éœ€è¦ API key
```

#### vLLM
```python
class VLLMProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "http://localhost:8000/v1"
    DEFAULT_MODEL = "meta-llama/Llama-3.2-3B-Instruct"
    API_KEY_ENV_VAR = "VLLM_API_KEY"
```

#### GPU Stack
```python
class GPUStackProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "http://localhost:8080/v1"
    DEFAULT_MODEL = "llama3.2"
    API_KEY_ENV_VAR = "GPUSTACK_API_KEY"
```

---

### 4. è¾…åŠ© Providers (3ä¸ª)

#### CustomProvider
é€šç”¨çš„è‡ªå®šä¹‰ Providerï¼Œæ”¯æŒä»»æ„ OpenAI å…¼å®¹çš„ APIã€‚

#### MockLLMProvider
æµ‹è¯•ç”¨çš„ Mock Providerï¼Œè¿”å›é¢„è®¾å“åº”ï¼Œæ— éœ€ API keyã€‚

#### retry_handler
æ™ºèƒ½é‡è¯•æœºåˆ¶ï¼Œå¤„ç†é€Ÿç‡é™åˆ¶ã€ç½‘ç»œé”™è¯¯ã€è¶…æ—¶ç­‰ã€‚

---

## å¦‚ä½•é€šè¿‡ API é…ç½® Provider

### æ–¹å¼ 1: ç›´æ¥åˆ›å»º Provider å®ä¾‹

è¿™æ˜¯**æ¨èçš„æ–¹å¼**ï¼Œç±»å‹å®‰å…¨ã€çµæ´»ã€å¯å¤ç”¨ã€‚

```python
from loom.providers.llm import DeepSeekProvider

# æ˜¾å¼æä¾› API key
provider = DeepSeekProvider(
    api_key="sk-...",
    model="deepseek-chat",
    temperature=0.7
)

# æˆ–ä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆæ¨èï¼‰
# export DEEPSEEK_API_KEY="sk-..."
provider = DeepSeekProvider(model="deepseek-chat")
```

### æ–¹å¼ 2: åœ¨ä¸‰å±‚ API ä¸­ä½¿ç”¨

#### Level 1 - Wave API
```python
from loom.api import wave
from loom.providers.llm import QwenProvider

provider = QwenProvider(api_key="sk-...")
agent = wave(
    agent_id="my-agent",
    name="My Agent",
    llm_provider=provider
)
```

#### Level 2 - Loom API
```python
from loom.api import Loom
from loom.providers.llm import ZhipuProvider

loom = Loom()
provider = ZhipuProvider(api_key="...")

agent = loom.create_agent(
    agent_id="my-agent",
    name="My Agent",
    llm_provider=provider
)
```

#### Level 3 - Builder API
```python
from loom.api import LoomBuilder
from loom.providers.llm import KimiProvider

provider = KimiProvider(api_key="...")

components = (
    LoomBuilder()
    .with_llm_provider(provider)  # è®¾ç½®é»˜è®¤ provider
    .build()
)

# æ‰€æœ‰ agent é»˜è®¤ä½¿ç”¨è¿™ä¸ª provider
agent1 = components.create_agent(agent_id="agent1", name="Agent 1")

# ä¹Ÿå¯ä»¥ä¸ºç‰¹å®š agent è¦†ç›– provider
from loom.providers.llm import DeepSeekProvider
agent2 = components.create_agent(
    agent_id="agent2",
    name="Agent 2",
    llm_provider=DeepSeekProvider(api_key="...")
)
```

---

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: ä½¿ç”¨å›½å†… LLM

```python
from loom.api import wave
from loom.providers.llm import DeepSeekProvider

# åˆ›å»º DeepSeek provider
provider = DeepSeekProvider(
    api_key="sk-...",
    model="deepseek-chat",
    temperature=0.7
)

# åˆ›å»º agent
agent = wave(
    agent_id="deepseek-agent",
    name="DeepSeek Agent",
    llm_provider=provider
)
```

### ç¤ºä¾‹ 2: ä½¿ç”¨æœ¬åœ° Ollama

```python
from loom.api import wave
from loom.providers.llm import OllamaProvider

# Ollama ä¸éœ€è¦ API key
provider = OllamaProvider(
    model="llama3.2",
    base_url="http://localhost:11434/v1"
)

agent = wave(
    agent_id="local-agent",
    name="Local Agent",
    llm_provider=provider
)
```

### ç¤ºä¾‹ 3: å¤š Provider ç³»ç»Ÿ

```python
from loom.api import Loom
from loom.providers.llm import (
    DeepSeekProvider,
    QwenProvider,
    ZhipuProvider
)

loom = Loom()

# åˆ›å»ºä¸åŒçš„ providers
deepseek = DeepSeekProvider(api_key="...")
qwen = QwenProvider(api_key="...")
zhipu = ZhipuProvider(api_key="...")

# åˆ›å»ºä½¿ç”¨ä¸åŒ provider çš„ agents
agent1 = loom.create_agent(
    agent_id="deepseek-agent",
    name="DeepSeek Agent",
    llm_provider=deepseek
)

agent2 = loom.create_agent(
    agent_id="qwen-agent",
    name="Qwen Agent",
    llm_provider=qwen
)

agent3 = loom.create_agent(
    agent_id="zhipu-agent",
    name="Zhipu Agent",
    llm_provider=zhipu
)
```

### ç¤ºä¾‹ 4: è‡ªå®šä¹‰ Provider

```python
from loom.providers.llm import CustomProvider

# è¿æ¥åˆ°ä»»æ„ OpenAI å…¼å®¹çš„ API
provider = CustomProvider(
    model="custom-model",
    base_url="https://api.example.com/v1",
    api_key="your-api-key"
)
```

### ç¤ºä¾‹ 5: æµ‹è¯•ç”¨ Mock Provider

```python
from loom.providers.llm import MockLLMProvider

# æ— éœ€ API keyï¼Œç”¨äºæµ‹è¯•
provider = MockLLMProvider()

agent = wave(
    agent_id="test-agent",
    name="Test Agent",
    llm_provider=provider
)
```

---

## ç¯å¢ƒå˜é‡é…ç½®

æ‰€æœ‰ providers éƒ½æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å– API keyï¼š

```bash
# å›½å†… LLM
export DEEPSEEK_API_KEY="sk-..."
export DASHSCOPE_API_KEY="sk-..."  # Qwen
export ZHIPU_API_KEY="..."
export MOONSHOT_API_KEY="sk-..."   # Kimi
export DOUBAO_API_KEY="..."

# æœ¬åœ°éƒ¨ç½²
export VLLM_API_KEY="..."
export GPUSTACK_API_KEY="..."
```

ç„¶ååœ¨ä»£ç ä¸­æ— éœ€æ˜¾å¼æä¾› API keyï¼š

```python
from loom.providers.llm import DeepSeekProvider

# è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å– DEEPSEEK_API_KEY
provider = DeepSeekProvider(model="deepseek-chat")
```

---

## ä»£ç ç»Ÿè®¡

| Provider | æ–‡ä»¶ | è¡Œæ•° | è¯´æ˜ |
|----------|------|------|------|
| OpenAICompatibleProvider | openai_compatible.py | 73 | åŸºç±» |
| DeepSeekProvider | deepseek.py | 27 | å›½å†… LLM |
| QwenProvider | qwen.py | 27 | å›½å†… LLM |
| ZhipuProvider | zhipu.py | 27 | å›½å†… LLM |
| KimiProvider | kimi.py | 27 | å›½å†… LLM |
| DoubaoProvider | doubao.py | 27 | å›½å†… LLM |
| OllamaProvider | ollama.py | 33 | æœ¬åœ°éƒ¨ç½² |
| VLLMProvider | vllm.py | 33 | æœ¬åœ°éƒ¨ç½² |
| GPUStackProvider | gpustack.py | 33 | æœ¬åœ°éƒ¨ç½² |
| CustomProvider | custom.py | 63 | é€šç”¨ |
| MockLLMProvider | mock.py | 82 | æµ‹è¯• |
| retry_handler | retry_handler.py | 124 | è¾…åŠ©å·¥å…· |
| **æ€»è®¡** | **12 æ–‡ä»¶** | **576 è¡Œ** | **å®Œæ•´å®ç°** |

---

## å…³é”®ç‰¹æ€§

### 1. ç»Ÿä¸€çš„é…ç½®æ–¹å¼

æ‰€æœ‰ providers ä½¿ç”¨ç›¸åŒçš„é…ç½®æ¨¡å¼ï¼š

```python
provider = SomeProvider(
    api_key="...",      # å¯é€‰ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–
    model="...",        # å¯é€‰ï¼Œä½¿ç”¨é»˜è®¤å€¼
    base_url="...",     # å¯é€‰ï¼Œä½¿ç”¨é»˜è®¤å€¼
    temperature=0.7,    # å¯é€‰
    max_tokens=None     # å¯é€‰
)
```

### 2. ç¯å¢ƒå˜é‡æ”¯æŒ

æ‰€æœ‰ providers è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å– API keyï¼Œæ— éœ€ç¡¬ç¼–ç ã€‚

### 3. ç±»å‹å®‰å…¨

IDE å¯ä»¥æä¾›è‡ªåŠ¨è¡¥å…¨å’Œç±»å‹æ£€æŸ¥ã€‚

### 4. å¯å¤ç”¨

åŒä¸€ä¸ª provider å®ä¾‹å¯ä»¥ç”¨äºå¤šä¸ª agentsã€‚

### 5. ç®€æ´çš„å­ç±»åŒ–

æ–°å¢ provider åªéœ€å®šä¹‰ç±»å±æ€§ï¼š

```python
class NewProvider(OpenAICompatibleProvider):
    DEFAULT_BASE_URL = "https://api.new.com/v1"
    DEFAULT_MODEL = "new-model"
    API_KEY_ENV_VAR = "NEW_API_KEY"
    PROVIDER_NAME = "New Provider"
```

---

## ä¸æ—§å®ç°å¯¹æ¯”

| ç‰¹æ€§ | æ—§å®ç° | æ–°å®ç° |
|------|--------|--------|
| é…ç½®æ–¹å¼ | LLMConfig + ConnectionConfig + GenerationConfig | ç›´æ¥ä¼ å‚ |
| ä»£ç é‡ | ~920 è¡Œ | ~576 è¡Œ (-37%) |
| å­ç±»åŒ– | éœ€è¦é‡å†™ __init__ | åªéœ€å®šä¹‰ç±»å±æ€§ |
| ç¯å¢ƒå˜é‡ | æ‰‹åŠ¨å¤„ç† | è‡ªåŠ¨å¤„ç† |
| ç±»å‹å®‰å…¨ | âš ï¸ | âœ… |
| æ˜“ç”¨æ€§ | ä¸­ç­‰ | é«˜ |

---

## ä¸‹ä¸€æ­¥

### å·²å®Œæˆ
- âœ… P0-1: Memory System
- âœ… P0-2: Fractal Synthesizer
- âœ… P0-3: Tool Execution
- âœ… P0-4: LLM Providers (æ ¸å¿ƒ 3 ä¸ª)
- âœ… P0-5: Loom API
- âœ… **LLM Providers è¿ç§» (12 ä¸ª)**

### å»ºè®®
1. **æµ‹è¯•éªŒè¯** - ä¸ºæ‰€æœ‰ providers ç¼–å†™å•å…ƒæµ‹è¯•
2. **æ–‡æ¡£å®Œå–„** - æ·»åŠ æ›´å¤šä½¿ç”¨ç¤ºä¾‹
3. **æ€§èƒ½ä¼˜åŒ–** - åˆ†æå’Œä¼˜åŒ– provider æ€§èƒ½
4. **åŠŸèƒ½æ‰©å±•** - æ·»åŠ æ›´å¤šé«˜çº§åŠŸèƒ½ï¼ˆå¦‚ç¼“å­˜ã€æ‰¹å¤„ç†ç­‰ï¼‰

---

## ç»“è®º

âœ… **LLM Providers è¿ç§»å®Œæˆ**

æˆåŠŸè¿ç§»äº† 12 ä¸ª LLM Providersï¼Œå®ç°äº†ï¼š
- ç»Ÿä¸€çš„é…ç½®æ–¹å¼
- ç®€æ´çš„ä»£ç ç»“æ„
- å®Œæ•´çš„åŠŸèƒ½æ”¯æŒ
- ä¼˜ç§€çš„å¯æ‰©å±•æ€§

**ä»£ç è´¨é‡**ï¼š
- 576 è¡Œæ–°ä»£ç 
- æ¯”æ—§å®ç°å‡å°‘ 37%
- æ›´æ˜“ç»´æŠ¤å’Œæ‰©å±•
- å®Œæ•´çš„ç±»å‹æ”¯æŒ

**æ”¯æŒçš„ Providers**ï¼š
- 3 ä¸ªæ ¸å¿ƒ providers (OpenAI, Anthropic, Gemini)
- 5 ä¸ªå›½å†… LLM providers
- 3 ä¸ªæœ¬åœ°éƒ¨ç½² providers
- 3 ä¸ªè¾…åŠ© providers
- **æ€»è®¡ 14 ä¸ª providers** ğŸš€
