# Loom Agent Framework

> ‰∏ã‰∏Ä‰ª£‰∏ä‰∏ãÊñáÂ∑•Á®ãÈ©±Âä®ÁöÑÊô∫ËÉΩÂä©ÁêÜÊ°ÜÊû∂ÔºàÂØπÊ†á LangChainÔºâÔºåÊîØÊåÅÂ∑•ÂÖ∑ÊµÅÊ∞¥Á∫ø„ÄÅRAG„ÄÅÂπ∂ÂèëË∞ÉÂ∫¶‰∏éÊµÅÂºè‰∫ã‰ª∂„ÄÇ

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## üöÄ Key Features

- **ü§ñ Multi-Agent Orchestration**: Coordinate multiple specialized agents working together
- **üß† Intelligent Context Management**: Automatic context optimization and memory management  
- **üîß Rich Tool Ecosystem**: Built-in tools for file operations, knowledge bases, code execution
- **üåä Streaming Processing**: Real-time data processing and response streaming
- **üîí Security First**: Built-in security checks and permission controls
- **‚ö° High Performance**: Asynchronous architecture with concurrent processing
- **üîå Extensible**: Modular design for easy customization and extension
- **üåê LLM Integration**: Support for multiple LLM providers (OpenAI, Anthropic, etc.)

## üèóÔ∏è Architecture

```
loom/
‚îú‚îÄ‚îÄ interfaces/   # ÊäΩË±°Êé•Âè£ (LLM/Tool/Memory/...)
‚îú‚îÄ‚îÄ core/         # ÊâßË°åÂÜÖÊ†∏ (AgentExecutor/ToolPipeline/RAG/...)
‚îú‚îÄ‚îÄ components/   # È´òÂ±ÇÊûÑ‰ª∂ (Agent/Chain/Router/Workflow)
‚îú‚îÄ‚îÄ llm/          # LLM Â≠êÁ≥ªÁªü (config/factory/pool/registry)
‚îú‚îÄ‚îÄ builtin/      # ÂÜÖÁΩÆ LLM/Tools/Memory/Retriever
‚îú‚îÄ‚îÄ patterns/     # Â∏∏Áî®Ê®°Âºè (RAG/Multi-Agent)
‚îî‚îÄ‚îÄ docs/         # ÊñáÊ°£
```

## üì¶ Installation

```bash
# Clone the repository
git clone https://github.com/your-org/loom-agent.git
cd loom-agent

# Install dependencies
pip install -r requirements.txt

# Or install in development mode
pip install -e .
```

## üèÉ‚Äç‚ôÇÔ∏è Quick Start

```python
import asyncio
import loom
from loom.builtin.llms import MockLLM

async def main():
    agent = loom.agent(llm=MockLLM(responses=["Hello from Loom!"]))
    print(await agent.ainvoke("Say hello"))

if __name__ == "__main__":
    asyncio.run(main())
```

### Tool Usage Example (decorator)

```python
import loom
from typing import List

@loom.tool(description="Sum a list of numbers")
def sum_list(nums: List[float]) -> float:
    return sum(nums)

SumTool = sum_list
agent = loom.agent(provider="openai", model="gpt-4o", tools=[SumTool()])
```

## üîß Core Components

### Agents
- **Agent Controller**: Manages agent lifecycle and coordination
- **Agent Registry**: Agent discovery and capability matching
- **Specialization**: Domain-specific agent behaviors

### Context Management  
- **Context Retrieval**: Intelligent context gathering
- **Context Processing**: Context optimization and compression
- **Memory Management**: Persistent and session memory

### Tool System
- **Tool Registry**: Centralized tool management
- **Tool Executor**: Safe tool execution with monitoring
- **Tool Scheduler**: Intelligent tool scheduling and orchestration

### Orchestration
- **Orchestration Engine**: Multi-agent workflow coordination
- **Strategy System**: Pluggable orchestration strategies
- **Event Coordination**: Inter-agent communication

### Streaming
- **Stream Processor**: Real-time data processing
- **Stream Pipeline**: Multi-stage processing pipelines
- **Stream Optimizer**: Performance optimization

## üõ†Ô∏è Built-in Tools

| Tool | Description | Safety Level |
|------|-------------|--------------|
| **File System** | File operations (read, write, list) | Cautious |
| **Knowledge Base** | Document storage and search | Safe |
| **Code Interpreter** | Code execution (Python, JS, Bash) | Exclusive |
| **Web Search** | Web information retrieval | Safe |

## üåê LLM Integration

The framework supports multiple LLM providers:

```python
# Environment configuration
export LLM_API_KEY="your-api-key"
export LLM_BASE_URL="https://api.openai.com/v1"  
export LLM_MODEL="gpt-3.5-turbo"

# Supported providers:
# - OpenAI (GPT-3.5, GPT-4)
# - Anthropic (Claude-3)
# - Azure OpenAI
# - Local models (Ollama, etc.)
```

## üìö Documentation

- Quickstart: `loom/docs/QUICKSTART.md`
- Framework Overview: `loom/docs/README_LOOM.md`
- Callbacks Spec: `loom/docs/CALLBACKS_SPEC.md`
- Examples: `examples/`

## üîí Security

The framework implements multiple security layers:

- **Path Traversal Protection**: Prevents unauthorized file access
- **Code Execution Sandboxing**: Safe code execution environment
- **Permission-based Access**: Granular permission controls
- **Input Validation**: Comprehensive input sanitization

## üìä Performance

- **Concurrent Agent Support**: 100+ agents simultaneously
- **Tool Execution**: Sub-second response times
- **Memory Efficiency**: Optimized context management
- **Streaming Throughput**: 1000+ events/second

## ü§ù Contributing

We welcome contributions! Please see our contributing guidelines for details.

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Inspired by modern multi-agent systems research
- Built with Python's async/await ecosystem
- Designed for production scalability

---

**Built with ‚ù§Ô∏è for the AI community**
