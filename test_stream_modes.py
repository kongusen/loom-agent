"""
æµ‹è¯•æµå¼è¾“å‡ºåœ¨ä¸åŒæ¨¡å¼ä¸‹çš„è¡¨ç°
1. Crewä¸²è¡Œæ¨¡å¼ - å­agentæ€è€ƒè¿‡ç¨‹æµå¼æ˜¾ç¤º
2. å¹¶è¡Œæ¨¡å¼ - ç»“æœæµå¼æ˜¾ç¤º
3. ReActèŒƒå¼ - æ•´ä¸ªæ¨ç†è¿‡ç¨‹æµå¼æ˜¾ç¤º
"""
import asyncio
import os
from loom import LoomBuilder
from loom.llm import OpenAIProvider
from loom.kernel.core import UniversalEventBus, Dispatcher
from loom.protocol.cloudevents import CloudEvent

# è®¾ç½®OpenAIå‡­è¯
os.environ["OPENAI_API_KEY"] = "sk-Fy6Y5WV5eugN61DhxH1AjI8th71OWfopqA2OCj5t93UIZ6aF"
os.environ["OPENAI_MODEL"] = "gpt-4o-mini"
os.environ["OPENAI_BASE_URL"] = "https://xiaoai.plus/v1"

# æµå¼è¾“å‡ºäº‹ä»¶ç›‘å¬å™¨
class StreamEventListener:
    """ç›‘å¬å¹¶æ˜¾ç¤ºæµå¼è¾“å‡ºäº‹ä»¶"""

    async def on_stream_text(self, event: CloudEvent):
        """å¤„ç†æ–‡æœ¬æµå¼è¾“å‡º"""
        text = event.data.get("content", "")
        print(text, end="", flush=True)

    async def on_stream_done(self, event: CloudEvent):
        """å¤„ç†æµå¼è¾“å‡ºç»“æŸ"""
        print()  # æ¢è¡Œ

    async def on_stream_tool_call_start(self, event: CloudEvent):
        """å¤„ç†å·¥å…·è°ƒç”¨å¼€å§‹"""
        tool_name = event.data.get("tool_name", "")
        print(f"\nğŸ”§ [è°ƒç”¨å·¥å…·: {tool_name}]", flush=True)

    async def on_stream_error(self, event: CloudEvent):
        """å¤„ç†æµå¼è¾“å‡ºé”™è¯¯"""
        error = event.data.get("error", "")
        print(f"\nâŒ [é”™è¯¯: {error}]", flush=True)

print("=" * 60)
print("æµ‹è¯•1: Crewä¸²è¡Œæ¨¡å¼ - æµå¼è¾“å‡º")
print("=" * 60)

async def test_crew_serial_stream():
    """æµ‹è¯•Crewä¸²è¡Œæ¨¡å¼ä¸‹çš„æµå¼è¾“å‡º"""
    print("\nğŸ”§ åˆ›å»ºåŸºç¡€è®¾æ–½...")
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºå¹¶æ³¨å†Œæµå¼è¾“å‡ºç›‘å¬å™¨ï¼ˆä½¿ç”¨é€šé…ç¬¦è®¢é˜…ï¼‰
    listener = StreamEventListener()
    await bus.subscribe("agent.stream.text/*", listener.on_stream_text)
    await bus.subscribe("agent.stream.done/*", listener.on_stream_done)
    await bus.subscribe("agent.stream.tool_call_start/*", listener.on_stream_tool_call_start)
    await bus.subscribe("agent.stream.error/*", listener.on_stream_error)
    print("âœ… æµå¼è¾“å‡ºç›‘å¬å™¨å·²æ³¨å†Œ")

    # åˆ›å»ºå¯ç”¨æµå¼è¾“å‡ºçš„OpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=True  # å¯ç”¨æµå¼è¾“å‡º
    )
    print(f"âœ… Provideråˆ›å»ºæˆåŠŸ (stream=True)")

    print("\nğŸ”§ åˆ›å»ºCrewæˆå‘˜...")
    # Agent 1: Researcher
    researcher = (LoomBuilder()
        .with_id('researcher')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_agent(
            role='Researcher',
            system_prompt='You are a researcher. Gather information and facts about the topic.'
        )
        .build())
    print(f"âœ… Researcheråˆ›å»ºæˆåŠŸ")

    # Agent 2: Analyst
    analyst = (LoomBuilder()
        .with_id('analyst')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_agent(
            role='Analyst',
            system_prompt='You are an analyst. Analyze information and draw insights.'
        )
        .build())
    print(f"âœ… Analyståˆ›å»ºæˆåŠŸ")

    # Agent 3: Writer
    writer = (LoomBuilder()
        .with_id('writer')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_agent(
            role='Writer',
            system_prompt='You are a writer. Write clear and engaging content.'
        )
        .build())
    print(f"âœ… Writeråˆ›å»ºæˆåŠŸ")

    # å¼€å§‹ä¸²è¡Œåä½œä»»åŠ¡
    topic = "AI Agentçš„æœªæ¥å‘å±•"
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ Crewä»»åŠ¡: {topic}")
    print(f"{'='*60}")

    # Step 1: Researcheræ”¶é›†ä¿¡æ¯
    print(f"\nğŸ” [Step 1] Researcherå¼€å§‹æ”¶é›†ä¿¡æ¯...")
    print("ğŸ’­ æ€è€ƒè¿‡ç¨‹:")
    research_event = CloudEvent(
        type="node.request",
        source="coordinator",
        data={"content": f"Research the topic: {topic}. Provide key facts."}
    )
    research_result = await researcher.process(research_event)
    print(f"\nâœ… Researchå®Œæˆ")
    print(f"ğŸ“„ ç»“æœ: {research_result[:150]}...")

    # Step 2: Analyståˆ†æä¿¡æ¯
    print(f"\nğŸ“Š [Step 2] Analystå¼€å§‹åˆ†æ...")
    print("ğŸ’­ æ€è€ƒè¿‡ç¨‹:")
    analysis_event = CloudEvent(
        type="node.request",
        source="coordinator",
        data={"content": f"Analyze this research: {research_result}"}
    )
    analysis_result = await analyst.process(analysis_event)
    print(f"\nâœ… Analysiså®Œæˆ")
    print(f"ğŸ“„ ç»“æœ: {analysis_result[:150]}...")

    # Step 3: Writeræ’°å†™æŠ¥å‘Š
    print(f"\nâœï¸ [Step 3] Writerå¼€å§‹æ’°å†™æŠ¥å‘Š...")
    print("ğŸ’­ æ€è€ƒè¿‡ç¨‹:")
    writing_event = CloudEvent(
        type="node.request",
        source="coordinator",
        data={"content": f"Write a report based on: {analysis_result}"}
    )
    final_report = await writer.process(writing_event)
    print(f"\nâœ… Writingå®Œæˆ")

    print(f"\n{'='*60}")
    print(f"ğŸ“ æœ€ç»ˆæŠ¥å‘Š:")
    print(f"{'='*60}")
    print(final_report)

    return final_report

# è¿è¡Œæµ‹è¯•1
asyncio.run(test_crew_serial_stream())
print("\nâœ… æµ‹è¯•1å®Œæˆ\n")

print("=" * 60)
print("æµ‹è¯•2: å¹¶è¡Œæ¨¡å¼ - æµå¼è¾“å‡º")
print("=" * 60)

async def test_parallel_stream():
    """æµ‹è¯•å¹¶è¡Œæ¨¡å¼ä¸‹çš„æµå¼è¾“å‡º"""
    from loom.node.tool import ToolNode
    from loom.protocol.mcp import MCPToolDefinition

    print("\nğŸ”§ åˆ›å»ºåŸºç¡€è®¾æ–½...")
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºå¹¶æ³¨å†Œæµå¼è¾“å‡ºç›‘å¬å™¨ï¼ˆä½¿ç”¨é€šé…ç¬¦è®¢é˜…ï¼‰
    listener = StreamEventListener()
    await bus.subscribe("agent.stream.text/*", listener.on_stream_text)
    await bus.subscribe("agent.stream.done/*", listener.on_stream_done)
    await bus.subscribe("agent.stream.tool_call_start/*", listener.on_stream_tool_call_start)
    await bus.subscribe("agent.stream.error/*", listener.on_stream_error)
    print("âœ… æµå¼è¾“å‡ºç›‘å¬å™¨å·²æ³¨å†Œ")

    # åˆ›å»ºå¯ç”¨æµå¼è¾“å‡ºçš„OpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=True
    )
    print(f"âœ… Provideråˆ›å»ºæˆåŠŸ (stream=True)")

    # åˆ›å»ºå¤šä¸ªå·¥å…·
    def get_weather(city: str) -> str:
        return f"Weather in {city}: Sunny, 25Â°C"

    def get_time(timezone: str) -> str:
        return f"Time in {timezone}: 14:30"

    def get_news(category: str) -> str:
        return f"Latest {category} news: AI advances"

    # åˆ›å»ºToolNode
    weather_tool = ToolNode(
        node_id="weather-tool",
        dispatcher=dispatcher,
        tool_def=MCPToolDefinition(
            name="get_weather",
            description="Get weather information",
            inputSchema={"type": "object", "properties": {"city": {"type": "string"}}, "required": ["city"]}
        ),
        func=get_weather
    )

    time_tool = ToolNode(
        node_id="time-tool",
        dispatcher=dispatcher,
        tool_def=MCPToolDefinition(
            name="get_time",
            description="Get current time",
            inputSchema={"type": "object", "properties": {"timezone": {"type": "string"}}, "required": ["timezone"]}
        ),
        func=get_time
    )

    news_tool = ToolNode(
        node_id="news-tool",
        dispatcher=dispatcher,
        tool_def=MCPToolDefinition(
            name="get_news",
            description="Get latest news",
            inputSchema={"type": "object", "properties": {"category": {"type": "string"}}, "required": ["category"]}
        ),
        func=get_news
    )
    print(f"âœ… åˆ›å»ºäº†3ä¸ªå·¥å…·")

    # åˆ›å»ºæ”¯æŒå¹¶è¡Œæ‰§è¡Œçš„Agent
    agent = (LoomBuilder()
        .with_id('parallel-agent')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_tools([weather_tool, time_tool, news_tool])
        .with_execution(parallel_execution=True, concurrency_limit=3)
        .with_agent(
            role='Information Assistant',
            system_prompt='You are an information assistant. Use tools to gather information.'
        )
        .build())
    print(f"âœ… Agentåˆ›å»ºæˆåŠŸ (parallel_execution=True)")

    # æµ‹è¯•å¹¶è¡Œå·¥å…·è°ƒç”¨
    print(f"\nğŸ“¨ å‘é€é—®é¢˜: è·å–åŒ—äº¬å¤©æ°”ã€UTCæ—¶é—´å’Œç§‘æŠ€æ–°é—»")
    print("ğŸ’­ Agentæ€è€ƒå¹¶å¹¶è¡Œè°ƒç”¨å·¥å…·...")
    event = CloudEvent(
        type="node.request",
        source="user",
        data={"content": "Please tell me: 1) weather in Beijing, 2) time in UTC, 3) tech news. Use tools."}
    )

    result = await agent.process(event)
    print(f"\nâœ… å¹¶è¡Œæ‰§è¡Œå®Œæˆ")
    print(f"\nğŸ¤– æœ€ç»ˆå“åº”:")
    print(result)

    return result

# è¿è¡Œæµ‹è¯•2
asyncio.run(test_parallel_stream())
print("\nâœ… æµ‹è¯•2å®Œæˆ\n")

print("=" * 60)
print("æµ‹è¯•3: ReActèŒƒå¼ - æµå¼è¾“å‡º")
print("=" * 60)

async def test_react_stream():
    """æµ‹è¯•ReActèŒƒå¼ä¸‹çš„æµå¼è¾“å‡ºï¼ˆå±•ç¤ºå®Œæ•´æ¨ç†è¿‡ç¨‹ï¼‰"""
    from loom.node.tool import ToolNode
    from loom.protocol.mcp import MCPToolDefinition

    print("\nğŸ”§ åˆ›å»ºåŸºç¡€è®¾æ–½...")
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºå¹¶æ³¨å†Œæµå¼è¾“å‡ºç›‘å¬å™¨ï¼ˆä½¿ç”¨é€šé…ç¬¦è®¢é˜…ï¼‰
    listener = StreamEventListener()
    await bus.subscribe("agent.stream.text/*", listener.on_stream_text)
    await bus.subscribe("agent.stream.done/*", listener.on_stream_done)
    await bus.subscribe("agent.stream.tool_call_start/*", listener.on_stream_tool_call_start)
    await bus.subscribe("agent.stream.error/*", listener.on_stream_error)
    print("âœ… æµå¼è¾“å‡ºç›‘å¬å™¨å·²æ³¨å†Œ")

    # åˆ›å»ºå¯ç”¨æµå¼è¾“å‡ºçš„OpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=True
    )
    print(f"âœ… Provideråˆ›å»ºæˆåŠŸ (stream=True)")

    # åˆ›å»ºè®¡ç®—å™¨å·¥å…·ï¼ˆç”¨äºReActæ¨ç†ï¼‰
    def calculator(operation: str, a: float, b: float) -> float:
        result = {"add": a + b, "multiply": a * b, "subtract": a - b, "divide": a / b if b != 0 else "Error"}
        return result.get(operation, "Unknown operation")

    calc_tool = ToolNode(
        node_id="calculator-tool",
        dispatcher=dispatcher,
        tool_def=MCPToolDefinition(
            name="calculator",
            description="Perform arithmetic operations",
            inputSchema={
                "type": "object",
                "properties": {
                    "operation": {"type": "string", "enum": ["add", "multiply", "subtract", "divide"]},
                    "a": {"type": "number"},
                    "b": {"type": "number"}
                },
                "required": ["operation", "a", "b"]
            }
        ),
        func=calculator
    )
    print(f"âœ… è®¡ç®—å™¨å·¥å…·åˆ›å»ºæˆåŠŸ")

    # åˆ›å»ºAgentï¼ˆReActæ¨¡å¼ï¼‰
    agent = (LoomBuilder()
        .with_id('react-agent')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_tools([calc_tool])
        .with_agent(
            role='Math Assistant',
            system_prompt='You are a math assistant. Think step by step and use the calculator tool when needed.'
        )
        .build())
    print(f"âœ… Agentåˆ›å»ºæˆåŠŸ (ReActæ¨¡å¼)")

    # æµ‹è¯•ReActæ¨ç†è¿‡ç¨‹
    print(f"\nğŸ“¨ å‘é€é—®é¢˜: è®¡ç®— (15 + 25) * 3")
    print("ğŸ’­ å±•ç¤ºå®Œæ•´ReActæ¨ç†è¿‡ç¨‹:")
    print("   [Thought â†’ Action â†’ Observation â†’ Thought â†’ ...]")
    event = CloudEvent(
        type="node.request",
        source="user",
        data={"content": "Calculate (15 + 25) * 3. Think step by step and use the calculator tool."}
    )

    result = await agent.process(event)
    print(f"\nâœ… ReActæ¨ç†å®Œæˆ")
    print(f"\nğŸ¤– æœ€ç»ˆç­”æ¡ˆ:")
    print(result)

    return result

# è¿è¡Œæµ‹è¯•3
asyncio.run(test_react_stream())
print("\nâœ… æµ‹è¯•3å®Œæˆ\n")

print("=" * 60)
print("âœ… æ‰€æœ‰æµå¼è¾“å‡ºæµ‹è¯•å®Œæˆ")
print("=" * 60)
