"""
Agent - è‡ªä¸»æ™ºèƒ½ä½“åŸºç±»

åŸºäºå…¬ç†ç³»ç»Ÿå’Œå”¯ä¸€æ€§åŸåˆ™ï¼š
å°†æ‰€æœ‰æ™ºèƒ½ä½“èƒ½åŠ›ç»Ÿä¸€åˆ°ä¸€ä¸ªAgentç±»ä¸­ï¼Œä½œä¸ºæ‰€æœ‰æ™ºèƒ½ä½“çš„åŸºç¡€ã€‚

è®¾è®¡åŸåˆ™ï¼š
1. å”¯ä¸€æ€§ - æ¯ä¸ªåŠŸèƒ½åªåœ¨ä¸€ä¸ªåœ°æ–¹å®ç°
2. ç»§æ‰¿BaseNode - è·å¾—è§‚æµ‹å’Œé›†ä½“è®°å¿†èƒ½åŠ›
3. é›†æˆLLM - æ”¯æŒæµå¼è¾“å‡º
4. å››èŒƒå¼è‡ªåŠ¨èƒ½åŠ› - LLMè‡ªä¸»å†³ç­–ä½¿ç”¨åæ€ã€å·¥å…·ã€è§„åˆ’ã€åä½œèƒ½åŠ›

åŸºç¡€èƒ½åŠ›ï¼ˆç»§æ‰¿è‡ªBaseNodeï¼‰ï¼š
- ç”Ÿå‘½å‘¨æœŸç®¡ç†
- äº‹ä»¶å‘å¸ƒï¼ˆè§‚æµ‹èƒ½åŠ›ï¼‰
- äº‹ä»¶æŸ¥è¯¢ï¼ˆé›†ä½“è®°å¿†èƒ½åŠ›ï¼‰
- ç»Ÿè®¡ä¿¡æ¯

è‡ªä¸»èƒ½åŠ›ï¼ˆå…¬ç†A6 - å››èŒƒå¼å·¥ä½œå…¬ç†ï¼‰ï¼š
- åæ€èƒ½åŠ›ï¼šæŒç»­çš„æ€è€ƒè¿‡ç¨‹ï¼ˆé€šè¿‡LLM streamingè‡ªåŠ¨ä½“ç°ï¼‰
- å·¥å…·ä½¿ç”¨ï¼šLLMè‡ªåŠ¨å†³ç­–è°ƒç”¨å·¥å…·ï¼ˆé€šè¿‡tool callingï¼‰
- è§„åˆ’èƒ½åŠ›ï¼šLLMæ£€æµ‹å¤æ‚ä»»åŠ¡è‡ªåŠ¨è§„åˆ’ï¼ˆé€šè¿‡meta-toolï¼‰
- åä½œèƒ½åŠ›ï¼šLLMæ£€æµ‹éœ€è¦åä½œè‡ªåŠ¨å§”æ´¾ï¼ˆé€šè¿‡meta-toolï¼‰
"""

from collections import defaultdict, deque
from typing import Any

from loom.events.queryable_event_bus import QueryableEventBus
from loom.exceptions import TaskComplete
from loom.memory.core import LoomMemory
from loom.memory.task_context import (
    EventBusContextSource,
    MemoryContextSource,
    TaskContextManager,
)
from loom.memory.tokenizer import TiktokenCounter
from loom.orchestration.base_node import BaseNode
from loom.protocol import Task, TaskStatus
from loom.providers.llm.interface import LLMProvider
from loom.tools.done_tool import create_done_tool, execute_done_tool


class Agent(BaseNode):
    """
    ç»Ÿä¸€çš„æ™ºèƒ½ä½“åŸºç±»

    ç»§æ‰¿è‡ªBaseNodeï¼Œé›†æˆäº†è§‚æµ‹ã€è®°å¿†ã€ä¸Šä¸‹æ–‡ç®¡ç†ç­‰æ‰€æœ‰åŸºç¡€èƒ½åŠ›ã€‚
    æ‰€æœ‰è‡ªå®šä¹‰æ™ºèƒ½ä½“éƒ½åº”è¯¥ç»§æ‰¿æ­¤ç±»ã€‚

    å±æ€§ï¼š
        llm_provider: LLMæä¾›è€…
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        memory: LoomMemoryå®ä¾‹ï¼ˆL1-L4åˆ†å±‚è®°å¿†ï¼‰
        context_manager: TaskContextManagerï¼ˆæ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ï¼‰
    """

    def __init__(
        self,
        node_id: str,
        llm_provider: LLMProvider,
        system_prompt: str = "",
        tools: list[dict[str, Any]] | None = None,
        available_agents: dict[str, Any] | None = None,
        event_bus: Any | None = None,  # QueryableEventBus
        enable_observation: bool = True,
        max_context_tokens: int = 4000,
        max_iterations: int = 10,
        require_done_tool: bool = True,
        skill_registry: Any | None = None,  # SkillRegistry
        memory_config: dict[str, Any] | None = None,
        **kwargs,
    ):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“

        Args:
            node_id: èŠ‚ç‚¹ID
            llm_provider: LLMæä¾›è€…
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆæ™®é€šå·¥å…·ï¼‰
            available_agents: å¯ç”¨çš„å…¶ä»–agentï¼ˆç”¨äºå§”æ´¾ï¼‰
            event_bus: äº‹ä»¶æ€»çº¿ï¼ˆå¯é€‰ï¼Œç”¨äºè§‚æµ‹å’Œä¸Šä¸‹æ–‡ç®¡ç†ï¼‰
            enable_observation: æ˜¯å¦å¯ç”¨è§‚æµ‹èƒ½åŠ›
            max_context_tokens: æœ€å¤§ä¸Šä¸‹æ–‡tokenæ•°
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            require_done_tool: æ˜¯å¦è¦æ±‚æ˜¾å¼è°ƒç”¨doneå·¥å…·å®Œæˆä»»åŠ¡
            skill_registry: Skillæ³¨å†Œè¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºåŠ è½½Skillsï¼‰
            memory_config: è®°å¿†ç³»ç»Ÿé…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æ ‡å‡†é…ç½®ï¼‰
            **kwargs: å…¶ä»–å‚æ•°ä¼ é€’ç»™BaseNode
        """
        super().__init__(
            node_id=node_id,
            node_type="agent",
            event_bus=event_bus,
            enable_observation=enable_observation,
            enable_collective_memory=True,
            **kwargs,
        )

        self.llm_provider = llm_provider
        self.system_prompt = self._build_autonomous_system_prompt(system_prompt)
        self.tools = tools or []
        self.available_agents = available_agents or {}
        self.max_iterations = max_iterations
        self.require_done_tool = require_done_tool
        self.skill_registry = skill_registry

        # å¦‚æœå¯ç”¨ done toolï¼Œæ·»åŠ åˆ°å·¥å…·åˆ—è¡¨
        if self.require_done_tool:
            self.tools.append(create_done_tool())

        # åˆ›å»º LoomMemoryï¼ˆä½¿ç”¨é…ç½®ï¼‰
        self.memory = LoomMemory(node_id=node_id, **(memory_config or {}))

        # åˆ›å»º TaskContextManager
        from loom.memory.task_context import ContextSource
        
        sources: list[ContextSource] = []
        sources.append(MemoryContextSource(self.memory))
        if event_bus and isinstance(event_bus, QueryableEventBus):
            sources.append(EventBusContextSource(event_bus))

        self.context_manager = TaskContextManager(
            token_counter=TiktokenCounter(model="gpt-4"),
            sources=sources,
            max_tokens=max_context_tokens,
            system_prompt=self.system_prompt,
        )

        # æ„å»ºå®Œæ•´å·¥å…·åˆ—è¡¨ï¼ˆæ™®é€šå·¥å…· + å…ƒå·¥å…·ï¼‰
        self.all_tools = self._build_tool_list()

        # Ephemeral æ¶ˆæ¯è·Ÿè¸ªï¼ˆç”¨äºå¤§è¾“å‡ºå·¥å…·ï¼‰
        self._ephemeral_tool_outputs: dict[str, deque] = defaultdict(lambda: deque())

        # EventBuså§”æ´¾å¤„ç†å™¨ï¼ˆç”¨äºå¼‚æ­¥å§”æ´¾ï¼‰
        self._delegation_handler = None
        if event_bus and isinstance(event_bus, QueryableEventBus):
            from .eventbus_delegation import EventBusDelegationHandler

            self._delegation_handler = EventBusDelegationHandler(event_bus)

    def _build_autonomous_system_prompt(self, base_prompt: str) -> str:
        """
        æ„å»ºè‡ªä¸»Agentçš„ç³»ç»Ÿæç¤ºè¯

        å¢å¼ºåŸºç¡€æç¤ºè¯ï¼Œå‘ŠçŸ¥LLMå…¶è‡ªä¸»èƒ½åŠ›ã€‚

        Args:
            base_prompt: åŸºç¡€ç³»ç»Ÿæç¤ºè¯

        Returns:
            å¢å¼ºåçš„ç³»ç»Ÿæç¤ºè¯
        """
        autonomous_capabilities = """

=== ä½ çš„è‡ªä¸»èƒ½åŠ›ï¼ˆå››èŒƒå¼å·¥ä½œæ¨¡å¼ï¼‰===

ä½ æ˜¯ä¸€ä¸ªè‡ªä¸»æ™ºèƒ½ä½“ï¼Œå…·å¤‡å››ç§æ ¸å¿ƒèƒ½åŠ›ï¼Œå¯ä»¥æ ¹æ®ä»»åŠ¡è‡ªåŠ¨å†³ç­–ä½¿ç”¨ï¼š

1. **åæ€èƒ½åŠ›ï¼ˆReflectionï¼‰**ï¼š
   - è¿™æ˜¯ä½ æœ€åŸºç¡€çš„èƒ½åŠ›ï¼Œè´¯ç©¿æ•´ä¸ªæ€è€ƒè¿‡ç¨‹
   - æŒç»­æ€è€ƒã€åˆ†æã€è¯„ä¼°ä½ çš„æ–¹æ³•å’Œç»“æœ
   - æ— éœ€è°ƒç”¨å·¥å…·ï¼Œè‡ªç„¶åœ°åœ¨å›å¤ä¸­ä½“ç°ä½ çš„æ€è€ƒ

2. **å·¥å…·ä½¿ç”¨ï¼ˆTool Useï¼‰**ï¼š
   - å½“éœ€è¦æ‰§è¡Œå…·ä½“æ“ä½œæ—¶ï¼Œè°ƒç”¨å¯ç”¨çš„å·¥å…·
   - æ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªä¸»å†³å®šä½¿ç”¨å“ªäº›å·¥å…·
   - å¯ä»¥å¤šæ¬¡è°ƒç”¨å·¥å…·ç›´åˆ°å®Œæˆä»»åŠ¡

3. **è§„åˆ’èƒ½åŠ›ï¼ˆPlanningï¼‰**ï¼š
   - å½“é‡åˆ°å¤æ‚ä»»åŠ¡æ—¶ï¼Œä½¿ç”¨ create_plan å·¥å…·åˆ¶å®šè®¡åˆ’
   - å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„æ­¥éª¤
   - æŒ‰è®¡åˆ’é€æ­¥æ‰§è¡Œ

4. **åä½œèƒ½åŠ›ï¼ˆMulti-Agentï¼‰**ï¼š
   - å½“ä»»åŠ¡è¶…å‡ºä½ çš„èƒ½åŠ›èŒƒå›´æ—¶ï¼Œä½¿ç”¨ delegate_task å·¥å…·å§”æ´¾ç»™å…¶ä»–agent
   - è‡ªä¸»åˆ¤æ–­ä½•æ—¶éœ€è¦åä½œ
   - æ•´åˆå¤šä¸ªagentçš„ç»“æœ

**å·¥ä½œåŸåˆ™**ï¼š
- å§‹ç»ˆä¿æŒåæ€ï¼Œå±•ç°ä½ çš„æ€è€ƒè¿‡ç¨‹
- æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªä¸»å†³å®šä½¿ç”¨å“ªäº›èƒ½åŠ›
- ä¸è¦è¯¢é—®æ˜¯å¦å¯ä»¥ä½¿ç”¨æŸä¸ªèƒ½åŠ›ï¼Œç›´æ¥ä½¿ç”¨
- è¿½æ±‚é«˜æ•ˆå®Œæˆä»»åŠ¡
"""

        if base_prompt:
            return base_prompt + autonomous_capabilities
        else:
            return autonomous_capabilities.strip()

    def _build_tool_list(self) -> list[dict[str, Any]]:
        """
        æ„å»ºå®Œæ•´å·¥å…·åˆ—è¡¨ï¼ˆæ™®é€šå·¥å…· + å…ƒå·¥å…·ï¼‰

        Returns:
            å®Œæ•´çš„å·¥å…·åˆ—è¡¨
        """
        tools = self.tools.copy()

        # æ·»åŠ è§„åˆ’å…ƒå·¥å…·
        tools.append(
            {
                "type": "function",
                "function": {
                    "name": "create_plan",
                    "description": "ä¸ºå¤æ‚ä»»åŠ¡åˆ›å»ºæ‰§è¡Œè®¡åˆ’ã€‚å½“ä»»åŠ¡éœ€è¦å¤šä¸ªæ­¥éª¤æˆ–è¾ƒä¸ºå¤æ‚æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "goal": {"type": "string", "description": "è¦å®ç°çš„ç›®æ ‡"},
                            "steps": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "æ‰§è¡Œæ­¥éª¤åˆ—è¡¨",
                            },
                            "reasoning": {"type": "string", "description": "ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªè®¡åˆ’"},
                        },
                        "required": ["goal", "steps"],
                    },
                },
            }
        )

        # æ·»åŠ å§”æ´¾å…ƒå·¥å…·ï¼ˆå¦‚æœæœ‰å¯ç”¨çš„agentsï¼‰
        if self.available_agents:
            agent_list = ", ".join(self.available_agents.keys())
            tools.append(
                {
                    "type": "function",
                    "function": {
                        "name": "delegate_task",
                        "description": f"å°†å­ä»»åŠ¡å§”æ´¾ç»™å…¶ä»–ä¸“ä¸šagentã€‚å¯ç”¨çš„agents: {agent_list}",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "target_agent": {
                                    "type": "string",
                                    "description": "ç›®æ ‡agentçš„ID",
                                    "enum": list(self.available_agents.keys()),
                                },
                                "subtask": {"type": "string", "description": "è¦å§”æ´¾çš„å­ä»»åŠ¡æè¿°"},
                                "reasoning": {
                                    "type": "string",
                                    "description": "ä¸ºä»€ä¹ˆéœ€è¦å§”æ´¾è¿™ä¸ªä»»åŠ¡",
                                },
                            },
                            "required": ["target_agent", "subtask"],
                        },
                    },
                }
            )

        return tools

    async def _execute_impl(self, task: Task) -> Task:
        """
        æ‰§è¡Œä»»åŠ¡ - Agent æ ¸å¿ƒå¾ªç¯

        æ ¸å¿ƒç†å¿µï¼šAgent is just a for loop

        Args:
            task: ä»»åŠ¡

        Returns:
            æ›´æ–°åçš„ä»»åŠ¡
        """
        # å­˜å‚¨ä»»åŠ¡åˆ°è®°å¿†
        self.memory.add_task(task)

        # åŠ è½½ç›¸å…³çš„Skillsï¼ˆProgressive Disclosureï¼‰
        task_content = task.parameters.get("content", "")
        relevant_skills = await self._load_relevant_skills(task_content)

        # Agent å¾ªç¯
        accumulated_messages: list[dict[str, Any]] = []
        final_content = ""

        try:
            for iteration in range(self.max_iterations):
                # 1. è¿‡æ»¤ ephemeral æ¶ˆæ¯ï¼ˆç¬¬ä¸€å±‚é˜²æŠ¤ï¼‰
                filtered_messages = self._filter_ephemeral_messages(accumulated_messages)

                # 2. æ„å»ºä¼˜åŒ–ä¸Šä¸‹æ–‡ï¼ˆç¬¬äºŒå±‚é˜²æŠ¤ï¼‰
                messages = await self.context_manager.build_context(task)

                # æ·»åŠ SkillsæŒ‡ä»¤ï¼ˆå¦‚æœæœ‰ç›¸å…³Skillsï¼‰
                if relevant_skills and iteration == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ·»åŠ 
                    skill_instructions = "\n\n=== Available Skills ===\n\n"
                    for skill in relevant_skills:
                        skill_instructions += skill.get_full_instructions() + "\n\n"
                    messages.append({"role": "system", "content": skill_instructions})

                # æ·»åŠ è¿‡æ»¤åçš„ç´¯ç§¯æ¶ˆæ¯
                if filtered_messages:
                    messages.extend(filtered_messages)

                # 2. è°ƒç”¨ LLMï¼ˆæµå¼ï¼‰
                full_content = ""
                tool_calls = []

                async for chunk in self.llm_provider.stream_chat(
                    messages, tools=self.all_tools if self.all_tools else None
                ):
                    if chunk.type == "text":
                        content_str = str(chunk.content) if isinstance(chunk.content, dict) else chunk.content
                        full_content += content_str
                        await self.publish_thinking(
                            content=content_str,
                            task_id=task.task_id,
                            metadata={"iteration": iteration},
                        )

                    elif chunk.type == "tool_call_complete":
                        if isinstance(chunk.content, dict):
                            tool_calls.append(chunk.content)
                        else:
                            # å¦‚æœä¸æ˜¯dictï¼Œå°è¯•è§£æ
                            import json
                            try:
                                tool_calls.append(json.loads(str(chunk.content)))
                            except (json.JSONDecodeError, TypeError):
                                tool_calls.append({"name": "", "arguments": {}, "content": str(chunk.content)})

                    elif chunk.type == "error":
                        await self._publish_event(
                            action="node.error",
                            parameters={"error": chunk.content},
                            task_id=task.task_id,
                        )

                final_content = full_content

                # 3. æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if not tool_calls:
                    if self.require_done_tool:
                        # è¦æ±‚ done toolï¼Œä½† LLM æ²¡æœ‰è°ƒç”¨
                        # æé†’ LLM è°ƒç”¨ done
                        accumulated_messages.append(
                            {
                                "role": "system",
                                "content": "Please call the 'done' tool when you have completed the task.",
                            }
                        )
                        continue
                    else:
                        # ä¸è¦æ±‚ done toolï¼Œç›´æ¥ç»“æŸ
                        break

                # 4. æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in tool_calls:
                    if not isinstance(tool_call, dict):
                        continue
                    tool_name = tool_call.get("name", "")
                    tool_args = tool_call.get("arguments", {})
                    if not isinstance(tool_args, dict):
                        tool_args = {}

                    # å‘å¸ƒå·¥å…·è°ƒç”¨äº‹ä»¶
                    await self.publish_tool_call(
                        tool_name=tool_name,
                        tool_args=tool_args,
                        task_id=task.task_id,
                    )

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ done tool
                    if tool_name == "done":
                        # æ‰§è¡Œ done toolï¼ˆä¼šæŠ›å‡º TaskCompleteï¼‰
                        await execute_done_tool(tool_args)

                    # å¤„ç†å…ƒå·¥å…·
                    if tool_name == "create_plan":
                        await self._auto_plan(tool_args, task.task_id)
                        result = f"Plan created: {tool_args.get('goal', '')}"
                    elif tool_name == "delegate_task":
                        # å‘å¸ƒå§”æ´¾äº‹ä»¶ï¼ˆè§‚æµ‹ï¼‰
                        await self._auto_delegate(tool_args, task.task_id)
                        # å®é™…æ‰§è¡Œå§”æ´¾
                        target_agent = tool_args.get("target_agent", "")
                        subtask = tool_args.get("subtask", "")
                        result = await self._execute_delegate_task(
                            target_agent, subtask, task.task_id
                        )
                    else:
                        # æ™®é€šå·¥å…· - è¿™é‡Œè¿”å›å ä½ç»“æœ
                        # å®é™…æ‰§è¡Œåº”è¯¥ç”±å·¥å…·æ‰§è¡Œå™¨å¤„ç†
                        result = f"Tool {tool_name} executed"

                    # ç´¯ç§¯æ¶ˆæ¯ï¼ˆæ ‡è®°å·¥å…·åç§°ç”¨äº ephemeral è¿‡æ»¤ï¼‰
                    accumulated_messages.append(
                        {
                            "role": "assistant",
                            "content": full_content or "",
                        }
                    )
                    accumulated_messages.append(
                        {
                            "role": "tool",
                            "content": result,
                            "tool_call_id": tool_call.get("id", ""),
                            "tool_name": tool_name,  # æ ‡è®°å·¥å…·åç§°
                        }
                    )

        except TaskComplete as e:
            # æ•è· TaskComplete å¼‚å¸¸ï¼Œæ­£å¸¸ç»“æŸ
            task.status = TaskStatus.COMPLETED
            task.result = {
                "content": e.message,
                "completed_explicitly": True,
            }
            self.memory.add_task(task)
            return task

        # å¦‚æœå¾ªç¯æ­£å¸¸ç»“æŸï¼ˆæ²¡æœ‰è°ƒç”¨ doneï¼‰
        task.status = TaskStatus.COMPLETED
        task.result = {
            "content": final_content,
            "completed_explicitly": False,
            "iterations": iteration + 1,
        }

        # å­˜å‚¨å®Œæˆçš„ä»»åŠ¡åˆ°è®°å¿†
        self.memory.add_task(task)

        return task

    # ==================== Ephemeral æ¶ˆæ¯è¿‡æ»¤ ====================

    def _get_tool_ephemeral_count(self, tool_name: str) -> int:
        """
        è·å–å·¥å…·çš„ ephemeral è®¾ç½®

        Args:
            tool_name: å·¥å…·åç§°

        Returns:
            ephemeral è®¡æ•°ï¼ˆ0 è¡¨ç¤ºä¸æ˜¯ ephemeral å·¥å…·ï¼‰
        """
        for tool in self.all_tools:
            if isinstance(tool, dict) and tool.get("function", {}).get("name") == tool_name:
                ephemeral = tool.get("_ephemeral", 0)
                return int(ephemeral) if isinstance(ephemeral, (int, float)) else 0
        return 0

    def _filter_ephemeral_messages(
        self,
        messages: list[dict[str, str]],
    ) -> list[dict[str, str]]:
        """
        è¿‡æ»¤ ephemeral æ¶ˆæ¯ï¼Œåªä¿ç•™æœ€è¿‘çš„

        ç­–ç•¥ï¼š
        1. è¯†åˆ«æ¯ä¸ª ephemeral å·¥å…·çš„è¾“å‡ºæ¶ˆæ¯
        2. åªä¿ç•™æœ€è¿‘ N æ¬¡è¾“å‡º
        3. ä¸¢å¼ƒæ—§çš„è¾“å‡º

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            è¿‡æ»¤åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if not messages:
            return messages

        # ç»Ÿè®¡æ¯ä¸ª ephemeral å·¥å…·çš„å‡ºç°æ¬¡æ•°
        tool_counts: dict[str, int] = defaultdict(int)
        filtered = []

        # åå‘éå†ï¼ˆä»æœ€æ–°åˆ°æœ€æ—§ï¼‰
        for msg in reversed(messages):
            tool_name = msg.get("tool_name")

            if tool_name:
                # è¿™æ˜¯å·¥å…·è¾“å‡ºæ¶ˆæ¯
                ephemeral_count = self._get_tool_ephemeral_count(tool_name)

                if ephemeral_count > 0:
                    # è¿™æ˜¯ ephemeral å·¥å…·
                    tool_counts[tool_name] += 1

                    if tool_counts[tool_name] <= ephemeral_count:
                        # åœ¨ä¿ç•™èŒƒå›´å†…
                        filtered.append(msg)
                    # else: ä¸¢å¼ƒè¿™æ¡æ¶ˆæ¯
                else:
                    # æ™®é€šå·¥å…·ï¼Œä¿ç•™
                    filtered.append(msg)
            else:
                # éå·¥å…·æ¶ˆæ¯ï¼Œä¿ç•™
                filtered.append(msg)

        # æ¢å¤æ­£åº
        filtered.reverse()
        return filtered

    # ==================== è‡ªåŠ¨èƒ½åŠ›ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰====================

    async def _auto_plan(self, plan_args: dict[str, Any], task_id: str) -> None:
        """
        è‡ªåŠ¨è§„åˆ’èƒ½åŠ› - LLMè°ƒç”¨create_planå…ƒå·¥å…·æ—¶è§¦å‘

        Args:
            plan_args: è§„åˆ’å‚æ•°ï¼ˆgoal, steps, reasoningï¼‰
            task_id: å…³è”çš„ä»»åŠ¡ID
        """
        goal = plan_args.get("goal", "")
        steps = plan_args.get("steps", [])
        reasoning = plan_args.get("reasoning", "")

        # å‘å¸ƒè§„åˆ’äº‹ä»¶
        await self._publish_event(
            action="node.auto_planning",
            parameters={
                "goal": goal,
                "steps": steps,
                "reasoning": reasoning,
                "step_count": len(steps),
            },
            task_id=task_id,
        )

        # å‘å¸ƒæ€è€ƒè¿‡ç¨‹
        await self.publish_thinking(
            content=f"ğŸ“‹ Creating plan for: {goal}\nSteps: {len(steps)}\nReasoning: {reasoning}",
            task_id=task_id,
            metadata={"phase": "auto_planning"},
        )

    async def _auto_delegate(self, delegate_args: dict[str, Any], task_id: str) -> None:
        """
        è‡ªåŠ¨å§”æ´¾èƒ½åŠ› - LLMè°ƒç”¨delegate_taskå…ƒå·¥å…·æ—¶è§¦å‘

        Args:
            delegate_args: å§”æ´¾å‚æ•°ï¼ˆtarget_agent, subtask, reasoningï¼‰
            task_id: å…³è”çš„ä»»åŠ¡ID
        """
        target_agent = delegate_args.get("target_agent", "")
        subtask = delegate_args.get("subtask", "")
        reasoning = delegate_args.get("reasoning", "")

        # å‘å¸ƒå§”æ´¾äº‹ä»¶
        await self._publish_event(
            action="node.auto_delegation",
            parameters={
                "target_agent": target_agent,
                "subtask": subtask,
                "reasoning": reasoning,
            },
            task_id=task_id,
        )

        # å‘å¸ƒæ€è€ƒè¿‡ç¨‹
        await self.publish_thinking(
            content=f"ğŸ¤ Delegating to {target_agent}: {subtask}\nReasoning: {reasoning}",
            task_id=task_id,
            metadata={"phase": "auto_delegation"},
        )

    async def _load_relevant_skills(self, task_description: str) -> list[Any]:
        """
        åŠ è½½ä¸ä»»åŠ¡ç›¸å…³çš„Skills

        ä½¿ç”¨Progressive Disclosure + LLMæ™ºèƒ½åˆ¤æ–­ï¼š
        1. ç¬¬ä¸€é˜¶æ®µï¼šè·å–æ‰€æœ‰Skillsçš„å…ƒæ•°æ®ï¼ˆname + descriptionï¼‰
        2. ä½¿ç”¨LLMåˆ¤æ–­å“ªäº›Skillsç›¸å…³
        3. ç¬¬äºŒé˜¶æ®µï¼šåªåŠ è½½ç›¸å…³Skillsçš„å®Œæ•´å®šä¹‰

        Args:
            task_description: ä»»åŠ¡æè¿°

        Returns:
            ç›¸å…³çš„SkillDefinitionåˆ—è¡¨
        """
        if not self.skill_registry:
            return []

        # è·å–æ‰€æœ‰Skillsçš„å…ƒæ•°æ®
        all_metadata = await self.skill_registry.get_all_metadata()

        if not all_metadata:
            return []

        # ä½¿ç”¨LLMæ™ºèƒ½åˆ¤æ–­ç›¸å…³æ€§
        from loom.skills.activator import SkillActivator

        activator = SkillActivator(self.llm_provider)
        relevant_skill_ids = await activator.find_relevant_skills(task_description, all_metadata)

        # åŠ è½½å®Œæ•´çš„Skillå®šä¹‰
        relevant_skills = []
        for skill_id in relevant_skill_ids:
            skill = await self.skill_registry.get_skill(skill_id)
            if skill:
                relevant_skills.append(skill)

        return relevant_skills

    async def _execute_delegate_task(
        self,
        target_agent_id: str,
        subtask: str,
        parent_task_id: str,
    ) -> str:
        """
        æ‰§è¡Œå§”æ´¾ä»»åŠ¡ - æœ€å°è¿æ¥æœºåˆ¶

        ä¸¤å±‚æœºåˆ¶ï¼š
        1. Tier 1ï¼ˆé»˜è®¤ï¼‰ï¼šç›´æ¥å¼•ç”¨ - é€šè¿‡ available_agents ç›´æ¥è°ƒç”¨
        2. Tier 2ï¼ˆå¯é€‰ï¼‰ï¼šEventBus è·¯ç”± - é€šè¿‡äº‹ä»¶æ€»çº¿è§£è€¦

        Args:
            target_agent_id: ç›®æ ‡ agent ID
            subtask: å­ä»»åŠ¡æè¿°
            parent_task_id: çˆ¶ä»»åŠ¡ ID

        Returns:
            å§”æ´¾ç»“æœå­—ç¬¦ä¸²
        """
        # Tier 1: ç›´æ¥å¼•ç”¨ï¼ˆé»˜è®¤æœºåˆ¶ï¼‰
        if target_agent_id in self.available_agents:
            target_agent = self.available_agents[target_agent_id]

            # åˆ›å»ºå§”æ´¾ä»»åŠ¡
            delegated_task = Task(
                task_id=f"{parent_task_id}:delegated:{target_agent_id}",
                source_agent=self.node_id,
                target_agent=target_agent_id,
                action="execute",
                parameters={"content": subtask},
                parent_task_id=parent_task_id,
            )

            # ç›´æ¥è°ƒç”¨ç›®æ ‡ agent
            try:
                result_task = await target_agent.execute_task(delegated_task)

                if result_task.status == TaskStatus.COMPLETED:
                    # æå–ç»“æœå†…å®¹
                    if isinstance(result_task.result, dict):
                        content = result_task.result.get("content", str(result_task.result))
                        return str(content)
                    else:
                        return str(result_task.result)
                else:
                    return f"Delegation failed: {result_task.error or 'Unknown error'}"

            except Exception as e:
                return f"Delegation error: {str(e)}"

        # Tier 2: EventBus è·¯ç”±ï¼ˆå¯é€‰æœºåˆ¶ï¼‰
        elif self._delegation_handler:
            # ä½¿ç”¨EventBusDelegationHandlerè¿›è¡Œå¼‚æ­¥å§”æ´¾
            result = await self._delegation_handler.delegate_task(
                source_agent_id=self.node_id,
                target_agent_id=target_agent_id,
                subtask=subtask,
                parent_task_id=parent_task_id,
            )
            return result

        # æ‰¾ä¸åˆ°ç›®æ ‡ agent
        else:
            return f"Error: Agent '{target_agent_id}' not found in available_agents"
