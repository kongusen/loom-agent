"""
Task-based Context Management

åŸºäº Task çš„ä¸Šä¸‹æ–‡ç®¡ç†ï¼Œæ•´åˆ LoomMemory å’Œ EventBusã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä»å¤šä¸ªæ¥æºæ”¶é›†ä¸Šä¸‹æ–‡ï¼ˆMemory + EventBusï¼‰
2. å°† Task è½¬æ¢ä¸º LLM æ¶ˆæ¯æ ¼å¼
3. æ™ºèƒ½å‹ç¼©å’Œæ€»ç»“
4. ç²¾ç¡®çš„ token æ§åˆ¶

è®¾è®¡ç†å¿µï¼š
- é˜²æ­¢ä¸Šä¸‹æ–‡è…åŒ–
- æœ€å¤§åŒ–æ™ºèƒ½
- æ”¯æŒé•¿æ—¶é—´ä»»åŠ¡
"""

from abc import ABC, abstractmethod
from typing import TYPE_CHECKING

from loom.memory.tokenizer import TokenCounter
from loom.protocol import Task

if TYPE_CHECKING:
    from loom.config.knowledge import KnowledgeBaseProvider
    from loom.events.queryable_event_bus import QueryableEventBus
    from loom.memory.core import LoomMemory


# ==================== æ¥å£å®šä¹‰ ====================


class ContextSource(ABC):
    """
    ä¸Šä¸‹æ–‡æºæŠ½è±¡æ¥å£

    å®šä¹‰ä»ä¸åŒæ¥æºè·å–ä¸Šä¸‹æ–‡çš„ç»Ÿä¸€æ¥å£ã€‚
    """

    @abstractmethod
    async def get_context(
        self,
        current_task: Task,
        max_items: int = 10,
    ) -> list[Task]:
        """
        è·å–ä¸Šä¸‹æ–‡ Task åˆ—è¡¨

        Args:
            current_task: å½“å‰ä»»åŠ¡
            max_items: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            ç›¸å…³çš„ Task åˆ—è¡¨
        """
        pass


# ==================== æ¶ˆæ¯è½¬æ¢å™¨ ====================


class MessageConverter:
    """
    Task â†’ LLM Message è½¬æ¢å™¨

    å°†ä¸åŒç±»å‹çš„ Task è½¬æ¢ä¸º LLM API æ¶ˆæ¯æ ¼å¼ã€‚
    """

    def convert_task_to_message(self, task: Task) -> dict[str, str] | None:
        """
        å°†å•ä¸ª Task è½¬æ¢ä¸ºæ¶ˆæ¯

        Args:
            task: Task å¯¹è±¡

        Returns:
            LLM æ¶ˆæ¯å­—å…¸ï¼Œå¦‚æœä¸åº”è¯¥åŒ…å«åˆ™è¿”å› None
        """
        action = task.action
        params = task.parameters

        # æ ¹æ® action ç±»å‹è½¬æ¢
        if action == "node.thinking":
            # æ€è€ƒè¿‡ç¨‹ â†’ assistant æ¶ˆæ¯
            content = params.get("content", "")
            if content:
                return {"role": "assistant", "content": content}

        elif action == "node.tool_call":
            # å·¥å…·è°ƒç”¨ â†’ assistant æ¶ˆæ¯
            tool_name = params.get("tool_name", "")
            tool_args = params.get("tool_args", {})
            return {"role": "assistant", "content": f"[Calling {tool_name}({tool_args})]"}

        elif action == "execute":
            # ä»»åŠ¡æ‰§è¡Œ â†’ user æ¶ˆæ¯
            content = params.get("content", "")
            if content:
                return {"role": "user", "content": content}

        # å…¶ä»–ç±»å‹æš‚ä¸è½¬æ¢
        return None

    def convert_tasks_to_messages(
        self,
        tasks: list[Task],
    ) -> list[dict[str, str]]:
        """
        æ‰¹é‡è½¬æ¢ Task ä¸ºæ¶ˆæ¯

        Args:
            tasks: Task åˆ—è¡¨

        Returns:
            æ¶ˆæ¯åˆ—è¡¨
        """
        messages = []
        for task in tasks:
            msg = self.convert_task_to_message(task)
            if msg:
                messages.append(msg)
        return messages


# ==================== ä¸Šä¸‹æ–‡æºå®ç° ====================


class MemoryContextSource(ContextSource):
    """
    ä» LoomMemory è·å–ä¸Šä¸‹æ–‡

    ä¼˜å…ˆçº§ï¼šL2 (å·¥ä½œè®°å¿†) > L1 (æœ€è¿‘ä»»åŠ¡)
    """

    def __init__(self, memory: "LoomMemory"):
        self.memory = memory

    async def get_context(
        self,
        _current_task: Task,
        max_items: int = 10,
    ) -> list[Task]:
        """è·å–è®°å¿†ä¸­çš„ç›¸å…³ä»»åŠ¡"""
        # 1. ä¼˜å…ˆä» L2 è·å–ï¼ˆé‡è¦ä»»åŠ¡ï¼‰
        l2_tasks = self.memory.get_l2_tasks(limit=max_items // 2)

        # 2. ä» L1 è·å–æœ€è¿‘ä»»åŠ¡
        l1_tasks = self.memory.get_l1_tasks(limit=max_items // 2)

        # 3. åˆå¹¶å»é‡
        seen_ids = set()
        context_tasks = []

        for task in l2_tasks + l1_tasks:
            if task.task_id not in seen_ids:
                context_tasks.append(task)
                seen_ids.add(task.task_id)

        return context_tasks[:max_items]


class EventBusContextSource(ContextSource):
    """
    ä» EventBus è·å–ä¸Šä¸‹æ–‡

    è·å–æ€è€ƒè¿‡ç¨‹ã€å·¥å…·è°ƒç”¨ç­‰äº‹ä»¶ã€‚
    """

    def __init__(self, event_bus: "QueryableEventBus"):
        self.event_bus = event_bus

    async def get_context(
        self,
        current_task: Task,
        max_items: int = 10,
    ) -> list[Task]:
        """è·å–ç›¸å…³äº‹ä»¶"""
        context_tasks = []

        # 1. è·å–å½“å‰ä»»åŠ¡çš„æ‰€æœ‰äº‹ä»¶
        task_events = self.event_bus.query_by_task(current_task.task_id)
        context_tasks.extend(task_events)

        # 2. è·å–å½“å‰èŠ‚ç‚¹çš„æœ€è¿‘æ€è€ƒ
        node_id = current_task.parameters.get("node_id")
        if node_id:
            thinking_events = self.event_bus.query_by_node(
                node_id,
                action_filter="node.thinking",
                limit=max_items // 2,
            )
            context_tasks.extend(thinking_events)

        # 3. å»é‡å¹¶é™åˆ¶æ•°é‡
        seen_ids = set()
        unique_tasks = []
        for task in context_tasks:
            if task.task_id not in seen_ids:
                unique_tasks.append(task)
                seen_ids.add(task.task_id)

        return unique_tasks[:max_items]


# ==================== æ ¸å¿ƒç®¡ç†å™¨ ====================


class TaskContextManager:
    """
    åŸºäº Task çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    æ•´åˆ LoomMemory å’Œ EventBusï¼Œæä¾›æ™ºèƒ½çš„ä¸Šä¸‹æ–‡æ„å»ºã€‚
    """

    def __init__(
        self,
        token_counter: TokenCounter,
        sources: list[ContextSource],
        converter: MessageConverter | None = None,
        max_tokens: int = 4000,
        system_prompt: str = "",
        knowledge_base: "KnowledgeBaseProvider | None" = None,
    ):
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.token_counter = token_counter
        self.sources = sources
        self.converter = converter or MessageConverter()
        self.max_tokens = max_tokens
        self.system_prompt = system_prompt
        self.knowledge_base = knowledge_base

    async def build_context(
        self,
        current_task: Task,
    ) -> list[dict[str, str]]:
        """
        æ„å»º LLM ä¸Šä¸‹æ–‡ï¼ˆä¼˜åŒ–ç‰ˆ - L1è‡ªåŠ¨åŒ…å« + LLMä¸»åŠ¨æŸ¥è¯¢L2/L3/L4ï¼‰

        æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼š
        - L1ï¼ˆæœ€è¿‘ä»»åŠ¡ï¼‰è‡ªåŠ¨åŒ…å«åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼ˆä¿è¯é€Ÿåº¦ï¼‰
        - å½“å‰ä»»åŠ¡ç›´æ¥åŒ…å«
        - L2/L3/L4é€šè¿‡å·¥å…·æŒ‰éœ€æŸ¥è¯¢ï¼ˆä»¥å‹ç¼©é™ˆè¿°å¥å½¢å¼ï¼‰

        Args:
            current_task: å½“å‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡

        Returns:
            OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        """
        # 1. æ”¶é›†L1æœ€è¿‘ä»»åŠ¡ï¼ˆè‡ªåŠ¨åŒ…å«ï¼Œä¿è¯é€Ÿåº¦ï¼‰
        l1_tasks = []
        for source in self.sources:
            # åªä»MemoryContextSourceè·å–L1ä»»åŠ¡
            if hasattr(source, "memory") and hasattr(source.memory, "get_l1_tasks"):
                l1_tasks = source.memory.get_l1_tasks(limit=10)  # æœ€è¿‘10ä¸ªä»»åŠ¡
                break

        # 2. è½¬æ¢L1ä»»åŠ¡ä¸ºæ¶ˆæ¯
        context_messages = []
        if l1_tasks:
            context_messages = self.converter.convert_tasks_to_messages(l1_tasks)

        # 3. å¤–éƒ¨çŸ¥è¯†åº“æŸ¥è¯¢ï¼ˆè‡ªåŠ¨åŒ…å«ç›¸å…³çŸ¥è¯†ï¼‰
        if self.knowledge_base:
            # ä½¿ç”¨å½“å‰ä»»åŠ¡çš„actionä½œä¸ºæŸ¥è¯¢
            query = current_task.action
            knowledge_items = await self.knowledge_base.query(query, limit=3)

            # è½¬æ¢çŸ¥è¯†æ¡ç›®ä¸ºæ¶ˆæ¯æ ¼å¼
            for item in knowledge_items:
                context_messages.append(
                    {
                        "role": "system",
                        "content": f"ğŸ“š Knowledge: {item.content}\n(Source: {item.source})",
                    }
                )

        # 4. æ·»åŠ å½“å‰ä»»åŠ¡
        current_task_messages = self.converter.convert_tasks_to_messages([current_task])
        context_messages.extend(current_task_messages)

        # 5. æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        final_messages = []
        if self.system_prompt:
            final_messages.append({"role": "system", "content": self.system_prompt})

        final_messages.extend(context_messages)

        # 5. Token é™åˆ¶å¤„ç†ï¼ˆç¡¬é™åˆ¶ï¼Œç”±æ¡†æ¶å¼ºåˆ¶æ‰§è¡Œï¼‰
        return self._fit_to_token_limit(final_messages)

    def _fit_to_token_limit(self, messages: list[dict[str, str]]) -> list[dict[str, str]]:
        """
        ç¡®ä¿æ¶ˆæ¯åˆ—è¡¨ä¸è¶…è¿‡ token é™åˆ¶

        ç­–ç•¥ï¼š
        1. å§‹ç»ˆä¿ç•™ System Message
        2. å§‹ç»ˆä¿ç•™æœ€å N æ¡æ¶ˆæ¯ (Recent)
        3. å¦‚æœè¶…å‡ºï¼Œä¸¢å¼ƒä¸­é—´çš„æ¶ˆæ¯
        """
        current_tokens = self.token_counter.count_messages(messages)
        if current_tokens <= self.max_tokens:
            return messages

        # åˆ†ç¦» System æ¶ˆæ¯
        system_msg = None
        other_messages = []

        if messages and messages[0]["role"] == "system":
            system_msg = messages[0]
            other_messages = messages[1:]
        else:
            other_messages = messages

        # è®¡ç®— System token
        system_tokens = self.token_counter.count_messages([system_msg]) if system_msg else 0
        available_tokens = self.max_tokens - system_tokens

        if available_tokens <= 0:
            # æç«¯æƒ…å†µï¼šç³»ç»Ÿæç¤ºè¯éƒ½æ”¾ä¸ä¸‹ï¼Œåªè¿”å› System Message
            return [system_msg] if system_msg else []

        # ä»åå¾€å‰æ·»åŠ ï¼Œç›´åˆ°å¡«æ»¡
        kept_messages = []
        current_count = 0

        for msg in reversed(other_messages):
            msg_tokens = self.token_counter.count_messages([msg])
            if current_count + msg_tokens > available_tokens:
                break
            kept_messages.insert(0, msg)
            current_count += msg_tokens

        if system_msg:
            return [system_msg] + kept_messages
        return kept_messages
