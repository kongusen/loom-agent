"""
Lexicon Agent Framework åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¡†æ¶çš„å„ç§åŠŸèƒ½
"""

import asyncio
import json
from lexicon_agent import LexiconAgent, create_agent, quick_chat


async def example_basic_chat():
    """åŸºæœ¬èŠå¤©ç¤ºä¾‹"""
    
    print("=== åŸºæœ¬èŠå¤©ç¤ºä¾‹ ===")
    
    # æ–¹å¼1: å¿«é€ŸèŠå¤©
    response = await quick_chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
    print(f"å¿«é€ŸèŠå¤©å“åº”: {response}")
    
    # æ–¹å¼2: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    async with LexiconAgent() as agent:
        response = await agent.simple_chat("è¯·åˆ†æä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿")
        print(f"ç®€å•èŠå¤©å“åº”: {response}")


async def example_streaming_chat():
    """æµå¼èŠå¤©ç¤ºä¾‹"""
    
    print("\n=== æµå¼èŠå¤©ç¤ºä¾‹ ===")
    
    async with LexiconAgent() as agent:
        print("ç”¨æˆ·: è¯·åˆ›å»ºä¸€ä¸ªPythonç¨‹åºæ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—")
        print("åŠ©æ‰‹: ", end="", flush=True)
        
        async for chunk in agent.process_message("è¯·åˆ›å»ºä¸€ä¸ªPythonç¨‹åºæ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"):
            if chunk["type"] == "response_text":
                print(chunk["content"], end="", flush=True)
            elif chunk["type"] == "stage_event":
                print(f"\n[é˜¶æ®µ: {chunk['content']['stage']} - {chunk['content']['status']}]")
            elif chunk["is_final"]:
                print("\n[å“åº”å®Œæˆ]")


async def example_with_session_context():
    """å¸¦ä¼šè¯ä¸Šä¸‹æ–‡çš„ç¤ºä¾‹"""
    
    print("\n=== ä¼šè¯ä¸Šä¸‹æ–‡ç¤ºä¾‹ ===")
    
    # åˆ›å»ºä¼šè¯ä¸Šä¸‹æ–‡
    session_context = {
        "user_id": "demo_user",
        "session_id": "demo_session_001", 
        "preferences": {
            "language": "chinese",
            "response_style": "detailed",
            "domain_expertise": ["programming", "ai"]
        },
        "conversation_history": [
            {"role": "user", "content": "æˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…"},
            {"role": "assistant", "content": "å¾ˆé«˜å…´è®¤è¯†æ‚¨ï¼æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è§£å†³Pythonå¼€å‘ç›¸å…³çš„é—®é¢˜ã€‚"}
        ]
    }
    
    async with LexiconAgent() as agent:
        response = await agent.simple_chat("åŸºäºæˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼Œæ¨èä¸€äº›é€‚åˆæˆ‘çš„Pythoné«˜çº§æŠ€å·§")
        print(f"å¸¦ä¸Šä¸‹æ–‡çš„å“åº”: {response}")


async def example_tool_usage():
    """å·¥å…·ä½¿ç”¨ç¤ºä¾‹"""
    
    print("\n=== å·¥å…·ä½¿ç”¨ç¤ºä¾‹ ===")
    
    async with LexiconAgent() as agent:
        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        tools = agent.tool_registry.list_tools()
        print(f"å¯ç”¨å·¥å…·: {tools}")
        
        # è·å–å·¥å…·ç»Ÿè®¡
        stats = agent.tool_registry.get_registry_statistics()
        print(f"å·¥å…·ç»Ÿè®¡: {json.dumps(stats, indent=2, ensure_ascii=False)}")
        
        # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨è¯·æ±‚
        print("\nå‘é€éœ€è¦å·¥å…·è°ƒç”¨çš„è¯·æ±‚...")
        async for chunk in agent.process_message("è¯·åˆ—å‡ºå½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œç„¶åæœç´¢ç›¸å…³çš„çŸ¥è¯†åº“ä¿¡æ¯"):
            if chunk["type"] == "tool_execution_start":
                print(f"å¼€å§‹æ‰§è¡Œå·¥å…·: {chunk['content']['tool_name']}")
            elif chunk["type"] == "tool_execution_complete":
                print(f"å·¥å…·æ‰§è¡Œå®Œæˆ: {chunk['content']['tool_name']}")


async def example_performance_monitoring():
    """æ€§èƒ½ç›‘æ§ç¤ºä¾‹"""
    
    print("\n=== æ€§èƒ½ç›‘æ§ç¤ºä¾‹ ===")
    
    # å¯ç”¨æ€§èƒ½ç›‘æ§
    config = {"performance_monitoring": True, "log_level": "INFO"}
    
    async with LexiconAgent(config) as agent:
        # å‘é€å¤šä¸ªè¯·æ±‚æ¥ç”Ÿæˆæ€§èƒ½æ•°æ®
        for i in range(3):
            response = await agent.simple_chat(f"è¿™æ˜¯ç¬¬{i+1}ä¸ªæµ‹è¯•è¯·æ±‚")
            print(f"è¯·æ±‚ {i+1} å®Œæˆ")
        
        # è·å–æ€§èƒ½æŠ¥å‘Š
        report = agent.get_performance_report()
        print(f"æ€§èƒ½æŠ¥å‘Š: {json.dumps(report, indent=2, ensure_ascii=False, default=str)}")
        
        # å¥åº·æ£€æŸ¥
        health = await agent.health_check()
        print(f"ç³»ç»Ÿå¥åº·çŠ¶æ€: {health['status']} (åˆ†æ•°: {health['overall_health_score']:.2f})")


async def example_error_handling():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    
    print("\n=== é”™è¯¯å¤„ç†ç¤ºä¾‹ ===")
    
    async with LexiconAgent() as agent:
        # æµ‹è¯•ç©ºæ¶ˆæ¯
        try:
            response = await agent.simple_chat("")
            print(f"ç©ºæ¶ˆæ¯å“åº”: {response}")
        except Exception as e:
            print(f"ç©ºæ¶ˆæ¯é”™è¯¯: {e}")
        
        # æµ‹è¯•å¼‚å¸¸é•¿çš„æ¶ˆæ¯
        long_message = "æµ‹è¯•" * 1000
        try:
            response = await agent.simple_chat(long_message)
            print(f"é•¿æ¶ˆæ¯å“åº”é•¿åº¦: {len(response)}")
        except Exception as e:
            print(f"é•¿æ¶ˆæ¯é”™è¯¯: {e}")


async def example_advanced_configuration():
    """é«˜çº§é…ç½®ç¤ºä¾‹"""
    
    print("\n=== é«˜çº§é…ç½®ç¤ºä¾‹ ===")
    
    # è‡ªå®šä¹‰é…ç½®
    advanced_config = {
        "log_level": "DEBUG",
        "performance_monitoring": True,
        "context_engine": {
            "max_context_length": 8000,
            "compression_enabled": True
        },
        "tool_system": {
            "max_concurrent_tools": 3,
            "safety_mode": "strict"
        },
        "orchestration": {
            "default_strategy": "functional",
            "max_agents": 5
        }
    }
    
    agent = LexiconAgent(advanced_config)
    await agent.start()
    
    try:
        # é…ç½®ä¸Šä¸‹æ–‡å¼•æ“
        agent.configure_context_engine(advanced_config.get("context_engine", {}))
        
        # è·å–æ¡†æ¶çŠ¶æ€
        status = agent.get_framework_status()
        print(f"æ¡†æ¶çŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False, default=str)}")
        
        # å¤„ç†å¤æ‚è¯·æ±‚
        response = await agent.simple_chat("è¯·åˆ†æå½“å‰AIæŠ€æœ¯å‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬å¤§è¯­è¨€æ¨¡å‹ã€å¤šæ¨¡æ€AIå’Œè‡ªåŠ¨åŒ–ç¼–ç¨‹ç­‰æ–¹å‘")
        print(f"å¤æ‚è¯·æ±‚å“åº”: {response[:200]}...")
        
    finally:
        await agent.stop()


async def example_concurrent_requests():
    """å¹¶å‘è¯·æ±‚ç¤ºä¾‹"""
    
    print("\n=== å¹¶å‘è¯·æ±‚ç¤ºä¾‹ ===")
    
    async with LexiconAgent() as agent:
        
        # å®šä¹‰ä¸åŒç±»å‹çš„è¯·æ±‚
        requests = [
            "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
            "ç¼–å†™ä¸€ä¸ªæ’åºç®—æ³•çš„ä»£ç ",
            "åˆ†æå½“å‰ç§‘æŠ€å‘å±•è¶‹åŠ¿",
            "æ¨èä¸€äº›ç¼–ç¨‹å­¦ä¹ èµ„æº",
            "è§£é‡ŠåŒºå—é“¾æŠ€æœ¯åŸç†"
        ]
        
        async def process_request(i, message):
            print(f"å¼€å§‹å¤„ç†è¯·æ±‚ {i+1}: {message[:30]}...")
            response = await agent.simple_chat(message)
            print(f"è¯·æ±‚ {i+1} å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response)}")
            return response
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è¯·æ±‚
        tasks = [process_request(i, msg) for i, msg in enumerate(requests)]
        responses = await asyncio.gather(*tasks)
        
        print(f"æ‰€æœ‰ {len(responses)} ä¸ªå¹¶å‘è¯·æ±‚å·²å®Œæˆ")


async def example_framework_lifecycle():
    """æ¡†æ¶ç”Ÿå‘½å‘¨æœŸç¤ºä¾‹"""
    
    print("\n=== æ¡†æ¶ç”Ÿå‘½å‘¨æœŸç¤ºä¾‹ ===")
    
    # åˆ›å»ºä½†ä¸å¯åŠ¨
    agent = LexiconAgent()
    print(f"æ¡†æ¶å·²åˆ›å»ºï¼Œåˆå§‹åŒ–çŠ¶æ€: {agent.is_initialized}")
    
    # æ‰‹åŠ¨å¯åŠ¨
    await agent.start()
    print(f"æ¡†æ¶å·²å¯åŠ¨ï¼Œåˆå§‹åŒ–çŠ¶æ€: {agent.is_initialized}")
    print(f"å¯åŠ¨æ—¶é—´: {agent.startup_time}")
    
    # ä½¿ç”¨æ¡†æ¶
    response = await agent.simple_chat("æµ‹è¯•æ¡†æ¶æ˜¯å¦æ­£å¸¸å·¥ä½œ")
    print(f"æµ‹è¯•å“åº”: {response[:50]}...")
    
    # è·å–è¿è¡Œæ—¶ç»Ÿè®¡
    status = agent.get_framework_status()
    print(f"è¿è¡Œæ—¶é•¿: {status['uptime_seconds']:.2f} ç§’")
    print(f"å¤„ç†è¯·æ±‚æ•°: {status['statistics']['total_requests']}")
    
    # æ‰‹åŠ¨åœæ­¢
    await agent.stop()
    print(f"æ¡†æ¶å·²åœæ­¢ï¼Œåˆå§‹åŒ–çŠ¶æ€: {agent.is_initialized}")


async def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    
    print("ğŸ¤– Lexicon Agent Framework ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        await example_basic_chat()
        await example_streaming_chat()
        await example_with_session_context()
        await example_tool_usage()
        await example_performance_monitoring()
        await example_error_handling()
        await example_advanced_configuration()
        await example_concurrent_requests()
        await example_framework_lifecycle()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())