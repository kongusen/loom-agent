"""
å¯¹è¯åŠ©æ‰‹ Demo - è¯­ä¹‰è¿è´¯çš„å¤æ‚é—®é¢˜åˆ†æ

ç‰¹æ€§ï¼š
- è¯­ä¹‰è¿è´¯çš„è‡ªç„¶å¯¹è¯ä½“éªŒ
- å†…éƒ¨å¤æ‚åˆ†æè¿‡ç¨‹å¯è§‚æµ‹
- é›†æˆæ™ºèƒ½RAGçŸ¥è¯†åº“
- æµå¼è¾“å‡ºæ€è€ƒè¿‡ç¨‹
- æ”¯æŒå¤šè½®å¯¹è¯

è¿è¡Œï¼š
  OPENAI_API_KEY=... python examples/conversational_assistant_demo.py

ç¤ºä¾‹å¯¹è¯ï¼š
  ç”¨æˆ·: è§£é‡Šä¸€ä¸‹Pythonçš„å¼‚æ­¥ç¼–ç¨‹åŸç†
  åŠ©æ‰‹: [å±•ç¤ºæ€è€ƒè¿‡ç¨‹] [æŸ¥è¯¢çŸ¥è¯†åº“] [ç»™å‡ºè¿è´¯çš„è§£é‡Š]
"""

import asyncio
import os
from typing import Any

from loom.api import LoomApp
from loom.api.models import AgentConfig
from loom.providers.knowledge.base import KnowledgeBaseProvider, KnowledgeItem
from loom.events import EventBus
from loom.protocol import Task
from loom.providers.llm.openai import OpenAIProvider


# ==================== çŸ¥è¯†åº“å®ç° ====================

class ConversationalKnowledgeBase(KnowledgeBaseProvider):
    """
    å¯¹è¯åŠ©æ‰‹çš„çŸ¥è¯†åº“

    åŒ…å«ç¼–ç¨‹ã€æŠ€æœ¯ã€AIç­‰é¢†åŸŸçš„çŸ¥è¯†
    """

    def __init__(self):
        self.knowledge_data = [
            {
                "id": "kb_python_async_001",
                "content": "Pythonå¼‚æ­¥ç¼–ç¨‹åŸºäºäº‹ä»¶å¾ªç¯ï¼ˆEvent Loopï¼‰å’Œåç¨‹ï¼ˆCoroutineï¼‰ã€‚"
                          "äº‹ä»¶å¾ªç¯è´Ÿè´£è°ƒåº¦å’Œæ‰§è¡Œå¼‚æ­¥ä»»åŠ¡ï¼Œåç¨‹æ˜¯å¯ä»¥æš‚åœå’Œæ¢å¤çš„å‡½æ•°ã€‚"
                          "ä½¿ç”¨async/awaitè¯­æ³•å¯ä»¥ç¼–å†™éé˜»å¡çš„å¼‚æ­¥ä»£ç ã€‚",
                "source": "Pythonå¼‚æ­¥ç¼–ç¨‹æŒ‡å—",
                "tags": ["python", "async", "coroutine", "event-loop"],
            },
            {
                "id": "kb_python_async_002",
                "content": "asyncioæ˜¯Pythonçš„æ ‡å‡†å¼‚æ­¥I/Oåº“ï¼Œæä¾›äº†äº‹ä»¶å¾ªç¯ã€åç¨‹ã€ä»»åŠ¡ç­‰æ ¸å¿ƒç»„ä»¶ã€‚"
                          "å¸¸ç”¨çš„å¼‚æ­¥æ“ä½œåŒ…æ‹¬ï¼šç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶I/Oã€æ•°æ®åº“æŸ¥è¯¢ç­‰ã€‚"
                          "å¼‚æ­¥ç¼–ç¨‹å¯ä»¥æ˜¾è‘—æé«˜I/Oå¯†é›†å‹åº”ç”¨çš„æ€§èƒ½ã€‚",
                "source": "asyncioå®˜æ–¹æ–‡æ¡£",
                "tags": ["python", "asyncio", "performance", "io"],
            },
            {
                "id": "kb_llm_001",
                "content": "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯åŸºäºTransformeræ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œ"
                          "é€šè¿‡åœ¨æµ·é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ è¯­è¨€çš„ç»Ÿè®¡è§„å¾‹å’Œè¯­ä¹‰è¡¨ç¤ºã€‚"
                          "ä»£è¡¨æ€§æ¨¡å‹åŒ…æ‹¬GPTç³»åˆ—ã€Claudeã€LLaMAç­‰ã€‚",
                "source": "LLMæŠ€æœ¯æ¦‚è§ˆ",
                "tags": ["llm", "ai", "transformer", "deep-learning"],
            },
            {
                "id": "kb_rag_001",
                "content": "RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æŠ€æœ¯ï¼Œ"
                          "é€šè¿‡ä»å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œå¢å¼ºLLMçš„å›ç­”å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ã€‚"
                          "RAGç³»ç»Ÿé€šå¸¸åŒ…æ‹¬ï¼šå‘é‡åŒ–ã€æ£€ç´¢ã€é‡æ’åºã€ç”Ÿæˆç­‰æ­¥éª¤ã€‚",
                "source": "RAGæŠ€æœ¯ç™½çš®ä¹¦",
                "tags": ["rag", "llm", "retrieval", "generation"],
            },
            {
                "id": "kb_agent_001",
                "content": "AI Agentæ˜¯èƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒã€åšå‡ºå†³ç­–å¹¶é‡‡å–è¡ŒåŠ¨çš„æ™ºèƒ½ç³»ç»Ÿã€‚"
                          "ç°ä»£Agenté€šå¸¸åŸºäºLLMï¼Œå…·å¤‡å·¥å…·ä½¿ç”¨ã€è§„åˆ’ã€åæ€ç­‰èƒ½åŠ›ã€‚"
                          "Agentå¯ä»¥è‡ªä¸»å®Œæˆå¤æ‚ä»»åŠ¡ï¼Œå¦‚ä»£ç ç”Ÿæˆã€æ•°æ®åˆ†æã€é—®é¢˜æ±‚è§£ç­‰ã€‚",
                "source": "AI Agentæ¶æ„è®¾è®¡",
                "tags": ["agent", "ai", "llm", "autonomous"],
            },
            {
                "id": "kb_memory_001",
                "content": "åˆ†å±‚è®°å¿†ç³»ç»Ÿæ¨¡æ‹Ÿäººç±»è®°å¿†æœºåˆ¶ï¼ŒåŒ…æ‹¬çŸ­æœŸè®°å¿†ã€å·¥ä½œè®°å¿†ã€é•¿æœŸè®°å¿†ç­‰å±‚æ¬¡ã€‚"
                          "L1å±‚å­˜å‚¨åŸå§‹äº¤äº’ï¼ŒL2å±‚å­˜å‚¨é‡è¦ä¿¡æ¯ï¼ŒL3å±‚å­˜å‚¨æ‘˜è¦ï¼ŒL4å±‚ä½¿ç”¨å‘é‡å­˜å‚¨ã€‚"
                          "è¿™ç§è®¾è®¡å¯ä»¥é«˜æ•ˆç®¡ç†å¤§é‡å†å²ä¿¡æ¯ã€‚",
                "source": "è®°å¿†ç³»ç»Ÿè®¾è®¡æ–‡æ¡£",
                "tags": ["memory", "architecture", "hierarchy"],
            },
        ]

    async def query(self, query: str, limit: int = 3) -> list[KnowledgeItem]:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        query_lower = query.lower()
        results = []

        for item in self.knowledge_data:
            content_lower = item["content"].lower()
            tags_lower = [tag.lower() for tag in item["tags"]]

            # è®¡ç®—ç›¸å…³åº¦
            relevance = 0.0
            if query_lower in content_lower:
                relevance = 0.95
            elif any(query_lower in tag for tag in tags_lower):
                relevance = 0.85
            elif any(word in content_lower for word in query_lower.split()):
                relevance = 0.75

            if relevance > 0:
                results.append(
                    KnowledgeItem(
                        id=item["id"],
                        content=item["content"],
                        source=item["source"],
                        relevance=relevance,
                        metadata={"tags": item["tags"]},
                    )
                )

        results.sort(key=lambda x: x.relevance, reverse=True)
        return results[:limit]


# ==================== å·¥å…·å®šä¹‰ ====================

def create_calculator_tool():
    """åˆ›å»ºè®¡ç®—å™¨å·¥å…·"""
    return {
        "type": "function",
        "function": {
            "name": "calculator",
            "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—ï¼Œæ”¯æŒåŸºæœ¬è¿ç®—å’Œæ•°å­¦å‡½æ•°",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ '2 + 2' æˆ– 'sqrt(16)'",
                    }
                },
                "required": ["expression"],
            },
        },
    }


def create_search_tool():
    """åˆ›å»ºæœç´¢å·¥å…·"""
    return {
        "type": "function",
        "function": {
            "name": "search_knowledge",
            "description": "æœç´¢çŸ¥è¯†åº“ä¸­çš„ç›¸å…³ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢æŸ¥è¯¢",
                    }
                },
                "required": ["query"],
            },
        },
    }


# ==================== äº‹ä»¶å¤„ç†å™¨ï¼ˆå¯è§‚æµ‹æ€§ï¼‰====================

class ConversationObserver:
    """
    å¯¹è¯è§‚å¯Ÿå™¨ - å±•ç¤ºå†…éƒ¨æ€è€ƒè¿‡ç¨‹
    """

    def __init__(self):
        self.thinking_buffer = []
        self.knowledge_queries = []
        self.tool_calls = []

    async def on_event(self, task: Task) -> Task:
        """å¤„ç†äº‹ä»¶"""
        action = task.action

        if action == "node.thinking":
            # æ€è€ƒè¿‡ç¨‹
            content = task.parameters.get("content", "")
            if content:
                self.thinking_buffer.append(content)
                print(f"ğŸ’­ {content}", end="", flush=True)

        elif action == "node.tool_call":
            # å·¥å…·è°ƒç”¨
            tool_name = task.parameters.get("tool_name", "unknown")
            self.tool_calls.append(tool_name)
            print(f"\nğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")

        elif action == "node.tool_result":
            # å·¥å…·ç»“æœ
            result = task.parameters.get("result", "")
            if "Knowledge" in str(result):
                self.knowledge_queries.append(result)
                print(f"ğŸ“š æŸ¥è¯¢çŸ¥è¯†åº“")

        return task


# ==================== å¯¹è¯å¾ªç¯ ====================

async def conversation_loop(agent: Any, observer: ConversationObserver):
    """
    å¯¹è¯å¾ªç¯ - å¤„ç†ç”¨æˆ·è¾“å…¥å’ŒAgentå“åº”
    """
    print("\n" + "=" * 60)
    print("ğŸ¤– å¯¹è¯åŠ©æ‰‹å·²å¯åŠ¨")
    print("=" * 60)
    print("\nç‰¹æ€§ï¼š")
    print("  - ğŸ’­ å¯è§‚æµ‹çš„æ€è€ƒè¿‡ç¨‹")
    print("  - ğŸ“š æ™ºèƒ½çŸ¥è¯†åº“æŸ¥è¯¢")
    print("  - ğŸ”„ å¤šè½®å¯¹è¯è®°å¿†")
    print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")

    conversation_history = []

    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n\nğŸ‘‹ å†è§ï¼")
            break

        if not user_input:
            continue

        if user_input.lower() in ["quit", "exit", "é€€å‡º"]:
            print("\nğŸ‘‹ å†è§ï¼")
            break

        # æ¸…ç©ºè§‚å¯Ÿå™¨ç¼“å†²åŒº
        observer.thinking_buffer.clear()
        observer.knowledge_queries.clear()
        observer.tool_calls.clear()

        print(f"\nğŸ¤– åŠ©æ‰‹: ", end="", flush=True)

        # åˆ›å»ºä»»åŠ¡
        task = Task(
            task_id=f"chat-{len(conversation_history)}",
            action="chat",
            parameters={
                "content": user_input,
                "history": conversation_history[-5:],  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯
            },
        )

        # æ‰§è¡Œä»»åŠ¡
        try:
            result = await agent.execute(task)
            response = result.result.get("response", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚")

            # æ·»åŠ åˆ°å¯¹è¯å†å²
            conversation_history.append({
                "role": "user",
                "content": user_input,
            })
            conversation_history.append({
                "role": "assistant",
                "content": response,
            })

            print(f"\n\nâœ“ å®Œæˆ")

        except Exception as e:
            print(f"\n\nâŒ é”™è¯¯: {e}")


# ==================== ä¸»å‡½æ•° ====================

async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("å¯¹è¯åŠ©æ‰‹ Demo")
    print("=" * 60)

    # 1. åˆ›å»ºEventBuså’Œè§‚å¯Ÿå™¨
    event_bus = EventBus()
    observer = ConversationObserver()
    event_bus.register_handler("*", observer.on_event)

    # 2. åˆ›å»ºLoomApp
    app = LoomApp(event_bus=event_bus)

    # 3. é…ç½®LLM
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return

    llm = OpenAIProvider(
        api_key=api_key,
        model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
    )
    app.set_llm_provider(llm)

    print("âœ“ LLMå·²é…ç½®")

    # 3. é…ç½®çŸ¥è¯†åº“
    knowledge_base = ConversationalKnowledgeBase()
    app.set_knowledge_base(knowledge_base)
    print(f"âœ“ çŸ¥è¯†åº“å·²é…ç½® ({len(knowledge_base.knowledge_data)} æ¡çŸ¥è¯†)")

    # 4. åˆ›å»ºEventBuså’Œè§‚å¯Ÿå™¨
    event_bus = EventBus()
    observer = ConversationObserver()
    event_bus.register_handler("*", observer.on_event)
    print("âœ“ äº‹ä»¶è§‚å¯Ÿå™¨å·²é…ç½®")

    # 4.5 æ·»åŠ å·¥å…·
    tools = [
        create_calculator_tool(),
        create_search_tool(),
    ]
    app.add_tools(tools)
    print(f"âœ“ å·¥å…·å·²é…ç½® ({len(tools)} ä¸ªå·¥å…·)")

    # 5. åˆ›å»ºAgenté…ç½®
    config = AgentConfig(
        agent_id="conversational-assistant",
        name="å¯¹è¯åŠ©æ‰‹",
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- è¯­ä¹‰è¿è´¯ï¼Œè¡¨è¾¾æ¸…æ™°
- å–„äºåˆ†æå¤æ‚é—®é¢˜
- èƒ½å¤Ÿåˆ©ç”¨çŸ¥è¯†åº“æä¾›å‡†ç¡®ä¿¡æ¯
- æ€è€ƒè¿‡ç¨‹é€æ˜å¯è§

è¯·ç”¨è‡ªç„¶ã€æµç•…çš„è¯­è¨€å›ç­”ç”¨æˆ·é—®é¢˜ã€‚""",
        knowledge_max_items=3,
        knowledge_relevance_threshold=0.75,
    )

    # 6. åˆ›å»ºAgent
    agent = app.create_agent(config)
    print(f"âœ“ Agentå·²åˆ›å»º: {agent.node_id}")

    # 7. å¯åŠ¨å¯¹è¯å¾ªç¯
    await conversation_loop(agent, observer)


if __name__ == "__main__":
    asyncio.run(main())

