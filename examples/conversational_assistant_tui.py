"""
å¯¹è¯åŠ©æ‰‹ TUI Demo - åŸºäºTextualçš„äº¤äº’å¼ç•Œé¢

ç‰¹æ€§ï¼š
- å®æ—¶å¯¹è¯äº¤äº’
- å¯è§‚æµ‹çš„æ€è€ƒè¿‡ç¨‹
- æ™ºèƒ½RAGçŸ¥è¯†åº“
- å·¥å…·å’ŒSkillé›†æˆ
- æµå¼è¾“å‡º

è¿è¡Œï¼š
  OPENAI_API_KEY=... python examples/conversational_assistant_tui.py

å¿«æ·é”®ï¼š
  - Tab: åˆ‡æ¢é¢æ¿
  - Ctrl+C: é€€å‡º
"""

import asyncio
import os
from dataclasses import dataclass, field
from typing import Any
from uuid import uuid4

from textual.app import App, ComposeResult
from textual.containers import Horizontal, Vertical
from textual.widgets import Footer, Header, Input, RichLog, Static

from loom.agent import Agent
from loom.tools.registry import ToolRegistry
from loom.config.llm import LLMConfig
from loom.events import EventBus
from loom.protocol import Task
from loom.providers.knowledge.base import KnowledgeBaseProvider, KnowledgeItem
from loom.providers.llm.openai import OpenAIProvider

# ==================== æ•°æ®ç»“æ„ ====================


@dataclass
class ParadigmStats:
    """èŒƒå¼ç»Ÿè®¡ - è·Ÿè¸ªå„ç§AIèƒ½åŠ›çš„ä½¿ç”¨"""

    reflection_events: int = 0
    tool_calls: int = 0
    planning_events: int = 0
    collaboration_events: int = 0
    context_queries: int = 0
    tool_creation_events: int = 0
    created_tools: list[str] = field(default_factory=list)


@dataclass
class ConversationState:
    """å¯¹è¯çŠ¶æ€ï¼ˆå¢å¼ºç‰ˆ - ç»¼åˆä¸¤ä¸ªdemoçš„ä¼˜åŠ¿ï¼‰"""

    # ===== åŸæœ‰å­—æ®µï¼ˆconversational_assistant_tui.pyï¼‰=====
    # å¯¹è¯å†å²
    messages: list[dict[str, str]] = field(default_factory=list)

    # çŸ¥è¯†åº“æŸ¥è¯¢è®°å½•
    knowledge_queries: int = 0

    # å½“å‰å›åˆä½¿ç”¨çš„çŸ¥è¯†é¡¹
    current_knowledge_items: list[dict] = field(default_factory=list)

    # ç»Ÿè®¡ä¿¡æ¯
    total_messages: int = 0
    total_tokens: int = 0

    # ===== æ–°å¢å­—æ®µï¼ˆå‚è€ƒcli_stream_demo_v4.pyï¼‰=====
    # åˆ†å½¢agentè·Ÿè¸ª
    current_thinking: dict[str, str] = field(default_factory=dict)  # base_task_id -> content
    thinking_order: list[str] = field(default_factory=list)  # æ€è€ƒé¡ºåº
    node_depth: dict[str, int] = field(default_factory=dict)  # èŠ‚ç‚¹æ·±åº¦
    task_nodes: dict[str, str] = field(default_factory=dict)  # task_id -> node_id
    parent_map: dict[str, str | None] = field(default_factory=dict)  # çˆ¶å­å…³ç³»
    task_names: dict[str, str] = field(default_factory=dict)  # ä»»åŠ¡åç§°

    # æµå¼æ˜¾ç¤º
    pending_sentences: list[tuple[str, str, str]] = field(
        default_factory=list
    )  # (task_id, node_id, chunk)

    # å·¥å…·è°ƒç”¨è·Ÿè¸ªï¼ˆå¢å¼ºç‰ˆï¼‰
    tool_calls: list[tuple[str, str, str, dict]] = field(
        default_factory=list
    )  # (task_id, node_id, tool, args)
    tool_results: list[tuple[str, str, str, str]] = field(
        default_factory=list
    )  # (task_id, node_id, tool, result)

    # è§„åˆ’äº‹ä»¶
    plans: list[tuple[str, str, dict]] = field(default_factory=list)  # (task_id, node_id, plan)

    # è¿è¡ŒçŠ¶æ€
    nodes_used: set[str] = field(default_factory=set)
    tasks_seen: set[str] = field(default_factory=set)
    running_nodes: set[str] = field(default_factory=set)
    running_tasks: set[str] = field(default_factory=set)
    max_depth: int = 0

    # èŒƒå¼ç»Ÿè®¡
    paradigms: ParadigmStats = field(default_factory=ParadigmStats)

    # æ˜¾ç¤ºæ¨¡å¼
    continuous_mode: bool = True  # è¿ç»­æ¨¡å¼ï¼šåˆå¹¶å­agentè¾“å‡º
    current_paradigm: str = "Idle"
    is_processing: bool = False


# ==================== è¾…åŠ©å‡½æ•° ====================


def shorten_id(full_id: str, length: int = 8) -> str:
    """ç¼©çŸ­é•¿IDä»¥ä¾¿æ˜¾ç¤º"""
    if len(full_id) <= length:
        return full_id
    parts = full_id.split("-")
    if len(parts) > 1:
        return parts[-1][:length]
    return full_id[:length]


# ==================== çŸ¥è¯†åº“ ====================


class ConversationalKnowledgeBase(KnowledgeBaseProvider):
    """å¯¹è¯çŸ¥è¯†åº“"""

    def __init__(self):
        self.knowledge_data = [
            {
                "id": "kb_python_001",
                "content": "Pythonå¼‚æ­¥ç¼–ç¨‹åŸºäºäº‹ä»¶å¾ªç¯å’Œåç¨‹ï¼Œä½¿ç”¨async/awaitè¯­æ³•ã€‚",
                "source": "PythonæŒ‡å—",
                "tags": ["python", "async"],
            },
            {
                "id": "kb_llm_001",
                "content": "å¤§è¯­è¨€æ¨¡å‹é€šè¿‡Transformeræ¶æ„å­¦ä¹ è¯­è¨€è§„å¾‹ã€‚",
                "source": "LLMæ¦‚è§ˆ",
                "tags": ["llm", "ai"],
            },
            {
                "id": "kb_rag_001",
                "content": "RAGç»“åˆæ£€ç´¢å’Œç”Ÿæˆï¼Œæä¾›æ›´å‡†ç¡®çš„ç­”æ¡ˆã€‚",
                "source": "RAGæŠ€æœ¯",
                "tags": ["rag", "retrieval"],
            },
        ]

    async def query(self, query: str, limit: int = 3) -> list[KnowledgeItem]:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        query_lower = query.lower()
        results = []

        for item in self.knowledge_data:
            relevance = 0.0
            if query_lower in item["content"].lower():
                relevance = 0.9
            elif any(query_lower in tag for tag in item["tags"]):
                relevance = 0.8

            if relevance > 0:
                results.append(
                    KnowledgeItem(
                        id=item["id"],
                        content=item["content"],
                        source=item["source"],
                        relevance=relevance,
                    )
                )

        results.sort(key=lambda x: x.relevance, reverse=True)
        return results[:limit]

    async def get_by_id(self, knowledge_id: str) -> KnowledgeItem | None:
        """æ ¹æ®IDè·å–çŸ¥è¯†é¡¹"""
        for item in self.knowledge_data:
            if item["id"] == knowledge_id:
                return KnowledgeItem(
                    id=item["id"],
                    content=item["content"],
                    source=item["source"],
                    relevance=1.0,
                )
        return None


# ==================== å·¥å…·å®šä¹‰ ====================


# å·¥å…·å®ç°å‡½æ•°
async def calculator(expression: str) -> str:
    """
    è®¡ç®—å™¨å·¥å…·å®ç°

    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼

    Returns:
        è®¡ç®—ç»“æœ
    """
    try:
        # ä½¿ç”¨ eval è®¡ç®—è¡¨è¾¾å¼ï¼ˆæ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•ï¼‰
        result = eval(expression, {"__builtins__": {}}, {})
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


async def search_knowledge(query: str) -> str:
    """
    æœç´¢çŸ¥è¯†åº“å·¥å…·å®ç°

    Args:
        query: æœç´¢æŸ¥è¯¢

    Returns:
        æœç´¢ç»“æœ
    """
    # æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°ä¼šåœ¨ main() ä¸­è¢«é‡æ–°å®šä¹‰ï¼Œä»¥è®¿é—® knowledge_base
    return "çŸ¥è¯†åº“æœç´¢åŠŸèƒ½éœ€è¦åœ¨åˆå§‹åŒ–åä½¿ç”¨"


def create_calculator_tool():
    """è®¡ç®—å™¨å·¥å…·"""
    return {
        "type": "function",
        "function": {
            "name": "calculator",
            "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—",
            "parameters": {
                "type": "object",
                "properties": {"expression": {"type": "string", "description": "æ•°å­¦è¡¨è¾¾å¼"}},
                "required": ["expression"],
            },
        },
    }


def create_search_tool():
    """æœç´¢å·¥å…·"""
    return {
        "type": "function",
        "function": {
            "name": "search_knowledge",
            "description": "æœç´¢çŸ¥è¯†åº“ä¸­çš„ç›¸å…³ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {"query": {"type": "string", "description": "æœç´¢æŸ¥è¯¢"}},
                "required": ["query"],
            },
        },
    }


# ==================== äº‹ä»¶å¤„ç†å™¨ ====================


class EventProcessor:
    """äº‹ä»¶å¤„ç†å™¨ - å¤„ç†Agentäº‹ä»¶å¹¶æ›´æ–°TUIï¼ˆå¢å¼ºç‰ˆ - ç»¼åˆä¸¤ä¸ªdemoï¼‰"""

    def __init__(self, app: "ConversationalAssistantApp", session_id: str):
        self.app = app
        self.session_id = session_id
        self.state = app.state  # ç›´æ¥å¼•ç”¨appçš„state

        # åŸæœ‰å­—æ®µï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰
        self.current_stage = None
        self.knowledge_items = []
        self.streaming_response = ""
        self.is_streaming = False

    def _base_task_id(self, event_task_id: str) -> str:
        """æå–åŸºç¡€task ID"""
        if ":event:" in event_task_id:
            return event_task_id.split(":event:", 1)[0]
        return event_task_id

    def _infer_parent(self, task_id: str) -> str | None:
        """æ¨æ–­çˆ¶task ID"""
        for marker in ("-child-", "-step-"):
            if marker in task_id:
                return task_id.split(marker, 1)[0]
        return None

    def _calculate_depth(self, task_id: str) -> int:
        """è®¡ç®—ä»»åŠ¡åœ¨å±‚çº§ä¸­çš„æ·±åº¦"""
        depth = 0
        current = task_id
        while current in self.state.parent_map and self.state.parent_map[current] is not None:
            depth += 1
            parent = self.state.parent_map[current]
            assert parent is not None
            current = parent
            if depth > 10:  # é˜²æ­¢æ— é™å¾ªç¯
                break
        return depth

    async def on_event(self, task: Task) -> Task:
        """å¤„ç†äº‹ä»¶ï¼ˆå¢å¼ºç‰ˆ - æ·»åŠ åˆ†å½¢agentè·Ÿè¸ªï¼‰"""
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ parameters ä¸ä¸º None
        if task.parameters is None:
            return task

        # Sessionè¿‡æ»¤
        if task.session_id != self.session_id:
            return task

        # æå–èŠ‚ç‚¹ä¿¡æ¯
        node_id = task.parameters.get("node_id", "unknown")
        if node_id:
            self.state.nodes_used.add(node_id)

        # æå–base_task_idå¹¶è·Ÿè¸ª
        base_task_id = self._base_task_id(task.task_id)
        if base_task_id not in self.state.tasks_seen:
            self.state.tasks_seen.add(base_task_id)
            self.state.parent_map[base_task_id] = self._infer_parent(base_task_id)
            self.state.task_names[base_task_id] = shorten_id(base_task_id)
            depth = self._calculate_depth(base_task_id)
            self.state.node_depth[base_task_id] = depth
            if depth > self.state.max_depth:
                self.state.max_depth = depth

        if base_task_id not in self.state.task_nodes and node_id:
            self.state.task_nodes[base_task_id] = node_id

        # è·¯ç”±åˆ°å…·ä½“çš„äº‹ä»¶å¤„ç†å™¨
        action = task.action
        if action == "node.thinking":
            await self._handle_thinking(task, base_task_id, node_id)
        elif action == "node.tool_call":
            await self._handle_tool_call(task, base_task_id, node_id)
        elif action == "node.tool_result":
            await self._handle_tool_result(task, base_task_id, node_id)
        elif action == "node.planning":
            await self._handle_planning(task, base_task_id, node_id)
        elif action == "node.knowledge_query":
            await self._handle_knowledge_query(task, base_task_id, node_id)
        elif action == "node.knowledge_result":
            await self._handle_knowledge_result(task, base_task_id, node_id)
        elif action == "node.response":
            await self._handle_response(task, base_task_id, node_id)
        elif action in {"node.start", "node.complete"}:
            await self._handle_lifecycle(task, base_task_id)

        return task

    async def _handle_thinking(self, task: Task, base_task_id: str, node_id: str) -> None:
        """å¤„ç†æ€è€ƒäº‹ä»¶ - ç´¯ç§¯å†…å®¹å¹¶æ”¯æŒæµå¼æ˜¾ç¤º"""
        content = task.parameters.get("content", "")
        stage = task.parameters.get("stage", None)

        if not content:
            return

        # ç´¯ç§¯æ€è€ƒå†…å®¹ï¼ˆæŒ‰task_idåˆ†ç»„ï¼‰
        if base_task_id not in self.state.current_thinking:
            self.state.current_thinking[base_task_id] = ""
            self.state.thinking_order.append(base_task_id)

        self.state.current_thinking[base_task_id] += content

        # æ·»åŠ åˆ°pending_sentencesç”¨äºæµå¼æ˜¾ç¤º
        self.state.pending_sentences.append((base_task_id, node_id, content))

        # æ›´æ–°èŒƒå¼ç»Ÿè®¡
        self.state.current_paradigm = "Reflection"
        self.state.paradigms.reflection_events += 1

        # æ˜¾ç¤ºé€»è¾‘ï¼šæ ¹æ®continuous_modeå†³å®šå¦‚ä½•æ˜¾ç¤º
        if self.state.continuous_mode:
            # è¿ç»­æ¨¡å¼ï¼šåœ¨èŠå¤©çª—å£ä¸­æµå¼æ˜¾ç¤ºï¼Œä¸æ˜¾ç¤ºèŠ‚ç‚¹ID
            if stage and stage != self.current_stage:
                self.current_stage = stage
                if stage == "generating":
                    self.is_streaming = True
                    self.streaming_response = ""
                    await self.app.start_streaming_response()

            if self.is_streaming:
                self.streaming_response += content
                await self.app.update_streaming_response(content)
            else:
                # åœ¨æ€è€ƒé¢æ¿æ˜¾ç¤º
                await self.app.update_thinking(content)
        else:
            # è¯¦ç»†æ¨¡å¼ï¼šæ˜¾ç¤ºèŠ‚ç‚¹ä¿¡æ¯
            if stage and stage != self.current_stage:
                self.current_stage = stage
                await self.app.show_thinking_stage(stage)

            await self.app.update_thinking(content)

    async def _handle_tool_call(self, task: Task, base_task_id: str, node_id: str) -> None:
        """å¤„ç†å·¥å…·è°ƒç”¨äº‹ä»¶"""
        tool_name = task.parameters.get("tool_name", "")
        tool_args = task.parameters.get("tool_args", {})

        self.state.tool_calls.append((base_task_id, node_id, tool_name, tool_args))

        # æ›´æ–°èŒƒå¼ç»Ÿè®¡
        if tool_name == "create_plan":
            self.state.paradigms.planning_events += 1
            self.state.current_paradigm = "Planning"
        elif tool_name == "delegate_task":
            self.state.paradigms.collaboration_events += 1
            self.state.current_paradigm = "Collaboration"
        elif tool_name == "create_tool":
            self.state.paradigms.tool_creation_events += 1
            self.state.current_paradigm = "Tool Creation"
            created_tool = tool_args.get("tool_name", "")
            if created_tool:
                self.state.paradigms.created_tools.append(created_tool)
        elif tool_name.startswith("query_"):
            self.state.paradigms.context_queries += 1
            self.state.current_paradigm = "Context Query"
        else:
            self.state.paradigms.tool_calls += 1
            self.state.current_paradigm = "Tool Use"

        # æ˜¾ç¤ºå·¥å…·è°ƒç”¨
        await self.app.add_tool_call(tool_name, tool_args)

    async def _handle_tool_result(self, task: Task, base_task_id: str, node_id: str) -> None:
        """å¤„ç†å·¥å…·ç»“æœäº‹ä»¶"""
        tool_name = task.parameters.get("tool_name", "")
        result = task.parameters.get("result", "")
        result_str = result if isinstance(result, str) else str(result)

        self.state.tool_results.append((base_task_id, node_id, tool_name, result_str))

        # æ˜¾ç¤ºå·¥å…·ç»“æœï¼ˆå¯é€‰ï¼Œé¿å…è¿‡å¤šè¾“å‡ºï¼‰
        # await self.app.add_tool_result(tool_name, result_str)

    async def _handle_planning(self, task: Task, base_task_id: str, node_id: str) -> None:
        """å¤„ç†è§„åˆ’äº‹ä»¶"""
        plan = {
            "goal": task.parameters.get("goal", ""),
            "steps": task.parameters.get("steps", []),
            "reasoning": task.parameters.get("reasoning", ""),
            "step_count": task.parameters.get("step_count", 0),
        }
        self.state.plans.append((base_task_id, node_id, plan))
        self.state.current_paradigm = "Planning"

        # åœ¨æ€è€ƒé¢æ¿æ˜¾ç¤ºè§„åˆ’
        await self.app.show_planning(plan)

    async def _handle_knowledge_query(self, task: Task, base_task_id: str, node_id: str) -> None:
        """å¤„ç†çŸ¥è¯†åº“æŸ¥è¯¢äº‹ä»¶"""
        query = task.parameters.get("query", "")
        await self.app.show_knowledge_query(query)

    async def _handle_knowledge_result(self, task: Task, base_task_id: str, node_id: str) -> None:
        """å¤„ç†çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœäº‹ä»¶"""
        items = task.parameters.get("items", [])
        self.knowledge_items = items
        self.state.current_knowledge_items = items
        await self.app.show_knowledge_results(items)

    async def _handle_response(self, task: Task, base_task_id: str, node_id: str) -> None:
        """å¤„ç†æœ€ç»ˆå“åº”äº‹ä»¶"""
        response = task.parameters.get("content", "")

        # å¦‚æœæœ‰æµå¼å“åº”ï¼Œä½¿ç”¨ç´¯ç§¯çš„å†…å®¹
        if self.is_streaming and self.streaming_response:
            response = self.streaming_response
            await self.app.finish_streaming_response()
        else:
            # éæµå¼å“åº”ï¼Œç›´æ¥æ˜¾ç¤º
            await self.app.add_response(response)

        # é‡ç½®çŠ¶æ€
        self.current_stage = None
        self.knowledge_items = []
        self.streaming_response = ""
        self.is_streaming = False

    async def _handle_lifecycle(self, task: Task, base_task_id: str) -> None:
        """å¤„ç†ç”Ÿå‘½å‘¨æœŸäº‹ä»¶"""
        if task.action == "node.start":
            self.state.running_tasks.add(base_task_id)
        else:
            self.state.running_tasks.discard(base_task_id)


# ==================== TUI ç»„ä»¶ ====================


class ChatWindow(RichLog):
    """èŠå¤©çª—å£"""

    def __init__(self):
        super().__init__(
            highlight=True,
            markup=True,
            wrap=True,
            auto_scroll=True,
        )
        self.border_title = "ğŸ’¬ å¯¹è¯"


class ThinkingPanel(RichLog):
    """æ€è€ƒé¢æ¿"""

    def __init__(self):
        super().__init__(
            highlight=True,
            markup=True,
            wrap=True,
            auto_scroll=True,
        )
        self.border_title = "ğŸ’­ æ€è€ƒè¿‡ç¨‹"


class StatsPanel(Static):
    """ç»Ÿè®¡é¢æ¿ï¼ˆå¢å¼ºç‰ˆ - æ˜¾ç¤ºèŒƒå¼ç»Ÿè®¡å’Œåˆ†å½¢agentä¿¡æ¯ï¼‰"""

    def __init__(self, state: ConversationState):
        super().__init__()
        self.border_title = "ğŸ“Š ç»Ÿè®¡"
        self.state = state

    def update_display(self):
        """æ›´æ–°ç»Ÿè®¡æ˜¾ç¤º"""
        self.update(self._render_stats())

    def _render_stats(self) -> str:
        """æ¸²æŸ“ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        # åŸºç¡€ç»Ÿè®¡
        basic_stats = f"""[bold cyan]å¯¹è¯ç»Ÿè®¡[/bold cyan]
æ¶ˆæ¯æ•°: {self.state.total_messages}
å·¥å…·è°ƒç”¨: {len(self.state.tool_calls)}
çŸ¥è¯†æŸ¥è¯¢: {self.state.knowledge_queries}
"""

        # åˆ†å½¢Agentç»Ÿè®¡
        fractal_stats = f"""
[bold green]åˆ†å½¢Agent[/bold green]
èŠ‚ç‚¹æ•°: {len(self.state.nodes_used)}
ä»»åŠ¡æ•°: {len(self.state.tasks_seen)}
æœ€å¤§æ·±åº¦: {self.state.max_depth}
å½“å‰èŒƒå¼: {self.state.current_paradigm}
"""

        # èŒƒå¼ç»Ÿè®¡
        paradigm_stats = f"""
[bold magenta]èŒƒå¼ç»Ÿè®¡[/bold magenta]
åæ€äº‹ä»¶: {self.state.paradigms.reflection_events}
è§„åˆ’äº‹ä»¶: {self.state.paradigms.planning_events}
åä½œäº‹ä»¶: {self.state.paradigms.collaboration_events}
å·¥å…·åˆ›å»º: {self.state.paradigms.tool_creation_events}
ä¸Šä¸‹æ–‡æŸ¥è¯¢: {self.state.paradigms.context_queries}
"""

        return basic_stats + fractal_stats + paradigm_stats


# ==================== ä¸»åº”ç”¨ ====================


class ConversationalAssistantApp(App):
    """å¯¹è¯åŠ©æ‰‹ TUI åº”ç”¨"""

    CSS = """
    Screen {
        layout: vertical;
    }

    #main-container {
        layout: horizontal;
        height: 1fr;
    }

    #left-panel {
        width: 2fr;
        layout: vertical;
    }

    #right-panel {
        width: 1fr;
        layout: vertical;
    }

    ChatWindow {
        height: 1fr;
        border: solid green;
    }

    ThinkingPanel {
        height: 1fr;
        border: solid yellow;
    }

    StatsPanel {
        height: 10;
        border: solid cyan;
    }

    Input {
        dock: bottom;
    }
    """

    def __init__(self, agent: Any, session_id: str):
        super().__init__()
        self.agent = agent
        self.session_id = session_id
        self.state = ConversationState()
        self.chat_window = None
        self.thinking_panel = None
        self.stats_panel = None
        self.event_queue: asyncio.Queue = asyncio.Queue()

    def compose(self) -> ComposeResult:
        """ç»„åˆUI"""
        yield Header()
        with Horizontal(id="main-container"):
            with Vertical(id="left-panel"):
                self.chat_window = ChatWindow()
                yield self.chat_window
            with Vertical(id="right-panel"):
                self.thinking_panel = ThinkingPanel()
                yield self.thinking_panel
                self.stats_panel = StatsPanel(self.state)
                yield self.stats_panel
        yield Input(placeholder="è¾“å…¥æ¶ˆæ¯... (è¾“å…¥ 'quit' é€€å‡º)")
        yield Footer()

    async def on_mount(self):
        """åº”ç”¨å¯åŠ¨æ—¶"""
        self.chat_window.write("[bold green]ğŸ¤– å¯¹è¯åŠ©æ‰‹å·²å¯åŠ¨[/bold green]")
        self.chat_window.write("[dim]ç‰¹æ€§: æ™ºèƒ½RAG | å·¥å…·è°ƒç”¨ | Skillé›†æˆ | å¯è§‚æµ‹æ€è€ƒ[/dim]")
        self.chat_window.write("")

    async def on_input_submitted(self, event: Input.Submitted):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        user_input = event.value.strip()
        if not user_input:
            return

        # æ¸…ç©ºè¾“å…¥æ¡†
        event.input.value = ""

        # æ£€æŸ¥é€€å‡ºå‘½ä»¤
        if user_input.lower() in ["quit", "exit", "é€€å‡º"]:
            self.exit()
            return

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        self.chat_window.write(f"[bold cyan]ğŸ‘¤ ä½ :[/bold cyan] {user_input}")
        self.chat_window.write("")

        # æ¸…ç©ºæ€è€ƒé¢æ¿
        self.thinking_panel.clear()

        # å¤„ç†æ¶ˆæ¯
        await self._process_message(user_input)

    async def update_thinking(self, content: str):
        """æ›´æ–°æ€è€ƒé¢æ¿"""
        self.thinking_panel.write(content, end="")

    async def show_thinking_stage(self, stage: str):
        """æ˜¾ç¤ºæ€è€ƒé˜¶æ®µ"""
        stage_names = {
            "understanding": "ğŸ¤” ç†è§£é—®é¢˜",
            "retrieving": "ğŸ“š æ£€ç´¢çŸ¥è¯†",
            "analyzing": "ğŸ” åˆ†ææ¨ç†",
            "generating": "âœï¸ ç”Ÿæˆå›ç­”",
        }
        stage_display = stage_names.get(stage, f"ğŸ’­ {stage}")
        self.thinking_panel.write(f"\n\n[bold magenta]{'='*40}[/bold magenta]")
        self.thinking_panel.write(f"\n[bold magenta]{stage_display}[/bold magenta]")
        self.thinking_panel.write(f"\n[bold magenta]{'='*40}[/bold magenta]\n")

    async def show_knowledge_query(self, query: str):
        """æ˜¾ç¤ºçŸ¥è¯†åº“æŸ¥è¯¢"""
        self.state.knowledge_queries += 1
        self.thinking_panel.write(f"\n[bold yellow]ğŸ“š æŸ¥è¯¢çŸ¥è¯†åº“:[/bold yellow] [dim]{query}[/dim]")
        self._update_stats()

    async def show_knowledge_results(self, items: list):
        """æ˜¾ç¤ºçŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ"""
        if items:
            self.thinking_panel.write(
                f"\n[bold yellow]âœ“ æ£€ç´¢åˆ° {len(items)} æ¡ç›¸å…³çŸ¥è¯†:[/bold yellow]"
            )
            for i, item in enumerate(items, 1):
                relevance = item.get("relevance", 0.0)
                source = item.get("source", "æœªçŸ¥æ¥æº")
                content_preview = item.get("content", "")[:60] + "..."
                self.thinking_panel.write(
                    f"\n  {i}. [dim]({relevance:.2f})[/dim] {source}: {content_preview}"
                )
        else:
            self.thinking_panel.write("\n[dim]æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†[/dim]")

    async def show_planning(self, plan: dict):
        """æ˜¾ç¤ºè§„åˆ’äº‹ä»¶"""
        goal = plan.get("goal", "")
        steps = plan.get("steps", [])
        reasoning = plan.get("reasoning", "")

        self.thinking_panel.write("\n[bold cyan]ğŸ“‹ è§„åˆ’:[/bold cyan]")
        if goal:
            self.thinking_panel.write(f"  ç›®æ ‡: {goal}")
        if reasoning:
            self.thinking_panel.write(f"  æ¨ç†: {reasoning}")
        if steps:
            self.thinking_panel.write(f"  æ­¥éª¤ ({len(steps)}):")
            for i, step in enumerate(steps, 1):
                self.thinking_panel.write(f"    {i}. {step}")

    async def add_tool_call(self, tool_name: str, tool_args: dict = None):
        """æ·»åŠ å·¥å…·è°ƒç”¨è®°å½•"""
        self.state.tool_calls.append((tool_name, tool_args or {}))
        args_str = ""
        if tool_args:
            args_preview = str(tool_args)[:50]
            args_str = (
                f" [dim]({args_preview}...)[/dim]"
                if len(str(tool_args)) > 50
                else f" [dim]({args_preview})[/dim]"
            )
        self.thinking_panel.write(f"\n[bold green]ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}{args_str}[/bold green]")
        self._update_stats()

    async def increment_knowledge_queries(self):
        """å¢åŠ çŸ¥è¯†åº“æŸ¥è¯¢è®¡æ•°ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        self.state.knowledge_queries += 1
        self._update_stats()

    async def add_response(self, response: str):
        """æ·»åŠ åŠ©æ‰‹å“åº”ï¼ˆä¼˜åŒ–ç‰ˆ - æ˜¾ç¤ºçŸ¥è¯†æ¥æºï¼‰"""
        self.chat_window.write(f"[bold green]ğŸ¤– åŠ©æ‰‹:[/bold green] {response}")

        # å¦‚æœä½¿ç”¨äº†çŸ¥è¯†åº“ï¼Œæ˜¾ç¤ºçŸ¥è¯†æ¥æº
        if self.state.current_knowledge_items:
            sources = set()
            for item in self.state.current_knowledge_items:
                source = item.get("source", "æœªçŸ¥æ¥æº")
                sources.add(source)

            if sources:
                sources_str = ", ".join(sources)
                self.chat_window.write(f"[dim]ğŸ“š å‚è€ƒæ¥æº: {sources_str}[/dim]")

        self.chat_window.write("")
        self.state.total_messages += 1
        # æ¸…ç©ºå½“å‰çŸ¥è¯†é¡¹ï¼Œå‡†å¤‡ä¸‹ä¸€è½®
        self.state.current_knowledge_items = []
        self._update_stats()

    async def start_streaming_response(self):
        """å¼€å§‹æµå¼å“åº”ï¼ˆæ‰“å­—æœºæ•ˆæœï¼‰"""
        self.chat_window.write("[bold green]ğŸ¤– åŠ©æ‰‹:[/bold green] ", end="")

    async def update_streaming_response(self, content: str):
        """æ›´æ–°æµå¼å“åº”ï¼ˆé€å­—ç¬¦æ˜¾ç¤ºï¼‰"""
        self.chat_window.write(content, end="")

    async def finish_streaming_response(self):
        """å®Œæˆæµå¼å“åº”"""
        # å¦‚æœä½¿ç”¨äº†çŸ¥è¯†åº“ï¼Œæ˜¾ç¤ºçŸ¥è¯†æ¥æº
        if self.state.current_knowledge_items:
            sources = set()
            for item in self.state.current_knowledge_items:
                source = item.get("source", "æœªçŸ¥æ¥æº")
                sources.add(source)

            if sources:
                sources_str = ", ".join(sources)
                self.chat_window.write(f"\n[dim]ğŸ“š å‚è€ƒæ¥æº: {sources_str}[/dim]")

        self.chat_window.write("")
        self.state.total_messages += 1
        # æ¸…ç©ºå½“å‰çŸ¥è¯†é¡¹ï¼Œå‡†å¤‡ä¸‹ä¸€è½®
        self.state.current_knowledge_items = []
        self._update_stats()

    def _update_stats(self):
        """æ›´æ–°ç»Ÿè®¡é¢æ¿"""
        self.stats_panel.update_display()

    async def process_events(self) -> None:
        """å¤„ç†äº‹ä»¶é˜Ÿåˆ—å¹¶å®ç°æµå¼æ˜¾ç¤ºï¼ˆå‚è€ƒdemo_v4ï¼‰"""
        displayed_chunks = 0
        displayed_tool_calls = 0
        current_node_buffer: dict[str, str] = {}
        last_display_time = 0.0

        while True:
            try:
                event = await asyncio.wait_for(self.event_queue.get(), timeout=0.1)
                if event is None:  # åœæ­¢ä¿¡å·
                    break

                # å¤„ç†äº‹ä»¶ï¼ˆæ›´æ–°stateï¼‰
                # EventProcessorä¼šæ›´æ–°self.state

                import time

                current_time = time.time()

                # å¤„ç†æ–°çš„æ€è€ƒå†…å®¹
                if len(self.state.pending_sentences) > displayed_chunks:
                    new_chunks = self.state.pending_sentences[displayed_chunks:]
                    for base_task_id, _, chunk in new_chunks:
                        if base_task_id not in current_node_buffer:
                            current_node_buffer[base_task_id] = ""
                        current_node_buffer[base_task_id] += chunk
                    displayed_chunks = len(self.state.pending_sentences)

                # æ¯0.3ç§’æ‰¹é‡æ˜¾ç¤º
                if current_time - last_display_time > 0.3 and current_node_buffer:
                    for base_task_id, content in list(current_node_buffer.items()):
                        if content:
                            await self.update_streaming_response(content)
                            current_node_buffer[base_task_id] = ""
                    last_display_time = current_time

                # å¤„ç†å·¥å…·è°ƒç”¨
                if len(self.state.tool_calls) > displayed_tool_calls:
                    new_calls = self.state.tool_calls[displayed_tool_calls:]
                    for _, _, tool_name, tool_args in new_calls:
                        await self.add_tool_call(tool_name, tool_args)
                    displayed_tool_calls = len(self.state.tool_calls)

            except TimeoutError:
                continue

    def _build_context_summary(self) -> str:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡æ‘˜è¦"""
        if not self.state.messages:
            return "è¿™æ˜¯å¯¹è¯çš„å¼€å§‹ã€‚"

        # è·å–æœ€è¿‘çš„å¯¹è¯
        recent_messages = self.state.messages[-6:]  # æœ€è¿‘3è½®å¯¹è¯

        # æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
        context_parts = []
        context_parts.append(f"å¯¹è¯è½®æ¬¡: {len(self.state.messages) // 2}")

        # æå–æœ€è¿‘è®¨è®ºçš„ä¸»é¢˜
        if len(recent_messages) >= 2:
            last_user_msg = recent_messages[-2]["content"] if len(recent_messages) >= 2 else ""
            if last_user_msg:
                context_parts.append(f"ä¸Šä¸€ä¸ªé—®é¢˜: {last_user_msg[:50]}...")

        return " | ".join(context_parts)

    async def _process_message(self, user_input: str):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆä¼˜åŒ–ç‰ˆ - æ”¯æŒæµå¼æ˜¾ç¤ºï¼‰"""
        try:
            # æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
            context_summary = self._build_context_summary()

            # åˆ›å»ºä»»åŠ¡ï¼ˆå¢å¼ºä¸Šä¸‹æ–‡ï¼‰
            task = Task(
                task_id=f"chat-{self.state.total_messages}",
                action="chat",
                parameters={
                    "content": user_input,
                    "history": self.state.messages[-10:],
                    "context_summary": context_summary,
                    "conversation_turn": len(self.state.messages) // 2 + 1,
                },
                session_id=self.session_id,
            )

            # å¯åŠ¨äº‹ä»¶å¤„ç†å™¨ï¼ˆåå°ä»»åŠ¡ï¼‰
            event_processor_task = asyncio.create_task(self.process_events())

            # å¼€å§‹æµå¼å“åº”
            await self.start_streaming_response()

            # æ‰§è¡Œä»»åŠ¡ï¼ˆåå°ï¼‰
            agent_task = asyncio.create_task(self.agent.execute_task(task))

            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            result = await agent_task

            # åœæ­¢äº‹ä»¶å¤„ç†å™¨
            await self.event_queue.put(None)
            await event_processor_task

            # å®Œæˆæµå¼å“åº”
            await self.finish_streaming_response()

            # æå–å“åº”å†…å®¹
            if result.result and isinstance(result.result, dict):
                response = result.result.get("content", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚")
            else:
                response = str(result.result) if result.result else "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"

            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.state.messages.append({"role": "user", "content": user_input})
            self.state.messages.append({"role": "assistant", "content": response})

            # æ›´æ–°ç»Ÿè®¡
            self._update_stats()

        except Exception as e:
            self.chat_window.write(f"[bold red]âŒ é”™è¯¯: {e}[/bold red]")
            self.chat_window.write("")


# ==================== ä¸»å‡½æ•° ====================


async def main():
    """ä¸»å‡½æ•°"""
    # 1. åˆ›å»ºEventBus
    event_bus = EventBus()

    # 2. é…ç½®LLM
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return

    llm_config = LLMConfig(
        provider="openai",
        model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
        api_key=api_key,
        temperature=0.7,
    )
    llm = OpenAIProvider(llm_config)
    print("âœ“ LLMå·²é…ç½®")

    # 3. é…ç½®çŸ¥è¯†åº“
    knowledge_base = ConversationalKnowledgeBase()
    print(f"âœ“ çŸ¥è¯†åº“å·²é…ç½® ({len(knowledge_base.knowledge_data)} æ¡çŸ¥è¯†)")

    # 4. åˆ›å»ºToolRegistryå¹¶æ³¨å†Œå·¥å…·å®ç°
    tool_registry = ToolRegistry()

    # æ³¨å†Œ calculator å·¥å…·
    tool_registry.register_function(calculator)

    # åˆ›å»º search_knowledge çš„é—­åŒ…ï¼Œä½¿å…¶èƒ½è®¿é—® knowledge_base
    async def search_knowledge_impl(query: str) -> str:
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            results = await knowledge_base.query(query, limit=3)
            if not results:
                return f"æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„çŸ¥è¯†"

            response = f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³çŸ¥è¯†ï¼š\n\n"
            for i, item in enumerate(results, 1):
                response += f"{i}. {item.content}\n"
                response += f"   æ¥æº: {item.source} (ç›¸å…³åº¦: {item.relevance:.2f})\n\n"
            return response
        except Exception as e:
            return f"æœç´¢é”™è¯¯: {str(e)}"

    tool_registry.register_function(search_knowledge_impl, name="search_knowledge")
    print("âœ“ å·¥å…·å·²æ³¨å†Œ (calculator, search_knowledge)")

    # 5. åˆ›å»ºå·¥å…·å®šä¹‰åˆ—è¡¨
    tools = [
        create_calculator_tool(),
        create_search_tool(),
    ]

    # 6. é›†æˆSkillsï¼ˆæš‚æ—¶ç¦ç”¨ï¼Œç­‰å¾… tool_registry å®ç°ï¼‰
    print("âœ“ Skillé›†æˆå·²è·³è¿‡ï¼ˆç­‰å¾… tool_registry å®ç°ï¼‰")

    # 7. åˆ›å»ºAgent
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIå¯¹è¯åŠ©æ‰‹ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- è¯­ä¹‰è¿è´¯ï¼Œè¡¨è¾¾æ¸…æ™°è‡ªç„¶
- å–„äºåˆ†æå¤æ‚é—®é¢˜ï¼Œæä¾›æ·±å…¥è§è§£
- èƒ½å¤Ÿåˆ©ç”¨çŸ¥è¯†åº“æä¾›å‡†ç¡®ä¿¡æ¯
- æ€è€ƒè¿‡ç¨‹é€æ˜å¯è§
- å¯ä»¥è°ƒç”¨å·¥å…·å’ŒSkillsæ¥å¢å¼ºèƒ½åŠ›
- å¯ä»¥åˆ›å»ºå­Agentæ¥å¤„ç†å¤æ‚çš„å­ä»»åŠ¡

**ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ï¼š**
- ä»”ç»†é˜…è¯»å¯¹è¯å†å²ï¼Œç†è§£ä¹‹å‰è®¨è®ºçš„ä¸»é¢˜å’Œä¸Šä¸‹æ–‡
- å½“ç”¨æˆ·ä½¿ç”¨"å®ƒ"ã€"è¿™ä¸ª"ã€"é‚£ä¸ª"ã€"åˆšæ‰"ç­‰æŒ‡ä»£è¯æ—¶ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡ç†è§£å…¶å«ä¹‰
- åœ¨å›ç­”æ—¶è‡ªç„¶åœ°å¼•ç”¨ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œä¿æŒå¯¹è¯è¿è´¯æ€§
- å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸ä¹‹å‰çš„è¯é¢˜ç›¸å…³ï¼Œæ˜ç¡®æŒ‡å‡ºè¿™ç§å…³è”
- è®°ä½ç”¨æˆ·çš„åå¥½å’Œä¹‹å‰æåˆ°çš„ä¿¡æ¯

**å·¥å…·å’ŒSkillä½¿ç”¨ï¼š**
- å½“ç”¨æˆ·éœ€è¦ä»£ç å®¡æŸ¥æ—¶ï¼Œä½¿ç”¨code_reviewå·¥å…·
- å½“ç”¨æˆ·éœ€è¦æ·±åº¦åˆ†ææ—¶ï¼Œå¯ä»¥ä½¿ç”¨deep_analysis skill

**åˆ†å½¢Agentèƒ½åŠ›ï¼ˆä½¿ç”¨delegate_taskå·¥å…·ï¼‰ï¼š**
å½“é‡åˆ°ä»¥ä¸‹æƒ…å†µæ—¶ï¼Œä½¿ç”¨delegate_taskå·¥å…·åˆ›å»ºå­Agentï¼š
- ä»»åŠ¡å¯ä»¥åˆ†è§£ä¸ºå¤šä¸ªç‹¬ç«‹çš„å­ä»»åŠ¡ï¼ˆå¦‚ï¼šè®¾è®¡ç³»ç»Ÿçš„å¤šä¸ªæ¨¡å—ï¼‰
- éœ€è¦æ·±åº¦åˆ†ææˆ–ä¸“ä¸šå¤„ç†ï¼ˆå¦‚ï¼šä»£ç å®¡æŸ¥ã€æ¶æ„è®¾è®¡ã€æ•°æ®åˆ†æï¼‰
- ä»»åŠ¡æ¶‰åŠå¤šä¸ªé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼ˆå¦‚ï¼šå‰ç«¯+åç«¯+æ•°æ®åº“è®¾è®¡ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
delegate_task(
    subtask_description="å…·ä½“çš„å­ä»»åŠ¡æè¿°",
    required_capabilities=["éœ€è¦çš„èƒ½åŠ›åˆ—è¡¨"]
)

ç¤ºä¾‹åœºæ™¯ï¼š
- ç”¨æˆ·ï¼š"è®¾è®¡ä¸€ä¸ªå®Œæ•´çš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿ"
  â†’ ä½¿ç”¨delegate_taskåˆ†åˆ«å¤„ç†ï¼šæ•°æ®åº“è®¾è®¡ã€APIè®¾è®¡ã€å‰ç«¯ç•Œé¢ã€å®‰å…¨ç­–ç•¥
- ç”¨æˆ·ï¼š"åˆ†æè¿™æ®µä»£ç çš„æ€§èƒ½é—®é¢˜"
  â†’ ä½¿ç”¨delegate_taskåˆ›å»ºä¸“é—¨çš„ä»£ç åˆ†æå­Agent

è¯·ç”¨è‡ªç„¶ã€æµç•…çš„è¯­è¨€å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè®©å¯¹è¯åƒä¸çœŸäººäº¤æµä¸€æ ·è‡ªç„¶ã€‚"""

    agent = Agent.from_llm(
        llm=llm,
        node_id="conversational-assistant",
        system_prompt=system_prompt,
        tools=tools,
        event_bus=event_bus,
        knowledge_base=knowledge_base,
        knowledge_max_items=3,
        knowledge_relevance_threshold=0.75,
        require_done_tool=False,
        tool_registry=tool_registry,
    )
    print(f"âœ“ Agentå·²åˆ›å»º: {agent.node_id}")

    # 9. åˆ›å»ºTUIåº”ç”¨å¹¶è®¾ç½®äº‹ä»¶å¤„ç†å™¨
    session_id = str(uuid4())
    tui_app = ConversationalAssistantApp(agent, session_id)

    # åˆ›å»ºäº‹ä»¶å¤„ç†å™¨ï¼ˆç”¨äºå¤„ç†äº‹ä»¶å¹¶æ›´æ–°stateï¼‰
    event_processor = EventProcessor(tui_app, session_id)

    # æ³¨å†Œäº‹ä»¶å¤„ç†å™¨ï¼šå°†äº‹ä»¶æ”¾å…¥é˜Ÿåˆ—ï¼Œç”±process_events()æ‰¹é‡å¤„ç†
    async def handle_event(task: Task) -> Task:
        # å…ˆè®©EventProcessorå¤„ç†äº‹ä»¶ï¼ˆæ›´æ–°stateï¼‰
        await event_processor.on_event(task)
        # ç„¶åæ”¾å…¥é˜Ÿåˆ—ä¾›UIæ˜¾ç¤º
        await tui_app.event_queue.put(task)
        return task

    event_bus.register_handler("*", handle_event)
    print("âœ“ äº‹ä»¶å¤„ç†å™¨å·²é…ç½®")

    # 10. è¿è¡ŒTUIåº”ç”¨
    print("\nå¯åŠ¨å¯¹è¯åŠ©æ‰‹ TUI...")
    print("=" * 60)
    await tui_app.run_async()


if __name__ == "__main__":
    asyncio.run(main())
