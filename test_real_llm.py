"""
ä½¿ç”¨çœŸå®LLMæµ‹è¯•Nodeé›†ç¾¤
"""
import asyncio
import os
from loom import LoomBuilder
from loom.llm import OpenAIProvider
from loom.kernel.core import UniversalEventBus, Dispatcher
from loom.protocol.cloudevents import CloudEvent

# è®¾ç½®OpenAIå‡­è¯
os.environ["OPENAI_API_KEY"] = "sk-Fy6Y5WV5eugN61DhxH1AjI8th71OWfopqA2OCj5t93UIZ6aF"
os.environ["OPENAI_MODEL"] = "gpt-4o-mini"
os.environ["OPENAI_BASE_URL"] = "https://xiaoai.plus/v1"

print("=" * 60)
print("æµ‹è¯•1: çœŸå®LLMåŸºç¡€å¯¹è¯")
print("=" * 60)

async def test_real_llm_basic():
    """æµ‹è¯•ä½¿ç”¨çœŸå®LLMçš„åŸºç¡€å¯¹è¯"""
    # åˆ›å»ºåŸºç¡€è®¾æ–½
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºOpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=False  # ç¦ç”¨æµå¼è¾“å‡ºï¼Œä½¿ç”¨æ ‡å‡†chatæ–¹æ³•
    )

    print(f"âœ… OpenAI Provideråˆ›å»ºæˆåŠŸ")
    print(f"   - Model: {provider.config.generation.model}")
    print(f"   - Base URL: {provider.config.connection.base_url}")

    # åˆ›å»ºAgent
    agent = (LoomBuilder()
        .with_id('real-llm-agent')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_agent(
            role='AI Assistant',
            system_prompt='You are a helpful AI assistant. Answer questions concisely and accurately.'
        )
        .build())

    print(f"âœ… Agentåˆ›å»ºæˆåŠŸ: {agent.node_id}")

    # æµ‹è¯•ç®€å•å¯¹è¯
    print("\nğŸ“¨ å‘é€é—®é¢˜: ä»€ä¹ˆæ˜¯åˆ†å‹æ¶æ„ï¼Ÿ")
    event = CloudEvent(
        type="node.request",
        source="user",
        data={"content": "ä»€ä¹ˆæ˜¯åˆ†å‹æ¶æ„ï¼Ÿè¯·ç”¨ä¸€å¥è¯ç®€å•è§£é‡Šã€‚"}
    )

    result = await agent.process(event)
    print(f"\nğŸ¤– LLMå“åº”:\n{result}")

    return agent

# è¿è¡Œæµ‹è¯•1
agent = asyncio.run(test_real_llm_basic())
print("\nâœ… æµ‹è¯•1å®Œæˆ\n")

print("=" * 60)
print("æµ‹è¯•2: çœŸå®LLM + Toolè°ƒç”¨")
print("=" * 60)

async def test_real_llm_with_tool():
    """æµ‹è¯•çœŸå®LLMè°ƒç”¨å·¥å…·"""
    from loom.node.tool import ToolNode
    from loom.protocol.mcp import MCPToolDefinition

    # åˆ›å»ºåŸºç¡€è®¾æ–½
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºOpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=False
    )

    # åˆ›å»ºè®¡ç®—å™¨å·¥å…·
    def calculator(operation: str, a: float, b: float) -> float:
        """ç®€å•è®¡ç®—å™¨å·¥å…·"""
        if operation == "add":
            return a + b
        elif operation == "subtract":
            return a - b
        elif operation == "multiply":
            return a * b
        elif operation == "divide":
            return a / b if b != 0 else "Error: Division by zero"
        return "Unknown operation"

    tool_def = MCPToolDefinition(
        name="calculator",
        description="A calculator that can perform basic arithmetic operations (add, subtract, multiply, divide)",
        inputSchema={
            "type": "object",
            "properties": {
                "operation": {"type": "string", "enum": ["add", "subtract", "multiply", "divide"]},
                "a": {"type": "number", "description": "First number"},
                "b": {"type": "number", "description": "Second number"}
            },
            "required": ["operation", "a", "b"]
        }
    )

    tool_node = ToolNode(
        node_id="calculator-tool",
        dispatcher=dispatcher,
        tool_def=tool_def,
        func=calculator
    )

    print(f"âœ… Toolåˆ›å»ºæˆåŠŸ: {tool_node.node_id}")

    # åˆ›å»ºå¸¦Toolçš„Agent
    agent = (LoomBuilder()
        .with_id('tool-agent')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_tools([tool_node])
        .with_agent(
            role='Calculator Assistant',
            system_prompt='You are a helpful calculator assistant. Use the calculator tool to perform calculations.'
        )
        .build())

    print(f"âœ… Agentåˆ›å»ºæˆåŠŸ: {agent.node_id}")
    print(f"   - å·²æ³¨å†Œå·¥å…·: {list(agent.known_tools.keys())}")

    # æµ‹è¯•å·¥å…·è°ƒç”¨
    print("\nğŸ“¨ å‘é€é—®é¢˜: What is 123 multiplied by 456?")
    event = CloudEvent(
        type="node.request",
        source="user",
        data={"content": "What is 123 multiplied by 456? Please use the calculator tool."}
    )

    result = await agent.process(event)
    print(f"\nğŸ¤– LLMå“åº”:\n{result}")

    return agent

# è¿è¡Œæµ‹è¯•2
agent2 = asyncio.run(test_real_llm_with_tool())
print("\nâœ… æµ‹è¯•2å®Œæˆ\n")

print("=" * 60)
print("æµ‹è¯•3: çœŸå®LLM + å¹¶è¡Œå·¥å…·æ‰§è¡Œ")
print("=" * 60)

async def test_real_llm_parallel_tools():
    """æµ‹è¯•çœŸå®LLMå¹¶è¡Œè°ƒç”¨å¤šä¸ªå·¥å…·"""
    from loom.node.tool import ToolNode
    from loom.protocol.mcp import MCPToolDefinition

    # åˆ›å»ºåŸºç¡€è®¾æ–½
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºOpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=False
    )

    # åˆ›å»ºå¤šä¸ªå·¥å…·
    def get_weather(city: str) -> str:
        """è·å–å¤©æ°”ä¿¡æ¯"""
        return f"The weather in {city} is sunny, 25Â°C"

    def get_time(timezone: str) -> str:
        """è·å–æ—¶é—´"""
        return f"Current time in {timezone} is 14:30"

    def get_news(category: str) -> str:
        """è·å–æ–°é—»"""
        return f"Latest {category} news: AI technology advances rapidly"

    weather_tool = ToolNode(
        node_id="weather-tool",
        dispatcher=dispatcher,
        tool_def=MCPToolDefinition(
            name="get_weather",
            description="Get weather information for a city",
            inputSchema={
                "type": "object",
                "properties": {"city": {"type": "string"}},
                "required": ["city"]
            }
        ),
        func=get_weather
    )

    time_tool = ToolNode(
        node_id="time-tool",
        dispatcher=dispatcher,
        tool_def=MCPToolDefinition(
            name="get_time",
            description="Get current time in a timezone",
            inputSchema={
                "type": "object",
                "properties": {"timezone": {"type": "string"}},
                "required": ["timezone"]
            }
        ),
        func=get_time
    )

    news_tool = ToolNode(
        node_id="news-tool",
        dispatcher=dispatcher,
        tool_def=MCPToolDefinition(
            name="get_news",
            description="Get latest news in a category",
            inputSchema={
                "type": "object",
                "properties": {"category": {"type": "string"}},
                "required": ["category"]
            }
        ),
        func=get_news
    )

    print(f"âœ… åˆ›å»ºäº†3ä¸ªå·¥å…·: weather, time, news")

    # åˆ›å»ºæ”¯æŒå¹¶è¡Œæ‰§è¡Œçš„Agent
    agent = (LoomBuilder()
        .with_id('parallel-agent')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_tools([weather_tool, time_tool, news_tool])
        .with_execution(parallel_execution=True, max_concurrent=3)
        .with_agent(
            role='Information Assistant',
            system_prompt='You are an information assistant. Use the available tools to gather information.'
        )
        .build())

    print(f"âœ… Agentåˆ›å»ºæˆåŠŸ: {agent.node_id}")
    print(f"   - å·²æ³¨å†Œå·¥å…·: {list(agent.known_tools.keys())}")
    print(f"   - å¹¶è¡Œæ‰§è¡Œ: {agent.execution_config.parallel_execution}")

    # æµ‹è¯•å¹¶è¡Œå·¥å…·è°ƒç”¨
    print("\nğŸ“¨ å‘é€é—®é¢˜: Tell me the weather in Beijing, time in UTC, and tech news")
    event = CloudEvent(
        type="node.request",
        source="user",
        data={"content": "Please tell me: 1) weather in Beijing, 2) current time in UTC timezone, 3) latest tech news. Use the tools to get this information."}
    )

    result = await agent.process(event)
    print(f"\nğŸ¤– LLMå“åº”:\n{result}")

    return agent

# è¿è¡Œæµ‹è¯•3
agent3 = asyncio.run(test_real_llm_parallel_tools())
print("\nâœ… æµ‹è¯•3å®Œæˆ\n")

print("=" * 60)
print("æµ‹è¯•4: çœŸå®LLM + Crewç»“æ„åä½œ")
print("=" * 60)

async def test_real_llm_crew():
    """æµ‹è¯•Crewç»“æ„çš„å¤šAgentåä½œ"""
    # åˆ›å»ºåŸºç¡€è®¾æ–½
    bus = UniversalEventBus()
    dispatcher = Dispatcher(bus)

    # åˆ›å»ºOpenAI Provider
    provider = OpenAIProvider(
        api_key=os.environ["OPENAI_API_KEY"],
        model=os.environ["OPENAI_MODEL"],
        base_url=os.environ["OPENAI_BASE_URL"],
        stream=False
    )

    print("ğŸ”§ åˆ›å»ºCrewæˆå‘˜...")

    # Agent 1: Researcherï¼ˆç ”ç©¶å‘˜ï¼‰
    researcher = (LoomBuilder()
        .with_id('researcher')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_agent(
            role='Researcher',
            system_prompt='You are a researcher. Your job is to gather information and facts about the given topic. Be thorough and factual.'
        )
        .build())
    print(f"âœ… Researcheråˆ›å»ºæˆåŠŸ: {researcher.node_id}")

    # Agent 2: Analystï¼ˆåˆ†æå¸ˆï¼‰
    analyst = (LoomBuilder()
        .with_id('analyst')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_agent(
            role='Analyst',
            system_prompt='You are an analyst. Your job is to analyze information and draw insights. Be analytical and critical.'
        )
        .build())
    print(f"âœ… Analyståˆ›å»ºæˆåŠŸ: {analyst.node_id}")

    # Agent 3: Writerï¼ˆå†™ä½œè€…ï¼‰
    writer = (LoomBuilder()
        .with_id('writer')
        .with_llm(provider)
        .with_dispatcher(dispatcher)
        .with_agent(
            role='Writer',
            system_prompt='You are a writer. Your job is to write clear and engaging content based on research and analysis. Be concise and well-structured.'
        )
        .build())
    print(f"âœ… Writeråˆ›å»ºæˆåŠŸ: {writer.node_id}")
    print(f"\nâœ… Crewåˆ›å»ºå®Œæˆï¼Œå…±{3}ä¸ªæˆå‘˜")

    # å¼€å§‹åä½œä»»åŠ¡
    topic = "AI Agentæ¡†æ¶çš„å‘å±•è¶‹åŠ¿"
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ Crewä»»åŠ¡: {topic}")
    print(f"{'='*60}")

    # Step 1: Researcheræ”¶é›†ä¿¡æ¯
    print(f"\nğŸ” [Step 1] Researcherå¼€å§‹æ”¶é›†ä¿¡æ¯...")
    research_event = CloudEvent(
        type="node.request",
        source="coordinator",
        data={"content": f"Research the topic: {topic}. Provide key facts and trends."}
    )
    research_result = await researcher.process(research_event)
    print(f"âœ… Researchå®Œæˆ")
    print(f"ğŸ“„ Researchç»“æœ:\n{research_result[:200]}...")

    # Step 2: Analyståˆ†æä¿¡æ¯
    print(f"\nğŸ“Š [Step 2] Analystå¼€å§‹åˆ†æ...")
    analysis_event = CloudEvent(
        type="node.request",
        source="coordinator",
        data={"content": f"Analyze this research result and provide insights:\n\n{research_result}"}
    )
    analysis_result = await analyst.process(analysis_event)
    print(f"âœ… Analysiså®Œæˆ")
    print(f"ğŸ“„ Analysisç»“æœ:\n{analysis_result[:200]}...")

    # Step 3: Writeræ’°å†™æŠ¥å‘Š
    print(f"\nâœï¸ [Step 3] Writerå¼€å§‹æ’°å†™æŠ¥å‘Š...")
    writing_event = CloudEvent(
        type="node.request",
        source="coordinator",
        data={"content": f"Write a concise report based on this analysis:\n\n{analysis_result}"}
    )
    final_report = await writer.process(writing_event)
    print(f"âœ… Writingå®Œæˆ")

    print(f"\n{'='*60}")
    print(f"ğŸ“ æœ€ç»ˆæŠ¥å‘Š:")
    print(f"{'='*60}")
    print(final_report)

    return researcher, analyst, writer, final_report

# è¿è¡Œæµ‹è¯•4
crew_result = asyncio.run(test_real_llm_crew())
print("\nâœ… æµ‹è¯•4å®Œæˆ\n")

