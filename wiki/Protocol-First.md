# åè®®ä¼˜å…ˆ (Protocol-First)

## å®šä¹‰

**åè®®ä¼˜å…ˆ**æ˜¯ Loom çš„æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼Œæ‰€æœ‰ç»„ä»¶å¿…é¡»å…ˆå®šä¹‰æ¥å£åè®®(Protocol)ï¼Œç„¶åå®ç°å…·ä½“åŠŸèƒ½ã€‚

## æ ¸å¿ƒæ€æƒ³

ä¼ ç»Ÿæ¡†æ¶çš„æ‰©å±•æ–¹å¼æ˜¯ç»§æ‰¿(Inheritance)ï¼Œå¯¼è‡´ï¼š
- ç´§è€¦åˆï¼šå­ç±»ä¾èµ–çˆ¶ç±»çš„å®ç°ç»†èŠ‚
- è„†å¼±ï¼šçˆ¶ç±»å˜æ›´å½±å“æ‰€æœ‰å­ç±»
- ä¸çµæ´»ï¼šå¤šé‡ç»§æ‰¿å¤æ‚ä¸”å®¹æ˜“å‡ºé”™

Loom é‡‡ç”¨**åè®®(Protocol)**æ–¹å¼ï¼š
- æ¾è€¦åˆï¼šåªä¾èµ–æ¥å£ï¼Œä¸ä¾èµ–å®ç°
- ç¨³å®šï¼šåè®®å®šä¹‰åå¾ˆå°‘å˜æ›´
- çµæ´»ï¼šä¸€ä¸ªç±»å¯ä»¥å®ç°å¤šä¸ªåè®®

## Protocol vs Inheritance

### ä¼ ç»Ÿæ–¹å¼ï¼šç»§æ‰¿

```python
class Agent:
    def execute(self, task):
        raise NotImplementedError

class MyAgent(Agent):  # ç´§è€¦åˆ
    def execute(self, task):
        # ...
```

### Loom æ–¹å¼ï¼šåè®®

```python
from typing import Protocol

class AgentProtocol(Protocol):  # æ¥å£å®šä¹‰
    def execute(self, task: Task) -> Task:
        ...

class MyAgent:  # æ¾è€¦åˆï¼Œä¸ç»§æ‰¿
    def execute(self, task: Task) -> Task:
        # åªéœ€å®ç°åè®®æ–¹æ³•
```

## æ ¸å¿ƒåè®®

### Agent åè®®

```python
class NodeProtocol(Protocol):
    """èŠ‚ç‚¹åè®®ï¼šæ‰€æœ‰ç»„ä»¶çš„åŸºç¡€æ¥å£"""

    node_id: str
    node_type: str

    async def execute_task(self, task: Task) -> Task:
        """æ‰§è¡Œä»»åŠ¡"""
        ...
```

### LLM åè®®

```python
class LLMProvider(Protocol):
    """LLM æä¾›è€…åè®®"""

    async def stream_chat(
        self,
        messages: list[dict],
        tools: list[dict] | None = None
    ) -> AsyncIterator[Chunk]:
        """æµå¼å¯¹è¯"""
        ...
```

### Memory åè®®

```python
class MemoryLayer(Protocol):
    """è®°å¿†å±‚åè®®"""

    async def add(self, item: Task) -> None:
        """æ·»åŠ è®°å¿†"""
        ...

    async def retrieve(
        self,
        query: Any,
        limit: int = 10
    ) -> list[Task]:
        """æ£€ç´¢è®°å¿†"""
        ...
```

## ä¼˜åŠ¿

### 1. å¯æ›¿æ¢æ€§

```python
# è½»æ¾æ›¿æ¢ LLM æä¾›è€…
llm1 = OpenAIProvider(api_key="...")
llm2 = AnthropicProvider(api_key="...")

# ä¸¤è€…éƒ½å®ç°äº† LLMProvider åè®®ï¼Œå¯ä»¥ç›´æ¥äº’æ¢
agent = Agent(llm_provider=llm1)
agent.llm_provider = llm2  # æ— ç¼åˆ‡æ¢
```

### 2. å¤šå®ç°å…±å­˜

```python
# åŒä¸€ä¸ªåè®®çš„å¤šä¸ªå®ç°
class InMemoryLLM(LLMProvider): ...
class OpenAILLM(LLMProvider): ...
class AnthropicLLM(LLMProvider): ...

# æ ¹æ®åœºæ™¯é€‰æ‹©
if testing:
    llm = InMemoryLLM()
elif production:
    llm = OpenAILLM(api_key="...")
```

### 3. ç±»å‹å®‰å…¨

```python
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    # ç±»å‹æ£€æŸ¥æ—¶ä½¿ç”¨åè®®
    from loom.protocol import LLMProvider

def create_agent(llm: LLMProvider):  # ç±»å‹æç¤º
    return Agent(llm_provider=llm)

# mypy ä¼šæ£€æŸ¥ä¼ å…¥çš„å¯¹è±¡æ˜¯å¦ç¬¦åˆåè®®
create_agent(OpenAIProvider())  # âœ“ é€šè¿‡
create_agent("not an llm")       # âœ— ç±»å‹é”™è¯¯
```

## åè®®å‘ç°

Loom ä½¿ç”¨ `Protocol` çš„é¸­å­ç±»å‹ï¼š

```python
class MyCustomLLM:
    """ä¸éœ€è¦æ˜¾å¼å£°æ˜å®ç° LLMProvider"""

    async def stream_chat(
        self,
        messages: list[dict],
        tools: list[dict] | None = None
    ) -> AsyncIterator[Chunk]:
        """åªè¦å®ç°äº†è¿™ä¸ªæ–¹æ³•ï¼Œå°±ç¬¦åˆåè®®"""
        yield Chunk(type="text", content="...")

# å¯ä»¥ç›´æ¥ä½¿ç”¨
agent = Agent(llm_provider=MyCustomLLM())  # âœ“
```

## ç›¸å…³æ¦‚å¿µ

- â†’ [å…¬ç†ç³»ç»Ÿ](Axiomatic-System) (A1: ç»Ÿä¸€æ¥å£å…¬ç†)
- â†’ [åˆ†å½¢é€’å½’](Fractal-Recursion) (åè®®ä¿è¯å¯ç»„åˆæ€§)

## å‚è§

- ğŸ“– [PEP 544](https://peps.python.org/pep-0544/) (Protocol è§„èŒƒ)
- ğŸ”§ [API æŒ‡å—]: [å®ç°è‡ªå®šä¹‰åè®®](api/Protocol)

## ä»£ç ä½ç½®

- åè®®å®šä¹‰: `loom/protocol/`
- èŠ‚ç‚¹åè®®: `loom/protocol/nodes.py`
- LLM åè®®: `loom/protocol/llm.py`

## åå‘é“¾æ¥

è¢«å¼•ç”¨äº: [å…¬ç†ç³»ç»Ÿ](Axiomatic-System) | [åˆ†å½¢æ¶æ„](Fractal-Architecture) | [å·¥å…·ç³»ç»Ÿ](Tool-System)
